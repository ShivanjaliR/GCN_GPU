Learning Rate: 0.0001
Epoch:0	training loss:4.9489665031433105	 training accuracy:0.16470588235294117
Epoch:1	training loss:4.828097820281982	 training accuracy:0.16470588235294117
Epoch:2	training loss:4.707603454589844	 training accuracy:0.16470588235294117
Epoch:3	training loss:4.5875773429870605	 training accuracy:0.16470588235294117
Epoch:4	training loss:4.468133449554443	 training accuracy:0.16470588235294117
Epoch:5	training loss:4.349412441253662	 training accuracy:0.16470588235294117
Epoch:6	training loss:4.231588363647461	 training accuracy:0.16470588235294117
Epoch:7	training loss:4.11487340927124	 training accuracy:0.16470588235294117
Epoch:8	training loss:3.9995226860046387	 training accuracy:0.16470588235294117
Epoch:9	training loss:3.885845899581909	 training accuracy:0.16470588235294117
Epoch:10	training loss:3.7742063999176025	 training accuracy:0.16470588235294117
Epoch:11	training loss:3.6650328636169434	 training accuracy:0.16470588235294117
Epoch:12	training loss:3.5588154792785645	 training accuracy:0.16470588235294117
Epoch:13	training loss:3.456104040145874	 training accuracy:0.16470588235294117
Epoch:14	training loss:3.357489585876465	 training accuracy:0.16470588235294117
Epoch:15	training loss:3.2635791301727295	 training accuracy:0.16470588235294117
Epoch:16	training loss:3.1749510765075684	 training accuracy:0.16470588235294117
Epoch:17	training loss:3.0920913219451904	 training accuracy:0.16470588235294117
Epoch:18	training loss:3.0153234004974365	 training accuracy:0.16470588235294117
Epoch:19	training loss:2.944732189178467	 training accuracy:0.16470588235294117
Epoch:20	training loss:2.8801209926605225	 training accuracy:0.16470588235294117
Epoch:21	training loss:2.8210270404815674	 training accuracy:0.16470588235294117
Epoch:22	training loss:2.7667953968048096	 training accuracy:0.16470588235294117
Epoch:23	training loss:2.716721296310425	 training accuracy:0.16470588235294117
Epoch:24	training loss:2.6701903343200684	 training accuracy:0.16470588235294117
Epoch:25	training loss:2.626777172088623	 training accuracy:0.16470588235294117
Epoch:26	training loss:2.586277484893799	 training accuracy:0.16470588235294117
Epoch:27	training loss:2.5486700534820557	 training accuracy:0.16470588235294117
Epoch:28	training loss:2.5140442848205566	 training accuracy:0.16470588235294117
Epoch:29	training loss:2.482517719268799	 training accuracy:0.16470588235294117
Epoch:30	training loss:2.4541590213775635	 training accuracy:0.16470588235294117
Epoch:31	training loss:2.428941249847412	 training accuracy:0.16470588235294117
Epoch:32	training loss:2.40671443939209	 training accuracy:0.16470588235294117
Epoch:33	training loss:2.3872079849243164	 training accuracy:0.16470588235294117
Epoch:34	training loss:2.37005352973938	 training accuracy:0.16470588235294117
Epoch:35	training loss:2.354818344116211	 training accuracy:0.1411764705882353
Epoch:36	training loss:2.3410468101501465	 training accuracy:0.1411764705882353
Epoch:37	training loss:2.3282978534698486	 training accuracy:0.1411764705882353
Epoch:38	training loss:2.316176652908325	 training accuracy:0.1411764705882353
Epoch:39	training loss:2.30435848236084	 training accuracy:0.1411764705882353
Epoch:40	training loss:2.2925992012023926	 training accuracy:0.1411764705882353
Epoch:41	training loss:2.2807412147521973	 training accuracy:0.15294117647058825
Epoch:42	training loss:2.2687149047851562	 training accuracy:0.08235294117647059
Epoch:43	training loss:2.256526231765747	 training accuracy:0.1411764705882353
Epoch:44	training loss:2.2442500591278076	 training accuracy:0.1411764705882353
Epoch:45	training loss:2.2320170402526855	 training accuracy:0.1411764705882353
Epoch:46	training loss:2.2199981212615967	 training accuracy:0.1411764705882353
Epoch:47	training loss:2.208387613296509	 training accuracy:0.1411764705882353
Epoch:48	training loss:2.197389841079712	 training accuracy:0.1411764705882353
Epoch:49	training loss:2.1872005462646484	 training accuracy:0.1411764705882353
Epoch:50	training loss:2.177992820739746	 training accuracy:0.1411764705882353
Epoch:51	training loss:2.1699025630950928	 training accuracy:0.1411764705882353
Epoch:52	training loss:2.163018226623535	 training accuracy:0.1411764705882353
Epoch:53	training loss:2.1573758125305176	 training accuracy:0.1411764705882353
Epoch:54	training loss:2.1529541015625	 training accuracy:0.1411764705882353
Epoch:55	training loss:2.1496779918670654	 training accuracy:0.07058823529411765
Epoch:56	training loss:2.1474266052246094	 training accuracy:0.12941176470588237
Epoch:57	training loss:2.14604115486145	 training accuracy:0.1411764705882353
Epoch:58	training loss:2.14534068107605	 training accuracy:0.12941176470588237
Epoch:59	training loss:2.145134687423706	 training accuracy:0.11764705882352941
Epoch:60	training loss:2.145238161087036	 training accuracy:0.1411764705882353
Epoch:61	training loss:2.145482063293457	 training accuracy:0.1411764705882353
Epoch:62	training loss:2.1457223892211914	 training accuracy:0.1411764705882353
Epoch:63	training loss:2.1458451747894287	 training accuracy:0.1411764705882353
Epoch:64	training loss:2.1457669734954834	 training accuracy:0.1411764705882353
Epoch:65	training loss:2.145434856414795	 training accuracy:0.1411764705882353
Epoch:66	training loss:2.1448216438293457	 training accuracy:0.1411764705882353
Epoch:67	training loss:2.1439247131347656	 training accuracy:0.1411764705882353
Epoch:68	training loss:2.142759084701538	 training accuracy:0.1411764705882353
Epoch:69	training loss:2.1413536071777344	 training accuracy:0.1411764705882353
Epoch:70	training loss:2.139749765396118	 training accuracy:0.1411764705882353
Epoch:71	training loss:2.1379966735839844	 training accuracy:0.1411764705882353
Epoch:72	training loss:2.13614821434021	 training accuracy:0.1411764705882353
Epoch:73	training loss:2.1342594623565674	 training accuracy:0.1411764705882353
Epoch:74	training loss:2.1323814392089844	 training accuracy:0.1411764705882353
Epoch:75	training loss:2.1305601596832275	 training accuracy:0.11764705882352941
Epoch:76	training loss:2.128831624984741	 training accuracy:0.11764705882352941
Epoch:77	training loss:2.127220392227173	 training accuracy:0.12941176470588237
Epoch:78	training loss:2.1257386207580566	 training accuracy:0.1411764705882353
Epoch:79	training loss:2.124387502670288	 training accuracy:0.15294117647058825
Epoch:80	training loss:2.123159170150757	 training accuracy:0.16470588235294117
Epoch:81	training loss:2.1220386028289795	 training accuracy:0.16470588235294117
Epoch:82	training loss:2.1210074424743652	 training accuracy:0.16470588235294117
Epoch:83	training loss:2.1200451850891113	 training accuracy:0.16470588235294117
Epoch:84	training loss:2.119133472442627	 training accuracy:0.16470588235294117
Epoch:85	training loss:2.1182539463043213	 training accuracy:0.16470588235294117
Epoch:86	training loss:2.1173934936523438	 training accuracy:0.16470588235294117
Epoch:87	training loss:2.116539239883423	 training accuracy:0.16470588235294117
Epoch:88	training loss:2.115682363510132	 training accuracy:0.16470588235294117
Epoch:89	training loss:2.114816188812256	 training accuracy:0.16470588235294117
Epoch:90	training loss:2.1139345169067383	 training accuracy:0.17647058823529413
Epoch:91	training loss:2.113034248352051	 training accuracy:0.17647058823529413
Epoch:92	training loss:2.112112522125244	 training accuracy:0.17647058823529413
Epoch:93	training loss:2.1111693382263184	 training accuracy:0.17647058823529413
Epoch:94	training loss:2.110206127166748	 training accuracy:0.17647058823529413
Epoch:95	training loss:2.109224796295166	 training accuracy:0.17647058823529413
Epoch:96	training loss:2.108231782913208	 training accuracy:0.17647058823529413
Epoch:97	training loss:2.1072309017181396	 training accuracy:0.17647058823529413
Epoch:98	training loss:2.106226921081543	 training accuracy:0.17647058823529413
Epoch:99	training loss:2.1052260398864746	 training accuracy:0.17647058823529413
Epoch:100	training loss:2.104231119155884	 training accuracy:0.17647058823529413
Epoch:101	training loss:2.103245258331299	 training accuracy:0.17647058823529413
Epoch:102	training loss:2.102269411087036	 training accuracy:0.17647058823529413
Epoch:103	training loss:2.1013035774230957	 training accuracy:0.17647058823529413
Epoch:104	training loss:2.1003477573394775	 training accuracy:0.17647058823529413
Epoch:105	training loss:2.099400520324707	 training accuracy:0.17647058823529413
Epoch:106	training loss:2.0984609127044678	 training accuracy:0.17647058823529413
Epoch:107	training loss:2.0975277423858643	 training accuracy:0.17647058823529413
Epoch:108	training loss:2.096599578857422	 training accuracy:0.17647058823529413
Epoch:109	training loss:2.095674991607666	 training accuracy:0.17647058823529413
Epoch:110	training loss:2.094752788543701	 training accuracy:0.17647058823529413
Epoch:111	training loss:2.093832492828369	 training accuracy:0.17647058823529413
Epoch:112	training loss:2.0929129123687744	 training accuracy:0.17647058823529413
Epoch:113	training loss:2.0919933319091797	 training accuracy:0.17647058823529413
Epoch:114	training loss:2.091071844100952	 training accuracy:0.17647058823529413
Epoch:115	training loss:2.090149402618408	 training accuracy:0.17647058823529413
Epoch:116	training loss:2.0892252922058105	 training accuracy:0.17647058823529413
Epoch:117	training loss:2.088299512863159	 training accuracy:0.17647058823529413
Epoch:118	training loss:2.087372064590454	 training accuracy:0.17647058823529413
Epoch:119	training loss:2.086444139480591	 training accuracy:0.17647058823529413
Epoch:120	training loss:2.0855159759521484	 training accuracy:0.17647058823529413
Epoch:121	training loss:2.084587574005127	 training accuracy:0.17647058823529413
Epoch:122	training loss:2.0836591720581055	 training accuracy:0.17647058823529413
Epoch:123	training loss:2.0827322006225586	 training accuracy:0.17647058823529413
Epoch:124	training loss:2.081805944442749	 training accuracy:0.17647058823529413
Epoch:125	training loss:2.0808804035186768	 training accuracy:0.17647058823529413
Epoch:126	training loss:2.079956293106079	 training accuracy:0.17647058823529413
Epoch:127	training loss:2.0790324211120605	 training accuracy:0.17647058823529413
Epoch:128	training loss:2.0781092643737793	 training accuracy:0.17647058823529413
Epoch:129	training loss:2.0771865844726562	 training accuracy:0.17647058823529413
Epoch:130	training loss:2.0762648582458496	 training accuracy:0.17647058823529413
Epoch:131	training loss:2.075343132019043	 training accuracy:0.17647058823529413
Epoch:132	training loss:2.0744218826293945	 training accuracy:0.17647058823529413
Epoch:133	training loss:2.0735011100769043	 training accuracy:0.17647058823529413
Epoch:134	training loss:2.072580575942993	 training accuracy:0.17647058823529413
Epoch:135	training loss:2.071659803390503	 training accuracy:0.17647058823529413
Epoch:136	training loss:2.0707390308380127	 training accuracy:0.17647058823529413
Epoch:137	training loss:2.069817543029785	 training accuracy:0.17647058823529413
Epoch:138	training loss:2.0688955783843994	 training accuracy:0.17647058823529413
Epoch:139	training loss:2.0679731369018555	 training accuracy:0.17647058823529413
Epoch:140	training loss:2.0670509338378906	 training accuracy:0.17647058823529413
Epoch:141	training loss:2.0661277770996094	 training accuracy:0.17647058823529413
Epoch:142	training loss:2.0652048587799072	 training accuracy:0.17647058823529413
Epoch:143	training loss:2.064281702041626	 training accuracy:0.17647058823529413
Epoch:144	training loss:2.0633585453033447	 training accuracy:0.17647058823529413
Epoch:145	training loss:2.0624349117279053	 training accuracy:0.17647058823529413
Epoch:146	training loss:2.061511516571045	 training accuracy:0.17647058823529413
Epoch:147	training loss:2.0605876445770264	 training accuracy:0.17647058823529413
Epoch:148	training loss:2.059663772583008	 training accuracy:0.17647058823529413
Epoch:149	training loss:2.058739423751831	 training accuracy:0.17647058823529413
Epoch:150	training loss:2.0578150749206543	 training accuracy:0.17647058823529413
Epoch:151	training loss:2.0568907260894775	 training accuracy:0.17647058823529413
Epoch:152	training loss:2.0559659004211426	 training accuracy:0.17647058823529413
Epoch:153	training loss:2.0550408363342285	 training accuracy:0.17647058823529413
Epoch:154	training loss:2.0541155338287354	 training accuracy:0.17647058823529413
Epoch:155	training loss:2.053189754486084	 training accuracy:0.17647058823529413
Epoch:156	training loss:2.0522639751434326	 training accuracy:0.17647058823529413
Epoch:157	training loss:2.051337480545044	 training accuracy:0.17647058823529413
Epoch:158	training loss:2.0504109859466553	 training accuracy:0.17647058823529413
Epoch:159	training loss:2.0494840145111084	 training accuracy:0.17647058823529413
Epoch:160	training loss:2.0485565662384033	 training accuracy:0.17647058823529413
Epoch:161	training loss:2.04762864112854	 training accuracy:0.17647058823529413
Epoch:162	training loss:2.0467004776000977	 training accuracy:0.17647058823529413
Epoch:163	training loss:2.045771837234497	 training accuracy:0.17647058823529413
Epoch:164	training loss:2.044842481613159	 training accuracy:0.18823529411764706
Epoch:165	training loss:2.043912887573242	 training accuracy:0.18823529411764706
Epoch:166	training loss:2.042983055114746	 training accuracy:0.18823529411764706
Epoch:167	training loss:2.042052745819092	 training accuracy:0.18823529411764706
Epoch:168	training loss:2.0411221981048584	 training accuracy:0.18823529411764706
Epoch:169	training loss:2.0401909351348877	 training accuracy:0.18823529411764706
Epoch:170	training loss:2.039259195327759	 training accuracy:0.18823529411764706
Epoch:171	training loss:2.038327217102051	 training accuracy:0.18823529411764706
Epoch:172	training loss:2.0373942852020264	 training accuracy:0.2
Epoch:173	training loss:2.036461353302002	 training accuracy:0.2
Epoch:174	training loss:2.0355279445648193	 training accuracy:0.2
Epoch:175	training loss:2.0345940589904785	 training accuracy:0.2
Epoch:176	training loss:2.0336594581604004	 training accuracy:0.2
Epoch:177	training loss:2.032724618911743	 training accuracy:0.2
Epoch:178	training loss:2.031789541244507	 training accuracy:0.2
Epoch:179	training loss:2.030853509902954	 training accuracy:0.2
Epoch:180	training loss:2.0299174785614014	 training accuracy:0.2
Epoch:181	training loss:2.0289809703826904	 training accuracy:0.2
Epoch:182	training loss:2.028043746948242	 training accuracy:0.2
Epoch:183	training loss:2.027106523513794	 training accuracy:0.2
Epoch:184	training loss:2.0261685848236084	 training accuracy:0.2
Epoch:185	training loss:2.025230884552002	 training accuracy:0.2
Epoch:186	training loss:2.0242919921875	 training accuracy:0.2
Epoch:187	training loss:2.023353099822998	 training accuracy:0.2
Epoch:188	training loss:2.022413492202759	 training accuracy:0.2
Epoch:189	training loss:2.0214736461639404	 training accuracy:0.2
Epoch:190	training loss:2.020533561706543	 training accuracy:0.2
Epoch:191	training loss:2.0195930004119873	 training accuracy:0.2
Epoch:192	training loss:2.0186517238616943	 training accuracy:0.2
Epoch:193	training loss:2.0177104473114014	 training accuracy:0.2
Epoch:194	training loss:2.01676869392395	 training accuracy:0.2
Epoch:195	training loss:2.0158262252807617	 training accuracy:0.2
Epoch:196	training loss:2.0148837566375732	 training accuracy:0.2
Epoch:197	training loss:2.0139412879943848	 training accuracy:0.2
Epoch:198	training loss:2.01299786567688	 training accuracy:0.2
Epoch:199	training loss:2.012054204940796	 training accuracy:0.2
Epoch:200	training loss:2.011110544204712	 training accuracy:0.2
Epoch:201	training loss:2.0101659297943115	 training accuracy:0.2
Epoch:202	training loss:2.009221076965332	 training accuracy:0.2
Epoch:203	training loss:2.0082757472991943	 training accuracy:0.2
Epoch:204	training loss:2.0073304176330566	 training accuracy:0.2
Epoch:205	training loss:2.00638484954834	 training accuracy:0.2
Epoch:206	training loss:2.0054383277893066	 training accuracy:0.2
Epoch:207	training loss:2.0044918060302734	 training accuracy:0.21176470588235294
Epoch:208	training loss:2.003545045852661	 training accuracy:0.21176470588235294
Epoch:209	training loss:2.0025975704193115	 training accuracy:0.21176470588235294
Epoch:210	training loss:2.001650094985962	 training accuracy:0.21176470588235294
Epoch:211	training loss:2.000701904296875	 training accuracy:0.21176470588235294
Epoch:212	training loss:1.9997538328170776	 training accuracy:0.21176470588235294
Epoch:213	training loss:1.9988048076629639	 training accuracy:0.21176470588235294
Epoch:214	training loss:1.9978563785552979	 training accuracy:0.21176470588235294
Epoch:215	training loss:1.996907114982605	 training accuracy:0.21176470588235294
Epoch:216	training loss:1.9959574937820435	 training accuracy:0.21176470588235294
Epoch:217	training loss:1.9950077533721924	 training accuracy:0.21176470588235294
Epoch:218	training loss:1.994057297706604	 training accuracy:0.21176470588235294
Epoch:219	training loss:1.9931066036224365	 training accuracy:0.2
Epoch:220	training loss:1.9921561479568481	 training accuracy:0.21176470588235294
Epoch:221	training loss:1.9912056922912598	 training accuracy:0.21176470588235294
Epoch:222	training loss:1.9902546405792236	 training accuracy:0.21176470588235294
Epoch:223	training loss:1.9893033504486084	 training accuracy:0.21176470588235294
Epoch:224	training loss:1.9883517026901245	 training accuracy:0.21176470588235294
Epoch:225	training loss:1.9874000549316406	 training accuracy:0.21176470588235294
Epoch:226	training loss:1.986448049545288	 training accuracy:0.21176470588235294
Epoch:227	training loss:1.9854958057403564	 training accuracy:0.21176470588235294
Epoch:228	training loss:1.9845432043075562	 training accuracy:0.21176470588235294
Epoch:229	training loss:1.9835902452468872	 training accuracy:0.2235294117647059
Epoch:230	training loss:1.9826371669769287	 training accuracy:0.2235294117647059
Epoch:231	training loss:1.9816842079162598	 training accuracy:0.2235294117647059
Epoch:232	training loss:1.980730652809143	 training accuracy:0.2235294117647059
Epoch:233	training loss:1.979777455329895	 training accuracy:0.2235294117647059
Epoch:234	training loss:1.9788237810134888	 training accuracy:0.2235294117647059
Epoch:235	training loss:1.9778698682785034	 training accuracy:0.2235294117647059
Epoch:236	training loss:1.9769160747528076	 training accuracy:0.2235294117647059
Epoch:237	training loss:1.9759622812271118	 training accuracy:0.23529411764705882
Epoch:238	training loss:1.9750078916549683	 training accuracy:0.23529411764705882
Epoch:239	training loss:1.9740536212921143	 training accuracy:0.23529411764705882
Epoch:240	training loss:1.9730993509292603	 training accuracy:0.23529411764705882
Epoch:241	training loss:1.9721447229385376	 training accuracy:0.23529411764705882
Epoch:242	training loss:1.971190094947815	 training accuracy:0.23529411764705882
Epoch:243	training loss:1.9702354669570923	 training accuracy:0.23529411764705882
Epoch:244	training loss:1.9692808389663696	 training accuracy:0.23529411764705882
Epoch:245	training loss:1.9683258533477783	 training accuracy:0.23529411764705882
Epoch:246	training loss:1.9673709869384766	 training accuracy:0.23529411764705882
Epoch:247	training loss:1.9664158821105957	 training accuracy:0.23529411764705882
Epoch:248	training loss:1.9654606580734253	 training accuracy:0.24705882352941178
Epoch:249	training loss:1.9645053148269653	 training accuracy:0.24705882352941178
Epoch:250	training loss:1.963550090789795	 training accuracy:0.25882352941176473
Epoch:251	training loss:1.9625946283340454	 training accuracy:0.27058823529411763
Epoch:252	training loss:1.961639165878296	 training accuracy:0.2823529411764706
Epoch:253	training loss:1.9606835842132568	 training accuracy:0.2823529411764706
Epoch:254	training loss:1.9597278833389282	 training accuracy:0.2823529411764706
Epoch:255	training loss:1.9587721824645996	 training accuracy:0.2823529411764706
Epoch:256	training loss:1.957816243171692	 training accuracy:0.2823529411764706
Epoch:257	training loss:1.9568603038787842	 training accuracy:0.2823529411764706
Epoch:258	training loss:1.9559041261672974	 training accuracy:0.2823529411764706
Epoch:259	training loss:1.9549480676651	 training accuracy:0.2823529411764706
Epoch:260	training loss:1.9539920091629028	 training accuracy:0.2823529411764706
Epoch:261	training loss:1.953035593032837	 training accuracy:0.2823529411764706
Epoch:262	training loss:1.9520796537399292	 training accuracy:0.2823529411764706
Epoch:263	training loss:1.9511233568191528	 training accuracy:0.2823529411764706
Epoch:264	training loss:1.9501668214797974	 training accuracy:0.2823529411764706
Epoch:265	training loss:1.9492100477218628	 training accuracy:0.29411764705882354
Epoch:266	training loss:1.9482532739639282	 training accuracy:0.29411764705882354
Epoch:267	training loss:1.9472966194152832	 training accuracy:0.29411764705882354
Epoch:268	training loss:1.9463393688201904	 training accuracy:0.29411764705882354
Epoch:269	training loss:1.9453822374343872	 training accuracy:0.29411764705882354
Epoch:270	training loss:1.9444252252578735	 training accuracy:0.29411764705882354
Epoch:271	training loss:1.943467617034912	 training accuracy:0.29411764705882354
Epoch:272	training loss:1.9425097703933716	 training accuracy:0.29411764705882354
Epoch:273	training loss:1.9415522813796997	 training accuracy:0.29411764705882354
Epoch:274	training loss:1.9405945539474487	 training accuracy:0.29411764705882354
Epoch:275	training loss:1.939636468887329	 training accuracy:0.29411764705882354
Epoch:276	training loss:1.9386783838272095	 training accuracy:0.29411764705882354
Epoch:277	training loss:1.9377200603485107	 training accuracy:0.3058823529411765
Epoch:278	training loss:1.9367609024047852	 training accuracy:0.3058823529411765
Epoch:279	training loss:1.9358023405075073	 training accuracy:0.3058823529411765
Epoch:280	training loss:1.9348431825637817	 training accuracy:0.3058823529411765
Epoch:281	training loss:1.9338839054107666	 training accuracy:0.3058823529411765
Epoch:282	training loss:1.9329241514205933	 training accuracy:0.3058823529411765
Epoch:283	training loss:1.931964635848999	 training accuracy:0.3058823529411765
Epoch:284	training loss:1.9310047626495361	 training accuracy:0.29411764705882354
Epoch:285	training loss:1.9300446510314941	 training accuracy:0.29411764705882354
Epoch:286	training loss:1.9290841817855835	 training accuracy:0.29411764705882354
Epoch:287	training loss:1.9281232357025146	 training accuracy:0.29411764705882354
Epoch:288	training loss:1.9271620512008667	 training accuracy:0.29411764705882354
Epoch:289	training loss:1.9262008666992188	 training accuracy:0.29411764705882354
Epoch:290	training loss:1.925239086151123	 training accuracy:0.29411764705882354
Epoch:291	training loss:1.9242768287658691	 training accuracy:0.29411764705882354
Epoch:292	training loss:1.9233144521713257	 training accuracy:0.29411764705882354
Epoch:293	training loss:1.9223518371582031	 training accuracy:0.29411764705882354
Epoch:294	training loss:1.9213887453079224	 training accuracy:0.29411764705882354
Epoch:295	training loss:1.920425534248352	 training accuracy:0.29411764705882354
Epoch:296	training loss:1.919461727142334	 training accuracy:0.29411764705882354
Epoch:297	training loss:1.9184975624084473	 training accuracy:0.29411764705882354
Epoch:298	training loss:1.917533278465271	 training accuracy:0.29411764705882354
Epoch:299	training loss:1.9165687561035156	 training accuracy:0.29411764705882354
Epoch:300	training loss:1.9156038761138916	 training accuracy:0.29411764705882354
Epoch:301	training loss:1.9146382808685303	 training accuracy:0.29411764705882354
Epoch:302	training loss:1.9136722087860107	 training accuracy:0.29411764705882354
Epoch:303	training loss:1.9127057790756226	 training accuracy:0.29411764705882354
Epoch:304	training loss:1.9117388725280762	 training accuracy:0.29411764705882354
Epoch:305	training loss:1.9107716083526611	 training accuracy:0.29411764705882354
Epoch:306	training loss:1.9098036289215088	 training accuracy:0.29411764705882354
Epoch:307	training loss:1.9088350534439087	 training accuracy:0.29411764705882354
Epoch:308	training loss:1.9078658819198608	 training accuracy:0.29411764705882354
Epoch:309	training loss:1.9068961143493652	 training accuracy:0.29411764705882354
Epoch:310	training loss:1.90592622756958	 training accuracy:0.29411764705882354
Epoch:311	training loss:1.9049551486968994	 training accuracy:0.29411764705882354
Epoch:312	training loss:1.9039838314056396	 training accuracy:0.29411764705882354
Epoch:313	training loss:1.9030119180679321	 training accuracy:0.3058823529411765
Epoch:314	training loss:1.9020392894744873	 training accuracy:0.3058823529411765
Epoch:315	training loss:1.9010658264160156	 training accuracy:0.3058823529411765
Epoch:316	training loss:1.900092363357544	 training accuracy:0.3058823529411765
Epoch:317	training loss:1.8991179466247559	 training accuracy:0.3058823529411765
Epoch:318	training loss:1.8981432914733887	 training accuracy:0.3058823529411765
Epoch:319	training loss:1.8971672058105469	 training accuracy:0.3058823529411765
Epoch:320	training loss:1.896191120147705	 training accuracy:0.3058823529411765
Epoch:321	training loss:1.8952140808105469	 training accuracy:0.3058823529411765
Epoch:322	training loss:1.8942359685897827	 training accuracy:0.3058823529411765
Epoch:323	training loss:1.8932576179504395	 training accuracy:0.3058823529411765
Epoch:324	training loss:1.8922784328460693	 training accuracy:0.3058823529411765
Epoch:325	training loss:1.8912982940673828	 training accuracy:0.3058823529411765
Epoch:326	training loss:1.8903172016143799	 training accuracy:0.3058823529411765
Epoch:327	training loss:1.88933527469635	 training accuracy:0.3058823529411765
Epoch:328	training loss:1.888352870941162	 training accuracy:0.3058823529411765
Epoch:329	training loss:1.8873698711395264	 training accuracy:0.3058823529411765
Epoch:330	training loss:1.8863856792449951	 training accuracy:0.3058823529411765
Epoch:331	training loss:1.8854001760482788	 training accuracy:0.3058823529411765
Epoch:332	training loss:1.8844140768051147	 training accuracy:0.3058823529411765
Epoch:333	training loss:1.8834272623062134	 training accuracy:0.3058823529411765
Epoch:334	training loss:1.8824400901794434	 training accuracy:0.3058823529411765
Epoch:335	training loss:1.8814513683319092	 training accuracy:0.3058823529411765
Epoch:336	training loss:1.8804618120193481	 training accuracy:0.3058823529411765
Epoch:337	training loss:1.8794713020324707	 training accuracy:0.3058823529411765
Epoch:338	training loss:1.878480076789856	 training accuracy:0.3058823529411765
Epoch:339	training loss:1.8774876594543457	 training accuracy:0.3058823529411765
Epoch:340	training loss:1.8764944076538086	 training accuracy:0.3058823529411765
Epoch:341	training loss:1.8755000829696655	 training accuracy:0.3058823529411765
Epoch:342	training loss:1.8745051622390747	 training accuracy:0.3058823529411765
Epoch:343	training loss:1.8735088109970093	 training accuracy:0.3058823529411765
Epoch:344	training loss:1.8725119829177856	 training accuracy:0.3058823529411765
Epoch:345	training loss:1.871513843536377	 training accuracy:0.3058823529411765
Epoch:346	training loss:1.870514988899231	 training accuracy:0.3058823529411765
Epoch:347	training loss:1.8695144653320312	 training accuracy:0.3058823529411765
Epoch:348	training loss:1.868513584136963	 training accuracy:0.3058823529411765
Epoch:349	training loss:1.867511510848999	 training accuracy:0.3058823529411765
Epoch:350	training loss:1.8665084838867188	 training accuracy:0.3058823529411765
Epoch:351	training loss:1.8655039072036743	 training accuracy:0.3058823529411765
Epoch:352	training loss:1.864498496055603	 training accuracy:0.3058823529411765
Epoch:353	training loss:1.8634920120239258	 training accuracy:0.3058823529411765
Epoch:354	training loss:1.862484335899353	 training accuracy:0.3058823529411765
Epoch:355	training loss:1.8614758253097534	 training accuracy:0.3058823529411765
Epoch:356	training loss:1.8604661226272583	 training accuracy:0.3058823529411765
Epoch:357	training loss:1.8594553470611572	 training accuracy:0.3058823529411765
Epoch:358	training loss:1.8584433794021606	 training accuracy:0.3058823529411765
Epoch:359	training loss:1.8574304580688477	 training accuracy:0.3058823529411765
Epoch:360	training loss:1.8564165830612183	 training accuracy:0.3058823529411765
Epoch:361	training loss:1.8554012775421143	 training accuracy:0.3058823529411765
Epoch:362	training loss:1.8543847799301147	 training accuracy:0.3058823529411765
Epoch:363	training loss:1.8533670902252197	 training accuracy:0.3058823529411765
Epoch:364	training loss:1.8523482084274292	 training accuracy:0.3058823529411765
Epoch:365	training loss:1.8513283729553223	 training accuracy:0.3058823529411765
Epoch:366	training loss:1.8503072261810303	 training accuracy:0.3058823529411765
Epoch:367	training loss:1.8492852449417114	 training accuracy:0.3058823529411765
Epoch:368	training loss:1.8482617139816284	 training accuracy:0.3058823529411765
Epoch:369	training loss:1.84723699092865	 training accuracy:0.3058823529411765
Epoch:370	training loss:1.8462109565734863	 training accuracy:0.3058823529411765
Epoch:371	training loss:1.845184326171875	 training accuracy:0.3058823529411765
Epoch:372	training loss:1.8441566228866577	 training accuracy:0.3058823529411765
Epoch:373	training loss:1.8431271314620972	 training accuracy:0.3058823529411765
Epoch:374	training loss:1.8420964479446411	 training accuracy:0.3058823529411765
Epoch:375	training loss:1.8410648107528687	 training accuracy:0.3058823529411765
Epoch:376	training loss:1.840031623840332	 training accuracy:0.3058823529411765
Epoch:377	training loss:1.838997721672058	 training accuracy:0.3176470588235294
Epoch:378	training loss:1.83796226978302	 training accuracy:0.3176470588235294
Epoch:379	training loss:1.836925745010376	 training accuracy:0.3176470588235294
Epoch:380	training loss:1.8358877897262573	 training accuracy:0.32941176470588235
Epoch:381	training loss:1.8348488807678223	 training accuracy:0.32941176470588235
Epoch:382	training loss:1.8338088989257812	 training accuracy:0.32941176470588235
Epoch:383	training loss:1.8327678442001343	 training accuracy:0.32941176470588235
Epoch:384	training loss:1.8317251205444336	 training accuracy:0.32941176470588235
Epoch:385	training loss:1.8306812047958374	 training accuracy:0.32941176470588235
Epoch:386	training loss:1.8296364545822144	 training accuracy:0.35294117647058826
Epoch:387	training loss:1.8285901546478271	 training accuracy:0.35294117647058826
Epoch:388	training loss:1.8275424242019653	 training accuracy:0.35294117647058826
Epoch:389	training loss:1.8264940977096558	 training accuracy:0.35294117647058826
Epoch:390	training loss:1.8254443407058716	 training accuracy:0.35294117647058826
Epoch:391	training loss:1.8243935108184814	 training accuracy:0.35294117647058826
Epoch:392	training loss:1.8233412504196167	 training accuracy:0.36470588235294116
Epoch:393	training loss:1.8222877979278564	 training accuracy:0.36470588235294116
Epoch:394	training loss:1.8212332725524902	 training accuracy:0.36470588235294116
Epoch:395	training loss:1.820177674293518	 training accuracy:0.36470588235294116
Epoch:396	training loss:1.819120168685913	 training accuracy:0.36470588235294116
Epoch:397	training loss:1.8180617094039917	 training accuracy:0.36470588235294116
Epoch:398	training loss:1.8170018196105957	 training accuracy:0.36470588235294116
Epoch:399	training loss:1.8159406185150146	 training accuracy:0.36470588235294116
Epoch:400	training loss:1.814878225326538	 training accuracy:0.36470588235294116
Epoch:401	training loss:1.8138147592544556	 training accuracy:0.36470588235294116
Epoch:402	training loss:1.8127503395080566	 training accuracy:0.36470588235294116
Epoch:403	training loss:1.8116837739944458	 training accuracy:0.36470588235294116
Epoch:404	training loss:1.8106155395507812	 training accuracy:0.36470588235294116
Epoch:405	training loss:1.8095470666885376	 training accuracy:0.3764705882352941
Epoch:406	training loss:1.8084768056869507	 training accuracy:0.3764705882352941
Epoch:407	training loss:1.8074053525924683	 training accuracy:0.3764705882352941
Epoch:408	training loss:1.8063327074050903	 training accuracy:0.38823529411764707
Epoch:409	training loss:1.8052587509155273	 training accuracy:0.38823529411764707
Epoch:410	training loss:1.8041831254959106	 training accuracy:0.38823529411764707
Epoch:411	training loss:1.803106427192688	 training accuracy:0.38823529411764707
Epoch:412	training loss:1.8020281791687012	 training accuracy:0.4
Epoch:413	training loss:1.8009488582611084	 training accuracy:0.4
Epoch:414	training loss:1.7998677492141724	 training accuracy:0.4
Epoch:415	training loss:1.7987850904464722	 training accuracy:0.4117647058823529
Epoch:416	training loss:1.7977015972137451	 training accuracy:0.4117647058823529
Epoch:417	training loss:1.7966160774230957	 training accuracy:0.4117647058823529
Epoch:418	training loss:1.7955297231674194	 training accuracy:0.43529411764705883
Epoch:419	training loss:1.7944415807724	 training accuracy:0.43529411764705883
Epoch:420	training loss:1.7933523654937744	 training accuracy:0.4470588235294118
Epoch:421	training loss:1.7922612428665161	 training accuracy:0.4470588235294118
Epoch:422	training loss:1.7911688089370728	 training accuracy:0.4470588235294118
Epoch:423	training loss:1.7900749444961548	 training accuracy:0.4470588235294118
Epoch:424	training loss:1.788979172706604	 training accuracy:0.47058823529411764
Epoch:425	training loss:1.7878822088241577	 training accuracy:0.47058823529411764
Epoch:426	training loss:1.7867836952209473	 training accuracy:0.47058823529411764
Epoch:427	training loss:1.7856833934783936	 training accuracy:0.47058823529411764
Epoch:428	training loss:1.7845815420150757	 training accuracy:0.47058823529411764
Epoch:429	training loss:1.7834781408309937	 training accuracy:0.47058823529411764
Epoch:430	training loss:1.7823728322982788	 training accuracy:0.47058823529411764
Epoch:431	training loss:1.781266450881958	 training accuracy:0.47058823529411764
Epoch:432	training loss:1.7801581621170044	 training accuracy:0.47058823529411764
Epoch:433	training loss:1.7790480852127075	 training accuracy:0.47058823529411764
Epoch:434	training loss:1.777936339378357	 training accuracy:0.47058823529411764
Epoch:435	training loss:1.7768229246139526	 training accuracy:0.47058823529411764
Epoch:436	training loss:1.775707721710205	 training accuracy:0.47058823529411764
Epoch:437	training loss:1.7745909690856934	 training accuracy:0.47058823529411764
Epoch:438	training loss:1.7734724283218384	 training accuracy:0.47058823529411764
Epoch:439	training loss:1.7723522186279297	 training accuracy:0.47058823529411764
Epoch:440	training loss:1.7712302207946777	 training accuracy:0.47058823529411764
Epoch:441	training loss:1.770106554031372	 training accuracy:0.47058823529411764
Epoch:442	training loss:1.7689810991287231	 training accuracy:0.47058823529411764
Epoch:443	training loss:1.7678534984588623	 training accuracy:0.49411764705882355
Epoch:444	training loss:1.7667244672775269	 training accuracy:0.49411764705882355
Epoch:445	training loss:1.7655930519104004	 training accuracy:0.5058823529411764
Epoch:446	training loss:1.7644600868225098	 training accuracy:0.5058823529411764
Epoch:447	training loss:1.763324499130249	 training accuracy:0.5058823529411764
Epoch:448	training loss:1.7621877193450928	 training accuracy:0.5058823529411764
Epoch:449	training loss:1.7610489130020142	 training accuracy:0.5058823529411764
Epoch:450	training loss:1.7599080801010132	 training accuracy:0.5058823529411764
Epoch:451	training loss:1.7587653398513794	 training accuracy:0.5176470588235295
Epoch:452	training loss:1.7576208114624023	 training accuracy:0.5176470588235295
Epoch:453	training loss:1.756474256515503	 training accuracy:0.5058823529411764
Epoch:454	training loss:1.755325436592102	 training accuracy:0.5058823529411764
Epoch:455	training loss:1.754175066947937	 training accuracy:0.5058823529411764
Epoch:456	training loss:1.7530221939086914	 training accuracy:0.5058823529411764
Epoch:457	training loss:1.751867651939392	 training accuracy:0.5176470588235295
Epoch:458	training loss:1.7507109642028809	 training accuracy:0.5176470588235295
Epoch:459	training loss:1.7495523691177368	 training accuracy:0.5176470588235295
Epoch:460	training loss:1.7483917474746704	 training accuracy:0.5176470588235295
Epoch:461	training loss:1.7472292184829712	 training accuracy:0.5176470588235295
Epoch:462	training loss:1.7460647821426392	 training accuracy:0.5176470588235295
Epoch:463	training loss:1.7448979616165161	 training accuracy:0.5176470588235295
Epoch:464	training loss:1.7437292337417603	 training accuracy:0.5176470588235295
Epoch:465	training loss:1.742558240890503	 training accuracy:0.5176470588235295
Epoch:466	training loss:1.7413856983184814	 training accuracy:0.5294117647058824
Epoch:467	training loss:1.7402105331420898	 training accuracy:0.5294117647058824
Epoch:468	training loss:1.739033579826355	 training accuracy:0.5294117647058824
Epoch:469	training loss:1.7378545999526978	 training accuracy:0.5294117647058824
Epoch:470	training loss:1.736673355102539	 training accuracy:0.5411764705882353
Epoch:471	training loss:1.735490083694458	 training accuracy:0.5411764705882353
Epoch:472	training loss:1.734304428100586	 training accuracy:0.5411764705882353
Epoch:473	training loss:1.733116865158081	 training accuracy:0.5411764705882353
Epoch:474	training loss:1.7319271564483643	 training accuracy:0.5411764705882353
Epoch:475	training loss:1.7307353019714355	 training accuracy:0.5411764705882353
Epoch:476	training loss:1.729541540145874	 training accuracy:0.5529411764705883
Epoch:477	training loss:1.728345513343811	 training accuracy:0.5529411764705883
Epoch:478	training loss:1.7271475791931152	 training accuracy:0.5529411764705883
Epoch:479	training loss:1.725947380065918	 training accuracy:0.5529411764705883
Epoch:480	training loss:1.7247449159622192	 training accuracy:0.5529411764705883
Epoch:481	training loss:1.7235406637191772	 training accuracy:0.5529411764705883
Epoch:482	training loss:1.7223339080810547	 training accuracy:0.5529411764705883
Epoch:483	training loss:1.7211250066757202	 training accuracy:0.5529411764705883
Epoch:484	training loss:1.7199140787124634	 training accuracy:0.5411764705882353
Epoch:485	training loss:1.7187014818191528	 training accuracy:0.5411764705882353
Epoch:486	training loss:1.7174865007400513	 training accuracy:0.5411764705882353
Epoch:487	training loss:1.7162690162658691	 training accuracy:0.5411764705882353
Epoch:488	training loss:1.715049386024475	 training accuracy:0.5411764705882353
Epoch:489	training loss:1.7138274908065796	 training accuracy:0.5529411764705883
Epoch:490	training loss:1.7126034498214722	 training accuracy:0.5529411764705883
Epoch:491	training loss:1.711377739906311	 training accuracy:0.5529411764705883
Epoch:492	training loss:1.7101495265960693	 training accuracy:0.5529411764705883
Epoch:493	training loss:1.7089194059371948	 training accuracy:0.5529411764705883
Epoch:494	training loss:1.7076867818832397	 training accuracy:0.5529411764705883
Epoch:495	training loss:1.7064521312713623	 training accuracy:0.5529411764705883
Epoch:496	training loss:1.705215334892273	 training accuracy:0.5529411764705883
Epoch:497	training loss:1.7039765119552612	 training accuracy:0.5529411764705883
Epoch:498	training loss:1.702735185623169	 training accuracy:0.5529411764705883
Epoch:499	training loss:1.7014919519424438	 training accuracy:0.5529411764705883
Epoch:500	training loss:1.7002460956573486	 training accuracy:0.5529411764705883
Epoch:501	training loss:1.6989980936050415	 training accuracy:0.5529411764705883
Epoch:502	training loss:1.6977474689483643	 training accuracy:0.5529411764705883
Epoch:503	training loss:1.6964936256408691	 training accuracy:0.5529411764705883
Epoch:504	training loss:1.6952365636825562	 training accuracy:0.5529411764705883
Epoch:505	training loss:1.6939760446548462	 training accuracy:0.5529411764705883
Epoch:506	training loss:1.6927131414413452	 training accuracy:0.5529411764705883
Epoch:507	training loss:1.6914470195770264	 training accuracy:0.5529411764705883
Epoch:508	training loss:1.6901780366897583	 training accuracy:0.5529411764705883
Epoch:509	training loss:1.6889066696166992	 training accuracy:0.5529411764705883
Epoch:510	training loss:1.6876322031021118	 training accuracy:0.5529411764705883
Epoch:511	training loss:1.6863549947738647	 training accuracy:0.5529411764705883
Epoch:512	training loss:1.6850751638412476	 training accuracy:0.5529411764705883
Epoch:513	training loss:1.683793067932129	 training accuracy:0.5647058823529412
Epoch:514	training loss:1.6825083494186401	 training accuracy:0.5647058823529412
Epoch:515	training loss:1.6812210083007812	 training accuracy:0.5764705882352941
Epoch:516	training loss:1.6799311637878418	 training accuracy:0.5764705882352941
Epoch:517	training loss:1.6786384582519531	 training accuracy:0.5764705882352941
Epoch:518	training loss:1.6773433685302734	 training accuracy:0.5764705882352941
Epoch:519	training loss:1.6760449409484863	 training accuracy:0.5764705882352941
Epoch:520	training loss:1.67474365234375	 training accuracy:0.5764705882352941
Epoch:521	training loss:1.673439621925354	 training accuracy:0.5882352941176471
Epoch:522	training loss:1.6721328496932983	 training accuracy:0.5882352941176471
Epoch:523	training loss:1.670823335647583	 training accuracy:0.5882352941176471
Epoch:524	training loss:1.669511318206787	 training accuracy:0.5882352941176471
Epoch:525	training loss:1.668196439743042	 training accuracy:0.5882352941176471
Epoch:526	training loss:1.6668792963027954	 training accuracy:0.5882352941176471
Epoch:527	training loss:1.665558934211731	 training accuracy:0.5882352941176471
Epoch:528	training loss:1.664236307144165	 training accuracy:0.5882352941176471
Epoch:529	training loss:1.6629106998443604	 training accuracy:0.5882352941176471
Epoch:530	training loss:1.6615822315216064	 training accuracy:0.5882352941176471
Epoch:531	training loss:1.6602513790130615	 training accuracy:0.5882352941176471
Epoch:532	training loss:1.6589176654815674	 training accuracy:0.5882352941176471
Epoch:533	training loss:1.6575814485549927	 training accuracy:0.5882352941176471
Epoch:534	training loss:1.6562424898147583	 training accuracy:0.5882352941176471
Epoch:535	training loss:1.6549010276794434	 training accuracy:0.5882352941176471
Epoch:536	training loss:1.6535567045211792	 training accuracy:0.5882352941176471
Epoch:537	training loss:1.6522096395492554	 training accuracy:0.5882352941176471
Epoch:538	training loss:1.6508599519729614	 training accuracy:0.5882352941176471
Epoch:539	training loss:1.6495076417922974	 training accuracy:0.5882352941176471
Epoch:540	training loss:1.6481531858444214	 training accuracy:0.5882352941176471
Epoch:541	training loss:1.6467955112457275	 training accuracy:0.5882352941176471
Epoch:542	training loss:1.6454355716705322	 training accuracy:0.5882352941176471
Epoch:543	training loss:1.6440727710723877	 training accuracy:0.5882352941176471
Epoch:544	training loss:1.6427075862884521	 training accuracy:0.6
Epoch:545	training loss:1.6413397789001465	 training accuracy:0.6
Epoch:546	training loss:1.6399693489074707	 training accuracy:0.6
Epoch:547	training loss:1.6385964155197144	 training accuracy:0.6
Epoch:548	training loss:1.6372207403182983	 training accuracy:0.6
Epoch:549	training loss:1.6358425617218018	 training accuracy:0.6
Epoch:550	training loss:1.6344618797302246	 training accuracy:0.6
Epoch:551	training loss:1.6330785751342773	 training accuracy:0.6
Epoch:552	training loss:1.63169264793396	 training accuracy:0.6
Epoch:553	training loss:1.6303044557571411	 training accuracy:0.6
Epoch:554	training loss:1.6289138793945312	 training accuracy:0.6
Epoch:555	training loss:1.6275207996368408	 training accuracy:0.6
Epoch:556	training loss:1.6261247396469116	 training accuracy:0.6
Epoch:557	training loss:1.62472665309906	 training accuracy:0.6
Epoch:558	training loss:1.6233258247375488	 training accuracy:0.6
Epoch:559	training loss:1.6219227313995361	 training accuracy:0.6
Epoch:560	training loss:1.6205171346664429	 training accuracy:0.6
Epoch:561	training loss:1.6191091537475586	 training accuracy:0.6
Epoch:562	training loss:1.6176985502243042	 training accuracy:0.6
Epoch:563	training loss:1.6162855625152588	 training accuracy:0.6
Epoch:564	training loss:1.6148701906204224	 training accuracy:0.6
Epoch:565	training loss:1.613452434539795	 training accuracy:0.6
Epoch:566	training loss:1.612032413482666	 training accuracy:0.6
Epoch:567	training loss:1.610609769821167	 training accuracy:0.6
Epoch:568	training loss:1.6091846227645874	 training accuracy:0.6
Epoch:569	training loss:1.6077576875686646	 training accuracy:0.6
Epoch:570	training loss:1.6063281297683716	 training accuracy:0.6
Epoch:571	training loss:1.604896068572998	 training accuracy:0.6
Epoch:572	training loss:1.6034611463546753	 training accuracy:0.6
Epoch:573	training loss:1.6020245552062988	 training accuracy:0.6
Epoch:574	training loss:1.6005855798721313	 training accuracy:0.6
Epoch:575	training loss:1.5991438627243042	 training accuracy:0.6
Epoch:576	training loss:1.5977002382278442	 training accuracy:0.6
Epoch:577	training loss:1.5962542295455933	 training accuracy:0.6
Epoch:578	training loss:1.5948054790496826	 training accuracy:0.6235294117647059
Epoch:579	training loss:1.5933550596237183	 training accuracy:0.6235294117647059
Epoch:580	training loss:1.5919018983840942	 training accuracy:0.6235294117647059
Epoch:581	training loss:1.5904464721679688	 training accuracy:0.6235294117647059
Epoch:582	training loss:1.5889891386032104	 training accuracy:0.6235294117647059
Epoch:583	training loss:1.5875293016433716	 training accuracy:0.6235294117647059
Epoch:584	training loss:1.5860670804977417	 training accuracy:0.6235294117647059
Epoch:585	training loss:1.5846025943756104	 training accuracy:0.6235294117647059
Epoch:586	training loss:1.583135962486267	 training accuracy:0.6235294117647059
Epoch:587	training loss:1.5816673040390015	 training accuracy:0.6235294117647059
Epoch:588	training loss:1.5801961421966553	 training accuracy:0.6235294117647059
Epoch:589	training loss:1.5787227153778076	 training accuracy:0.6235294117647059
Epoch:590	training loss:1.5772470235824585	 training accuracy:0.6235294117647059
Epoch:591	training loss:1.5757694244384766	 training accuracy:0.6235294117647059
Epoch:592	training loss:1.5742889642715454	 training accuracy:0.6235294117647059
Epoch:593	training loss:1.5728065967559814	 training accuracy:0.6235294117647059
Epoch:594	training loss:1.5713220834732056	 training accuracy:0.6235294117647059
Epoch:595	training loss:1.5698354244232178	 training accuracy:0.6235294117647059
Epoch:596	training loss:1.5683465003967285	 training accuracy:0.6352941176470588
Epoch:597	training loss:1.5668551921844482	 training accuracy:0.6470588235294118
Epoch:598	training loss:1.5653619766235352	 training accuracy:0.6470588235294118
Epoch:599	training loss:1.5638664960861206	 training accuracy:0.6470588235294118
Epoch:600	training loss:1.5623687505722046	 training accuracy:0.6470588235294118
Epoch:601	training loss:1.5608690977096558	 training accuracy:0.6470588235294118
Epoch:602	training loss:1.5593671798706055	 training accuracy:0.6588235294117647
Epoch:603	training loss:1.5578628778457642	 training accuracy:0.6588235294117647
Epoch:604	training loss:1.55635666847229	 training accuracy:0.6588235294117647
Epoch:605	training loss:1.554848313331604	 training accuracy:0.6588235294117647
Epoch:606	training loss:1.553337812423706	 training accuracy:0.6588235294117647
Epoch:607	training loss:1.5518250465393066	 training accuracy:0.6588235294117647
Epoch:608	training loss:1.5503102540969849	 training accuracy:0.6588235294117647
Epoch:609	training loss:1.5487931966781616	 training accuracy:0.6588235294117647
Epoch:610	training loss:1.5472744703292847	 training accuracy:0.6588235294117647
Epoch:611	training loss:1.5457531213760376	 training accuracy:0.6705882352941176
Epoch:612	training loss:1.5442299842834473	 training accuracy:0.6705882352941176
Epoch:613	training loss:1.5427045822143555	 training accuracy:0.6705882352941176
Epoch:614	training loss:1.5411773920059204	 training accuracy:0.6823529411764706
Epoch:615	training loss:1.5396478176116943	 training accuracy:0.6823529411764706
Epoch:616	training loss:1.5381159782409668	 training accuracy:0.6823529411764706
Epoch:617	training loss:1.536582350730896	 training accuracy:0.6823529411764706
Epoch:618	training loss:1.5350465774536133	 training accuracy:0.6941176470588235
Epoch:619	training loss:1.5335087776184082	 training accuracy:0.6941176470588235
Epoch:620	training loss:1.531968593597412	 training accuracy:0.6941176470588235
Epoch:621	training loss:1.5304267406463623	 training accuracy:0.6941176470588235
Epoch:622	training loss:1.528882622718811	 training accuracy:0.6941176470588235
Epoch:623	training loss:1.527336597442627	 training accuracy:0.6941176470588235
Epoch:624	training loss:1.5257883071899414	 training accuracy:0.6941176470588235
Epoch:625	training loss:1.524238109588623	 training accuracy:0.6941176470588235
Epoch:626	training loss:1.5226861238479614	 training accuracy:0.7058823529411765
Epoch:627	training loss:1.5211317539215088	 training accuracy:0.7058823529411765
Epoch:628	training loss:1.5195752382278442	 training accuracy:0.7058823529411765
Epoch:629	training loss:1.5180168151855469	 training accuracy:0.7176470588235294
Epoch:630	training loss:1.5164567232131958	 training accuracy:0.7176470588235294
Epoch:631	training loss:1.5148943662643433	 training accuracy:0.7176470588235294
Epoch:632	training loss:1.5133297443389893	 training accuracy:0.7176470588235294
Epoch:633	training loss:1.511763334274292	 training accuracy:0.7176470588235294
Epoch:634	training loss:1.5101948976516724	 training accuracy:0.7176470588235294
Epoch:635	training loss:1.5086243152618408	 training accuracy:0.7176470588235294
Epoch:636	training loss:1.5070515871047974	 training accuracy:0.7176470588235294
Epoch:637	training loss:1.5054770708084106	 training accuracy:0.7176470588235294
Epoch:638	training loss:1.503900408744812	 training accuracy:0.7176470588235294
Epoch:639	training loss:1.5023219585418701	 training accuracy:0.7176470588235294
Epoch:640	training loss:1.5007414817810059	 training accuracy:0.7294117647058823
Epoch:641	training loss:1.4991587400436401	 training accuracy:0.7294117647058823
Epoch:642	training loss:1.4975742101669312	 training accuracy:0.7294117647058823
Epoch:643	training loss:1.4959876537322998	 training accuracy:0.7294117647058823
Epoch:644	training loss:1.4943991899490356	 training accuracy:0.7411764705882353
Epoch:645	training loss:1.4928083419799805	 training accuracy:0.7411764705882353
Epoch:646	training loss:1.4912158250808716	 training accuracy:0.7411764705882353
Epoch:647	training loss:1.4896212816238403	 training accuracy:0.7411764705882353
Epoch:648	training loss:1.4880245923995972	 training accuracy:0.7411764705882353
Epoch:649	training loss:1.4864262342453003	 training accuracy:0.7411764705882353
Epoch:650	training loss:1.484825849533081	 training accuracy:0.7411764705882353
Epoch:651	training loss:1.48322331905365	 training accuracy:0.7411764705882353
Epoch:652	training loss:1.4816186428070068	 training accuracy:0.7411764705882353
Epoch:653	training loss:1.4800124168395996	 training accuracy:0.7411764705882353
Epoch:654	training loss:1.4784040451049805	 training accuracy:0.7411764705882353
Epoch:655	training loss:1.4767934083938599	 training accuracy:0.7411764705882353
Epoch:656	training loss:1.475181221961975	 training accuracy:0.7411764705882353
Epoch:657	training loss:1.4735667705535889	 training accuracy:0.7411764705882353
Epoch:658	training loss:1.4719504117965698	 training accuracy:0.7411764705882353
Epoch:659	training loss:1.4703322649002075	 training accuracy:0.7411764705882353
Epoch:660	training loss:1.4687119722366333	 training accuracy:0.7411764705882353
Epoch:661	training loss:1.4670897722244263	 training accuracy:0.7411764705882353
Epoch:662	training loss:1.4654654264450073	 training accuracy:0.7411764705882353
Epoch:663	training loss:1.4638392925262451	 training accuracy:0.7411764705882353
Epoch:664	training loss:1.4622111320495605	 training accuracy:0.7529411764705882
Epoch:665	training loss:1.4605811834335327	 training accuracy:0.7529411764705882
Epoch:666	training loss:1.4589494466781616	 training accuracy:0.7529411764705882
Epoch:667	training loss:1.4573156833648682	 training accuracy:0.7529411764705882
Epoch:668	training loss:1.4556796550750732	 training accuracy:0.7529411764705882
Epoch:669	training loss:1.454041838645935	 training accuracy:0.7529411764705882
Epoch:670	training loss:1.4524022340774536	 training accuracy:0.7647058823529411
Epoch:671	training loss:1.4507606029510498	 training accuracy:0.7647058823529411
Epoch:672	training loss:1.4491171836853027	 training accuracy:0.7647058823529411
Epoch:673	training loss:1.4474716186523438	 training accuracy:0.7647058823529411
Epoch:674	training loss:1.4458242654800415	 training accuracy:0.7647058823529411
Epoch:675	training loss:1.4441747665405273	 training accuracy:0.7647058823529411
Epoch:676	training loss:1.44252347946167	 training accuracy:0.7647058823529411
Epoch:677	training loss:1.4408701658248901	 training accuracy:0.7647058823529411
Epoch:678	training loss:1.4392153024673462	 training accuracy:0.7647058823529411
Epoch:679	training loss:1.4375581741333008	 training accuracy:0.7647058823529411
Epoch:680	training loss:1.4358989000320435	 training accuracy:0.7647058823529411
Epoch:681	training loss:1.4342379570007324	 training accuracy:0.7764705882352941
Epoch:682	training loss:1.4325752258300781	 training accuracy:0.7764705882352941
Epoch:683	training loss:1.430910587310791	 training accuracy:0.7764705882352941
Epoch:684	training loss:1.429243803024292	 training accuracy:0.7764705882352941
Epoch:685	training loss:1.4275753498077393	 training accuracy:0.7764705882352941
Epoch:686	training loss:1.4259048700332642	 training accuracy:0.7764705882352941
Epoch:687	training loss:1.4242326021194458	 training accuracy:0.7764705882352941
Epoch:688	training loss:1.422558069229126	 training accuracy:0.7764705882352941
Epoch:689	training loss:1.4208823442459106	 training accuracy:0.7764705882352941
Epoch:690	training loss:1.4192041158676147	 training accuracy:0.7764705882352941
Epoch:691	training loss:1.4175242185592651	 training accuracy:0.7764705882352941
Epoch:692	training loss:1.4158425331115723	 training accuracy:0.7764705882352941
Epoch:693	training loss:1.414158821105957	 training accuracy:0.788235294117647
Epoch:694	training loss:1.412473201751709	 training accuracy:0.788235294117647
Epoch:695	training loss:1.4107857942581177	 training accuracy:0.788235294117647
Epoch:696	training loss:1.409096360206604	 training accuracy:0.8
Epoch:697	training loss:1.407405138015747	 training accuracy:0.8
Epoch:698	training loss:1.4057121276855469	 training accuracy:0.8
Epoch:699	training loss:1.4040169715881348	 training accuracy:0.8
Epoch:700	training loss:1.402320146560669	 training accuracy:0.8
Epoch:701	training loss:1.4006212949752808	 training accuracy:0.8
Epoch:702	training loss:1.3989207744598389	 training accuracy:0.8
Epoch:703	training loss:1.3972182273864746	 training accuracy:0.8
Epoch:704	training loss:1.3955140113830566	 training accuracy:0.8
Epoch:705	training loss:1.3938076496124268	 training accuracy:0.8
Epoch:706	training loss:1.3920996189117432	 training accuracy:0.8
Epoch:707	training loss:1.3903898000717163	 training accuracy:0.8
Epoch:708	training loss:1.388677954673767	 training accuracy:0.8
Epoch:709	training loss:1.3869644403457642	 training accuracy:0.8
Epoch:710	training loss:1.3852490186691284	 training accuracy:0.8
Epoch:711	training loss:1.3835315704345703	 training accuracy:0.8
Epoch:712	training loss:1.3818122148513794	 training accuracy:0.8
Epoch:713	training loss:1.3800913095474243	 training accuracy:0.8
Epoch:714	training loss:1.3783682584762573	 training accuracy:0.8
Epoch:715	training loss:1.3766437768936157	 training accuracy:0.8
Epoch:716	training loss:1.3749172687530518	 training accuracy:0.8
Epoch:717	training loss:1.373189091682434	 training accuracy:0.8
Epoch:718	training loss:1.3714585304260254	 training accuracy:0.8117647058823529
Epoch:719	training loss:1.3697266578674316	 training accuracy:0.8117647058823529
Epoch:720	training loss:1.367992877960205	 training accuracy:0.8117647058823529
Epoch:721	training loss:1.3662570714950562	 training accuracy:0.8235294117647058
Epoch:722	training loss:1.3645195960998535	 training accuracy:0.8235294117647058
Epoch:723	training loss:1.3627803325653076	 training accuracy:0.8705882352941177
Epoch:724	training loss:1.361039400100708	 training accuracy:0.8705882352941177
Epoch:725	training loss:1.359296441078186	 training accuracy:0.8705882352941177
Epoch:726	training loss:1.3575518131256104	 training accuracy:0.8823529411764706
Epoch:727	training loss:1.3558051586151123	 training accuracy:0.8823529411764706
Epoch:728	training loss:1.3540568351745605	 training accuracy:0.8823529411764706
Epoch:729	training loss:1.352306842803955	 training accuracy:0.8823529411764706
Epoch:730	training loss:1.3505549430847168	 training accuracy:0.8823529411764706
Epoch:731	training loss:1.3488012552261353	 training accuracy:0.8823529411764706
Epoch:732	training loss:1.3470458984375	 training accuracy:0.8823529411764706
Epoch:733	training loss:1.3452885150909424	 training accuracy:0.8823529411764706
Epoch:734	training loss:1.3435299396514893	 training accuracy:0.8823529411764706
Epoch:735	training loss:1.3417692184448242	 training accuracy:0.8823529411764706
Epoch:736	training loss:1.3400065898895264	 training accuracy:0.8823529411764706
Epoch:737	training loss:1.3382422924041748	 training accuracy:0.8823529411764706
Epoch:738	training loss:1.3364765644073486	 training accuracy:0.8823529411764706
Epoch:739	training loss:1.3347089290618896	 training accuracy:0.8823529411764706
Epoch:740	training loss:1.332939624786377	 training accuracy:0.8823529411764706
Epoch:741	training loss:1.3311686515808105	 training accuracy:0.8823529411764706
Epoch:742	training loss:1.3293957710266113	 training accuracy:0.8823529411764706
Epoch:743	training loss:1.3276214599609375	 training accuracy:0.8823529411764706
Epoch:744	training loss:1.3258451223373413	 training accuracy:0.8823529411764706
Epoch:745	training loss:1.32406747341156	 training accuracy:0.8823529411764706
Epoch:746	training loss:1.3222877979278564	 training accuracy:0.8823529411764706
Epoch:747	training loss:1.3205066919326782	 training accuracy:0.8823529411764706
Epoch:748	training loss:1.3187240362167358	 training accuracy:0.8823529411764706
Epoch:749	training loss:1.3169397115707397	 training accuracy:0.8823529411764706
Epoch:750	training loss:1.3151534795761108	 training accuracy:0.9058823529411765
Epoch:751	training loss:1.3133659362792969	 training accuracy:0.9058823529411765
Epoch:752	training loss:1.31157648563385	 training accuracy:0.9058823529411765
Epoch:753	training loss:1.3097857236862183	 training accuracy:0.9058823529411765
Epoch:754	training loss:1.3079934120178223	 training accuracy:0.9058823529411765
Epoch:755	training loss:1.306199073791504	 training accuracy:0.9058823529411765
Epoch:756	training loss:1.3044034242630005	 training accuracy:0.9058823529411765
Epoch:757	training loss:1.302606463432312	 training accuracy:0.9058823529411765
Epoch:758	training loss:1.3008074760437012	 training accuracy:0.9058823529411765
Epoch:759	training loss:1.2990070581436157	 training accuracy:0.9058823529411765
Epoch:760	training loss:1.2972049713134766	 training accuracy:0.9058823529411765
Epoch:761	training loss:1.2954015731811523	 training accuracy:0.9058823529411765
Epoch:762	training loss:1.293596625328064	 training accuracy:0.9058823529411765
Epoch:763	training loss:1.2917900085449219	 training accuracy:0.9058823529411765
Epoch:764	training loss:1.2899819612503052	 training accuracy:0.9058823529411765
Epoch:765	training loss:1.288172721862793	 training accuracy:0.9058823529411765
Epoch:766	training loss:1.286361575126648	 training accuracy:0.9058823529411765
Epoch:767	training loss:1.2845489978790283	 training accuracy:0.9058823529411765
Epoch:768	training loss:1.2827352285385132	 training accuracy:0.9058823529411765
Epoch:769	training loss:1.2809196710586548	 training accuracy:0.9058823529411765
Epoch:770	training loss:1.2791030406951904	 training accuracy:0.9058823529411765
Epoch:771	training loss:1.2772845029830933	 training accuracy:0.9058823529411765
Epoch:772	training loss:1.2754651308059692	 training accuracy:0.9058823529411765
Epoch:773	training loss:1.2736438512802124	 training accuracy:0.9058823529411765
Epoch:774	training loss:1.2718216180801392	 training accuracy:0.9058823529411765
Epoch:775	training loss:1.2699977159500122	 training accuracy:0.9058823529411765
Epoch:776	training loss:1.2681725025177002	 training accuracy:0.9058823529411765
Epoch:777	training loss:1.2663459777832031	 training accuracy:0.9058823529411765
Epoch:778	training loss:1.2645180225372314	 training accuracy:0.9058823529411765
Epoch:779	training loss:1.2626887559890747	 training accuracy:0.9058823529411765
Epoch:780	training loss:1.2608585357666016	 training accuracy:0.9058823529411765
Epoch:781	training loss:1.2590266466140747	 training accuracy:0.9058823529411765
Epoch:782	training loss:1.257193684577942	 training accuracy:0.9058823529411765
Epoch:783	training loss:1.255359172821045	 training accuracy:0.9058823529411765
Epoch:784	training loss:1.253523349761963	 training accuracy:0.9058823529411765
Epoch:785	training loss:1.2516868114471436	 training accuracy:0.9058823529411765
Epoch:786	training loss:1.2498489618301392	 training accuracy:0.9058823529411765
Epoch:787	training loss:1.2480095624923706	 training accuracy:0.9058823529411765
Epoch:788	training loss:1.246168851852417	 training accuracy:0.9058823529411765
Epoch:789	training loss:1.2443275451660156	 training accuracy:0.9058823529411765
Epoch:790	training loss:1.2424850463867188	 training accuracy:0.9058823529411765
Epoch:791	training loss:1.2406409978866577	 training accuracy:0.9058823529411765
Epoch:792	training loss:1.2387959957122803	 training accuracy:0.9058823529411765
Epoch:793	training loss:1.2369498014450073	 training accuracy:0.9058823529411765
Epoch:794	training loss:1.2351025342941284	 training accuracy:0.9058823529411765
Epoch:795	training loss:1.2332544326782227	 training accuracy:0.9058823529411765
Epoch:796	training loss:1.2314050197601318	 training accuracy:0.9058823529411765
Epoch:797	training loss:1.229554533958435	 training accuracy:0.9058823529411765
Epoch:798	training loss:1.2277032136917114	 training accuracy:0.9058823529411765
Epoch:799	training loss:1.2258508205413818	 training accuracy:0.9058823529411765
Epoch:800	training loss:1.2239973545074463	 training accuracy:0.9058823529411765
Epoch:801	training loss:1.2221429347991943	 training accuracy:0.9058823529411765
Epoch:802	training loss:1.2202876806259155	 training accuracy:0.9176470588235294
Epoch:803	training loss:1.2184314727783203	 training accuracy:0.9176470588235294
Epoch:804	training loss:1.2165743112564087	 training accuracy:0.9176470588235294
Epoch:805	training loss:1.2147160768508911	 training accuracy:0.9176470588235294
Epoch:806	training loss:1.2128572463989258	 training accuracy:0.9176470588235294
Epoch:807	training loss:1.210997462272644	 training accuracy:0.9176470588235294
Epoch:808	training loss:1.209136962890625	 training accuracy:0.9176470588235294
Epoch:809	training loss:1.207275390625	 training accuracy:0.9176470588235294
Epoch:810	training loss:1.2054131031036377	 training accuracy:0.9176470588235294
Epoch:811	training loss:1.2035499811172485	 training accuracy:0.9176470588235294
Epoch:812	training loss:1.201686143875122	 training accuracy:0.9176470588235294
Epoch:813	training loss:1.1998217105865479	 training accuracy:0.9176470588235294
Epoch:814	training loss:1.1979564428329468	 training accuracy:0.9176470588235294
Epoch:815	training loss:1.1960904598236084	 training accuracy:0.9176470588235294
Epoch:816	training loss:1.1942238807678223	 training accuracy:0.9176470588235294
Epoch:817	training loss:1.1923567056655884	 training accuracy:0.9176470588235294
Epoch:818	training loss:1.1904889345169067	 training accuracy:0.9176470588235294
Epoch:819	training loss:1.1886202096939087	 training accuracy:0.9176470588235294
Epoch:820	training loss:1.186751365661621	 training accuracy:0.9176470588235294
Epoch:821	training loss:1.1848816871643066	 training accuracy:0.9176470588235294
Epoch:822	training loss:1.1830116510391235	 training accuracy:0.9176470588235294
Epoch:823	training loss:1.1811408996582031	 training accuracy:0.9176470588235294
Epoch:824	training loss:1.1792699098587036	 training accuracy:0.9176470588235294
Epoch:825	training loss:1.1773980855941772	 training accuracy:0.9176470588235294
Epoch:826	training loss:1.1755261421203613	 training accuracy:0.9176470588235294
Epoch:827	training loss:1.1736536026000977	 training accuracy:0.9176470588235294
Epoch:828	training loss:1.1717805862426758	 training accuracy:0.9176470588235294
Epoch:829	training loss:1.1699072122573853	 training accuracy:0.9176470588235294
Epoch:830	training loss:1.1680337190628052	 training accuracy:0.9176470588235294
Epoch:831	training loss:1.1661596298217773	 training accuracy:0.9176470588235294
Epoch:832	training loss:1.1642851829528809	 training accuracy:0.9176470588235294
Epoch:833	training loss:1.1624106168746948	 training accuracy:0.9176470588235294
Epoch:834	training loss:1.1605358123779297	 training accuracy:0.9176470588235294
Epoch:835	training loss:1.1586605310440063	 training accuracy:0.9176470588235294
Epoch:836	training loss:1.1567851305007935	 training accuracy:0.9176470588235294
Epoch:837	training loss:1.154909372329712	 training accuracy:0.9176470588235294
Epoch:838	training loss:1.1530336141586304	 training accuracy:0.9176470588235294
Epoch:839	training loss:1.1511576175689697	 training accuracy:0.9176470588235294
Epoch:840	training loss:1.1492815017700195	 training accuracy:0.9176470588235294
Epoch:841	training loss:1.1474053859710693	 training accuracy:0.9176470588235294
Epoch:842	training loss:1.14552903175354	 training accuracy:0.9176470588235294
Epoch:843	training loss:1.1436526775360107	 training accuracy:0.9176470588235294
Epoch:844	training loss:1.141776442527771	 training accuracy:0.9176470588235294
Epoch:845	training loss:1.1398999691009521	 training accuracy:0.9176470588235294
Epoch:846	training loss:1.1380236148834229	 training accuracy:0.9176470588235294
Epoch:847	training loss:1.136147141456604	 training accuracy:0.9176470588235294
Epoch:848	training loss:1.1342710256576538	 training accuracy:0.9176470588235294
Epoch:849	training loss:1.1323950290679932	 training accuracy:0.9176470588235294
Epoch:850	training loss:1.130518913269043	 training accuracy:0.9176470588235294
Epoch:851	training loss:1.1286431550979614	 training accuracy:0.9176470588235294
Epoch:852	training loss:1.1267673969268799	 training accuracy:0.9176470588235294
Epoch:853	training loss:1.1248918771743774	 training accuracy:0.9176470588235294
Epoch:854	training loss:1.1230169534683228	 training accuracy:0.9176470588235294
Epoch:855	training loss:1.1211419105529785	 training accuracy:0.9176470588235294
Epoch:856	training loss:1.1192671060562134	 training accuracy:0.9176470588235294
Epoch:857	training loss:1.1173927783966064	 training accuracy:0.9176470588235294
Epoch:858	training loss:1.1155186891555786	 training accuracy:0.9176470588235294
Epoch:859	training loss:1.1136449575424194	 training accuracy:0.9176470588235294
Epoch:860	training loss:1.111771583557129	 training accuracy:0.9176470588235294
Epoch:861	training loss:1.1098989248275757	 training accuracy:0.9176470588235294
Epoch:862	training loss:1.1080266237258911	 training accuracy:0.9176470588235294
Epoch:863	training loss:1.1061546802520752	 training accuracy:0.9176470588235294
Epoch:864	training loss:1.1042832136154175	 training accuracy:0.9294117647058824
Epoch:865	training loss:1.1024123430252075	 training accuracy:0.9294117647058824
Epoch:866	training loss:1.1005419492721558	 training accuracy:0.9294117647058824
Epoch:867	training loss:1.0986721515655518	 training accuracy:0.9294117647058824
Epoch:868	training loss:1.0968031883239746	 training accuracy:0.9294117647058824
Epoch:869	training loss:1.0949349403381348	 training accuracy:0.9294117647058824
Epoch:870	training loss:1.0930671691894531	 training accuracy:0.9294117647058824
Epoch:871	training loss:1.091200351715088	 training accuracy:0.9294117647058824
Epoch:872	training loss:1.0893340110778809	 training accuracy:0.9294117647058824
Epoch:873	training loss:1.0874686241149902	 training accuracy:0.9294117647058824
Epoch:874	training loss:1.085603952407837	 training accuracy:0.9294117647058824
Epoch:875	training loss:1.0837401151657104	 training accuracy:0.9294117647058824
Epoch:876	training loss:1.0818772315979004	 training accuracy:0.9294117647058824
Epoch:877	training loss:1.0800151824951172	 training accuracy:0.9294117647058824
Epoch:878	training loss:1.0781540870666504	 training accuracy:0.9294117647058824
Epoch:879	training loss:1.076293706893921	 training accuracy:0.9294117647058824
Epoch:880	training loss:1.0744343996047974	 training accuracy:0.9294117647058824
Epoch:881	training loss:1.0725761651992798	 training accuracy:0.9294117647058824
Epoch:882	training loss:1.0707191228866577	 training accuracy:0.9294117647058824
Epoch:883	training loss:1.0688631534576416	 training accuracy:0.9294117647058824
Epoch:884	training loss:1.0670078992843628	 training accuracy:0.9294117647058824
Epoch:885	training loss:1.0651540756225586	 training accuracy:0.9294117647058824
Epoch:886	training loss:1.0633015632629395	 training accuracy:0.9294117647058824
Epoch:887	training loss:1.0614497661590576	 training accuracy:0.9294117647058824
Epoch:888	training loss:1.0595992803573608	 training accuracy:0.9294117647058824
Epoch:889	training loss:1.0577502250671387	 training accuracy:0.9294117647058824
Epoch:890	training loss:1.0559022426605225	 training accuracy:0.9294117647058824
Epoch:891	training loss:1.0540556907653809	 training accuracy:0.9294117647058824
Epoch:892	training loss:1.0522104501724243	 training accuracy:0.9294117647058824
Epoch:893	training loss:1.0503666400909424	 training accuracy:0.9294117647058824
Epoch:894	training loss:1.048524022102356	 training accuracy:0.9294117647058824
Epoch:895	training loss:1.0466828346252441	 training accuracy:0.9294117647058824
Epoch:896	training loss:1.044843077659607	 training accuracy:0.9294117647058824
Epoch:897	training loss:1.0430046319961548	 training accuracy:0.9294117647058824
Epoch:898	training loss:1.041167974472046	 training accuracy:0.9294117647058824
Epoch:899	training loss:1.039332628250122	 training accuracy:0.9294117647058824
Epoch:900	training loss:1.037498950958252	 training accuracy:0.9294117647058824
Epoch:901	training loss:1.0356669425964355	 training accuracy:0.9294117647058824
Epoch:902	training loss:1.0338363647460938	 training accuracy:0.9294117647058824
Epoch:903	training loss:1.0320075750350952	 training accuracy:0.9294117647058824
Epoch:904	training loss:1.0301802158355713	 training accuracy:0.9294117647058824
Epoch:905	training loss:1.0283547639846802	 training accuracy:0.9294117647058824
Epoch:906	training loss:1.0265308618545532	 training accuracy:0.9294117647058824
Epoch:907	training loss:1.0247087478637695	 training accuracy:0.9294117647058824
Epoch:908	training loss:1.022888422012329	 training accuracy:0.9294117647058824
Epoch:909	training loss:1.0210700035095215	 training accuracy:0.9294117647058824
Epoch:910	training loss:1.0192534923553467	 training accuracy:0.9294117647058824
Epoch:911	training loss:1.0174386501312256	 training accuracy:0.9294117647058824
Epoch:912	training loss:1.0156257152557373	 training accuracy:0.9294117647058824
Epoch:913	training loss:1.0138146877288818	 training accuracy:0.9294117647058824
Epoch:914	training loss:1.0120058059692383	 training accuracy:0.9294117647058824
Epoch:915	training loss:1.0101985931396484	 training accuracy:0.9294117647058824
Epoch:916	training loss:1.0083935260772705	 training accuracy:0.9294117647058824
Epoch:917	training loss:1.0065906047821045	 training accuracy:0.9294117647058824
Epoch:918	training loss:1.0047898292541504	 training accuracy:0.9294117647058824
Epoch:919	training loss:1.002990961074829	 training accuracy:0.9294117647058824
Epoch:920	training loss:1.0011941194534302	 training accuracy:0.9294117647058824
Epoch:921	training loss:0.9993995428085327	 training accuracy:0.9294117647058824
Epoch:922	training loss:0.9976072311401367	 training accuracy:0.9294117647058824
Epoch:923	training loss:0.9958170652389526	 training accuracy:0.9294117647058824
Epoch:924	training loss:0.9940292835235596	 training accuracy:0.9294117647058824
Epoch:925	training loss:0.9922435283660889	 training accuracy:0.9294117647058824
Epoch:926	training loss:0.9904601573944092	 training accuracy:0.9294117647058824
Epoch:927	training loss:0.9886791706085205	 training accuracy:0.9294117647058824
Epoch:928	training loss:0.9869004487991333	 training accuracy:0.9294117647058824
Epoch:929	training loss:0.9851239323616028	 training accuracy:0.9294117647058824
Epoch:930	training loss:0.9833501577377319	 training accuracy:0.9294117647058824
Epoch:931	training loss:0.981578528881073	 training accuracy:0.9294117647058824
Epoch:932	training loss:0.9798094034194946	 training accuracy:0.9294117647058824
Epoch:933	training loss:0.9780428409576416	 training accuracy:0.9294117647058824
Epoch:934	training loss:0.9762789607048035	 training accuracy:0.9294117647058824
Epoch:935	training loss:0.9745172262191772	 training accuracy:0.9294117647058824
Epoch:936	training loss:0.9727582335472107	 training accuracy:0.9294117647058824
Epoch:937	training loss:0.9710016846656799	 training accuracy:0.9294117647058824
Epoch:938	training loss:0.9692477583885193	 training accuracy:0.9294117647058824
Epoch:939	training loss:0.9674965739250183	 training accuracy:0.9294117647058824
Epoch:940	training loss:0.9657480120658875	 training accuracy:0.9294117647058824
Epoch:941	training loss:0.9640021324157715	 training accuracy:0.9294117647058824
Epoch:942	training loss:0.9622589349746704	 training accuracy:0.9294117647058824
Epoch:943	training loss:0.9605183005332947	 training accuracy:0.9294117647058824
Epoch:944	training loss:0.9587804079055786	 training accuracy:0.9294117647058824
Epoch:945	training loss:0.957045316696167	 training accuracy:0.9294117647058824
Epoch:946	training loss:0.9553132057189941	 training accuracy:0.9294117647058824
Epoch:947	training loss:0.9535835981369019	 training accuracy:0.9294117647058824
Epoch:948	training loss:0.9518570303916931	 training accuracy:0.9294117647058824
Epoch:949	training loss:0.9501332640647888	 training accuracy:0.9294117647058824
Epoch:950	training loss:0.9484124183654785	 training accuracy:0.9294117647058824
Epoch:951	training loss:0.9466944336891174	 training accuracy:0.9294117647058824
Epoch:952	training loss:0.9449794292449951	 training accuracy:0.9294117647058824
Epoch:953	training loss:0.9432674646377563	 training accuracy:0.9294117647058824
Epoch:954	training loss:0.9415583610534668	 training accuracy:0.9294117647058824
Epoch:955	training loss:0.9398522973060608	 training accuracy:0.9294117647058824
Epoch:956	training loss:0.9381493330001831	 training accuracy:0.9294117647058824
Epoch:957	training loss:0.9364492893218994	 training accuracy:0.9294117647058824
Epoch:958	training loss:0.934752345085144	 training accuracy:0.9294117647058824
Epoch:959	training loss:0.9330584406852722	 training accuracy:0.9294117647058824
Epoch:960	training loss:0.9313677549362183	 training accuracy:0.9294117647058824
Epoch:961	training loss:0.9296799898147583	 training accuracy:0.9294117647058824
Epoch:962	training loss:0.9279953837394714	 training accuracy:0.9294117647058824
Epoch:963	training loss:0.9263138771057129	 training accuracy:0.9294117647058824
Epoch:964	training loss:0.9246355891227722	 training accuracy:0.9294117647058824
Epoch:965	training loss:0.922960638999939	 training accuracy:0.9294117647058824
Epoch:966	training loss:0.9212889671325684	 training accuracy:0.9294117647058824
Epoch:967	training loss:0.919620156288147	 training accuracy:0.9294117647058824
Epoch:968	training loss:0.9179548621177673	 training accuracy:0.9294117647058824
Epoch:969	training loss:0.9162927865982056	 training accuracy:0.9411764705882353
Epoch:970	training loss:0.9146339893341064	 training accuracy:0.9411764705882353
Epoch:971	training loss:0.9129785299301147	 training accuracy:0.9411764705882353
Epoch:972	training loss:0.9113264083862305	 training accuracy:0.9411764705882353
Epoch:973	training loss:0.9096777439117432	 training accuracy:0.9411764705882353
Epoch:974	training loss:0.9080324769020081	 training accuracy:0.9411764705882353
Epoch:975	training loss:0.9063905477523804	 training accuracy:0.9411764705882353
Epoch:976	training loss:0.9047518968582153	 training accuracy:0.9411764705882353
Epoch:977	training loss:0.9031167030334473	 training accuracy:0.9411764705882353
Epoch:978	training loss:0.9014852046966553	 training accuracy:0.9411764705882353
Epoch:979	training loss:0.8998568058013916	 training accuracy:0.9529411764705882
Epoch:980	training loss:0.8982319831848145	 training accuracy:0.9529411764705882
Epoch:981	training loss:0.8966107964515686	 training accuracy:0.9529411764705882
Epoch:982	training loss:0.8949928879737854	 training accuracy:0.9529411764705882
Epoch:983	training loss:0.893378734588623	 training accuracy:0.9529411764705882
Epoch:984	training loss:0.8917677402496338	 training accuracy:0.9529411764705882
Epoch:985	training loss:0.8901605010032654	 training accuracy:0.9529411764705882
Epoch:986	training loss:0.888556718826294	 training accuracy:0.9529411764705882
Epoch:987	training loss:0.8869563341140747	 training accuracy:0.9529411764705882
Epoch:988	training loss:0.8853596448898315	 training accuracy:0.9529411764705882
Epoch:989	training loss:0.8837665319442749	 training accuracy:0.9529411764705882
Epoch:990	training loss:0.8821771144866943	 training accuracy:0.9529411764705882
Epoch:991	training loss:0.8805912733078003	 training accuracy:0.9529411764705882
Epoch:992	training loss:0.8790090084075928	 training accuracy:0.9529411764705882
Epoch:993	training loss:0.8774304986000061	 training accuracy:0.9529411764705882
Epoch:994	training loss:0.8758554458618164	 training accuracy:0.9529411764705882
Epoch:995	training loss:0.8742843866348267	 training accuracy:0.9529411764705882
Epoch:996	training loss:0.8727166652679443	 training accuracy:0.9529411764705882
Epoch:997	training loss:0.8711528778076172	 training accuracy:0.9529411764705882
Epoch:998	training loss:0.8695927858352661	 training accuracy:0.9529411764705882
Epoch:999	training loss:0.8680362701416016	 training accuracy:0.9529411764705882
Epoch:1000	training loss:0.8664833903312683	 training accuracy:0.9529411764705882
Epoch:1001	training loss:0.8652857542037964	 training accuracy:0.9529411764705882
Epoch:1002	training loss:0.8640909790992737	 training accuracy:0.9529411764705882
Epoch:1003	training loss:0.8629025220870972	 training accuracy:0.9529411764705882
Epoch:1004	training loss:0.8617186546325684	 training accuracy:0.9529411764705882
Epoch:1005	training loss:0.8605362772941589	 training accuracy:0.9529411764705882
Epoch:1006	training loss:0.8593543171882629	 training accuracy:0.9529411764705882
Epoch:1007	training loss:0.8581748008728027	 training accuracy:0.9529411764705882
Epoch:1008	training loss:0.8569985628128052	 training accuracy:0.9529411764705882
Epoch:1009	training loss:0.8558262586593628	 training accuracy:0.9529411764705882
Epoch:1010	training loss:0.8546550869941711	 training accuracy:0.9529411764705882
Epoch:1011	training loss:0.8534858226776123	 training accuracy:0.9529411764705882
Epoch:1012	training loss:0.8523189425468445	 training accuracy:0.9529411764705882
Epoch:1013	training loss:0.8511548638343811	 training accuracy:0.9529411764705882
Epoch:1014	training loss:0.8499939441680908	 training accuracy:0.9647058823529412
Epoch:1015	training loss:0.8488353490829468	 training accuracy:0.9647058823529412
Epoch:1016	training loss:0.8476771712303162	 training accuracy:0.9647058823529412
Epoch:1017	training loss:0.8465227484703064	 training accuracy:0.9647058823529412
Epoch:1018	training loss:0.8453714847564697	 training accuracy:0.9647058823529412
Epoch:1019	training loss:0.8442224860191345	 training accuracy:0.9647058823529412
Epoch:1020	training loss:0.8430762887001038	 training accuracy:0.9764705882352941
Epoch:1021	training loss:0.8419317007064819	 training accuracy:0.9764705882352941
Epoch:1022	training loss:0.8407890200614929	 training accuracy:0.9764705882352941
Epoch:1023	training loss:0.8396489024162292	 training accuracy:0.9764705882352941
Epoch:1024	training loss:0.8385117053985596	 training accuracy:0.9764705882352941
Epoch:1025	training loss:0.8373768925666809	 training accuracy:0.9764705882352941
Epoch:1026	training loss:0.8362445831298828	 training accuracy:0.9764705882352941
Epoch:1027	training loss:0.8351148366928101	 training accuracy:0.9764705882352941
Epoch:1028	training loss:0.8339868783950806	 training accuracy:0.9764705882352941
Epoch:1029	training loss:0.8328612446784973	 training accuracy:0.9764705882352941
Epoch:1030	training loss:0.8317382335662842	 training accuracy:0.9764705882352941
Epoch:1031	training loss:0.8306179046630859	 training accuracy:0.9764705882352941
Epoch:1032	training loss:0.8295004963874817	 training accuracy:0.9764705882352941
Epoch:1033	training loss:0.8283853530883789	 training accuracy:0.9764705882352941
Epoch:1034	training loss:0.8272713422775269	 training accuracy:0.9764705882352941
Epoch:1035	training loss:0.8261593580245972	 training accuracy:0.9764705882352941
Epoch:1036	training loss:0.8250505328178406	 training accuracy:0.9764705882352941
Epoch:1037	training loss:0.8239442110061646	 training accuracy:0.9764705882352941
Epoch:1038	training loss:0.8228408098220825	 training accuracy:0.9764705882352941
Epoch:1039	training loss:0.8217397928237915	 training accuracy:0.9764705882352941
Epoch:1040	training loss:0.8206400275230408	 training accuracy:0.9764705882352941
Epoch:1041	training loss:0.8195429444313049	 training accuracy:0.9764705882352941
Epoch:1042	training loss:0.8184483647346497	 training accuracy:0.9764705882352941
Epoch:1043	training loss:0.8173564672470093	 training accuracy:0.9764705882352941
Epoch:1044	training loss:0.8162667751312256	 training accuracy:0.9764705882352941
Epoch:1045	training loss:0.8151794075965881	 training accuracy:0.9764705882352941
Epoch:1046	training loss:0.8140943646430969	 training accuracy:0.9764705882352941
Epoch:1047	training loss:0.8130114674568176	 training accuracy:0.9764705882352941
Epoch:1048	training loss:0.8119306564331055	 training accuracy:0.9764705882352941
Epoch:1049	training loss:0.8108527064323425	 training accuracy:0.9764705882352941
Epoch:1050	training loss:0.8097773194313049	 training accuracy:0.9764705882352941
Epoch:1051	training loss:0.8087043762207031	 training accuracy:0.9764705882352941
Epoch:1052	training loss:0.8076332211494446	 training accuracy:0.9764705882352941
Epoch:1053	training loss:0.8065643906593323	 training accuracy:0.9764705882352941
Epoch:1054	training loss:0.8054978251457214	 training accuracy:0.9764705882352941
Epoch:1055	training loss:0.8044336438179016	 training accuracy:0.9764705882352941
Epoch:1056	training loss:0.8033728003501892	 training accuracy:0.9764705882352941
Epoch:1057	training loss:0.8023145794868469	 training accuracy:0.9764705882352941
Epoch:1058	training loss:0.8012577891349792	 training accuracy:0.9764705882352941
Epoch:1059	training loss:0.8002025485038757	 training accuracy:0.9764705882352941
Epoch:1060	training loss:0.7991498112678528	 training accuracy:0.9764705882352941
Epoch:1061	training loss:0.7981009483337402	 training accuracy:0.9764705882352941
Epoch:1062	training loss:0.7970540523529053	 training accuracy:0.9764705882352941
Epoch:1063	training loss:0.7960092425346375	 training accuracy:0.9764705882352941
Epoch:1064	training loss:0.7949656248092651	 training accuracy:0.9764705882352941
Epoch:1065	training loss:0.7939247488975525	 training accuracy:0.9764705882352941
Epoch:1066	training loss:0.79288649559021	 training accuracy:0.9764705882352941
Epoch:1067	training loss:0.7918511033058167	 training accuracy:0.9764705882352941
Epoch:1068	training loss:0.79081791639328	 training accuracy:0.9764705882352941
Epoch:1069	training loss:0.7897869348526001	 training accuracy:0.9764705882352941
Epoch:1070	training loss:0.7887578010559082	 training accuracy:0.9764705882352941
Epoch:1071	training loss:0.7877309918403625	 training accuracy:0.9764705882352941
Epoch:1072	training loss:0.7867066264152527	 training accuracy:0.9764705882352941
Epoch:1073	training loss:0.7856848239898682	 training accuracy:0.9764705882352941
Epoch:1074	training loss:0.7846657633781433	 training accuracy:0.9764705882352941
Epoch:1075	training loss:0.7836490273475647	 training accuracy:0.9764705882352941
Epoch:1076	training loss:0.7826341986656189	 training accuracy:0.9764705882352941
Epoch:1077	training loss:0.7816213369369507	 training accuracy:0.9764705882352941
Epoch:1078	training loss:0.7806105613708496	 training accuracy:0.9764705882352941
Epoch:1079	training loss:0.7796026468276978	 training accuracy:0.9764705882352941
Epoch:1080	training loss:0.7785972952842712	 training accuracy:0.9764705882352941
Epoch:1081	training loss:0.7775945663452148	 training accuracy:0.9764705882352941
Epoch:1082	training loss:0.7765932679176331	 training accuracy:0.9764705882352941
Epoch:1083	training loss:0.7755936980247498	 training accuracy:0.9764705882352941
Epoch:1084	training loss:0.7745963335037231	 training accuracy:0.9764705882352941
Epoch:1085	training loss:0.7736020684242249	 training accuracy:0.9764705882352941
Epoch:1086	training loss:0.7726110816001892	 training accuracy:0.9764705882352941
Epoch:1087	training loss:0.7716223001480103	 training accuracy:0.9764705882352941
Epoch:1088	training loss:0.7706344723701477	 training accuracy:0.9764705882352941
Epoch:1089	training loss:0.7696490287780762	 training accuracy:0.9764705882352941
Epoch:1090	training loss:0.7686659097671509	 training accuracy:0.9764705882352941
Epoch:1091	training loss:0.7676860690116882	 training accuracy:0.9764705882352941
Epoch:1092	training loss:0.7667089700698853	 training accuracy:0.9764705882352941
Epoch:1093	training loss:0.7657335996627808	 training accuracy:0.9764705882352941
Epoch:1094	training loss:0.7647594213485718	 training accuracy:0.9764705882352941
Epoch:1095	training loss:0.7637871503829956	 training accuracy:0.9764705882352941
Epoch:1096	training loss:0.7628178596496582	 training accuracy:0.9764705882352941
Epoch:1097	training loss:0.7618512511253357	 training accuracy:0.9764705882352941
Epoch:1098	training loss:0.7608869671821594	 training accuracy:0.9764705882352941
Epoch:1099	training loss:0.759924590587616	 training accuracy:0.9764705882352941
Epoch:1100	training loss:0.7589638233184814	 training accuracy:0.9764705882352941
Epoch:1101	training loss:0.7580059766769409	 training accuracy:0.9764705882352941
Epoch:1102	training loss:0.7570501565933228	 training accuracy:0.9764705882352941
Epoch:1103	training loss:0.756096363067627	 training accuracy:0.9764705882352941
Epoch:1104	training loss:0.7551449537277222	 training accuracy:0.9764705882352941
Epoch:1105	training loss:0.7541964054107666	 training accuracy:0.9764705882352941
Epoch:1106	training loss:0.7532495260238647	 training accuracy:0.9764705882352941
Epoch:1107	training loss:0.7523043155670166	 training accuracy:0.9764705882352941
Epoch:1108	training loss:0.7513614892959595	 training accuracy:0.9764705882352941
Epoch:1109	training loss:0.7504216432571411	 training accuracy:0.9764705882352941
Epoch:1110	training loss:0.7494845390319824	 training accuracy:0.9764705882352941
Epoch:1111	training loss:0.748549222946167	 training accuracy:0.9764705882352941
Epoch:1112	training loss:0.7476153373718262	 training accuracy:0.9764705882352941
Epoch:1113	training loss:0.746683657169342	 training accuracy:0.9764705882352941
Epoch:1114	training loss:0.7457542419433594	 training accuracy:0.9764705882352941
Epoch:1115	training loss:0.7448278069496155	 training accuracy:0.9764705882352941
Epoch:1116	training loss:0.7439036965370178	 training accuracy:0.9764705882352941
Epoch:1117	training loss:0.7429815530776978	 training accuracy:0.9764705882352941
Epoch:1118	training loss:0.7420608401298523	 training accuracy:0.9764705882352941
Epoch:1119	training loss:0.7411421537399292	 training accuracy:0.9764705882352941
Epoch:1120	training loss:0.740225613117218	 training accuracy:0.9764705882352941
Epoch:1121	training loss:0.7393118143081665	 training accuracy:0.9764705882352941
Epoch:1122	training loss:0.7384007573127747	 training accuracy:0.9764705882352941
Epoch:1123	training loss:0.7374919056892395	 training accuracy:0.9764705882352941
Epoch:1124	training loss:0.7365844249725342	 training accuracy:0.9764705882352941
Epoch:1125	training loss:0.7356785535812378	 training accuracy:0.9882352941176471
Epoch:1126	training loss:0.7347750067710876	 training accuracy:0.9882352941176471
Epoch:1127	training loss:0.7338742613792419	 training accuracy:0.9882352941176471
Epoch:1128	training loss:0.7329760789871216	 training accuracy:0.9882352941176471
Epoch:1129	training loss:0.7320800423622131	 training accuracy:0.9882352941176471
Epoch:1130	training loss:0.7311853170394897	 training accuracy:0.9882352941176471
Epoch:1131	training loss:0.7302919626235962	 training accuracy:0.9882352941176471
Epoch:1132	training loss:0.7294010519981384	 training accuracy:0.9882352941176471
Epoch:1133	training loss:0.7285131216049194	 training accuracy:0.9882352941176471
Epoch:1134	training loss:0.7276275157928467	 training accuracy:0.9882352941176471
Epoch:1135	training loss:0.7267435193061829	 training accuracy:0.9882352941176471
Epoch:1136	training loss:0.7258612513542175	 training accuracy:0.9882352941176471
Epoch:1137	training loss:0.7249814867973328	 training accuracy:0.9882352941176471
Epoch:1138	training loss:0.724103569984436	 training accuracy:0.9882352941176471
Epoch:1139	training loss:0.7232277393341064	 training accuracy:0.9882352941176471
Epoch:1140	training loss:0.7223544716835022	 training accuracy:0.9882352941176471
Epoch:1141	training loss:0.7214834690093994	 training accuracy:0.9882352941176471
Epoch:1142	training loss:0.7206140756607056	 training accuracy:0.9882352941176471
Epoch:1143	training loss:0.7197464108467102	 training accuracy:0.9882352941176471
Epoch:1144	training loss:0.7188809514045715	 training accuracy:0.9882352941176471
Epoch:1145	training loss:0.7180180549621582	 training accuracy:0.9882352941176471
Epoch:1146	training loss:0.717157781124115	 training accuracy:0.9882352941176471
Epoch:1147	training loss:0.7162997126579285	 training accuracy:0.9882352941176471
Epoch:1148	training loss:0.715442955493927	 training accuracy:0.9882352941176471
Epoch:1149	training loss:0.7145875096321106	 training accuracy:0.9882352941176471
Epoch:1150	training loss:0.7137341499328613	 training accuracy:0.9882352941176471
Epoch:1151	training loss:0.7128835916519165	 training accuracy:0.9882352941176471
Epoch:1152	training loss:0.7120355367660522	 training accuracy:0.9882352941176471
Epoch:1153	training loss:0.7111891508102417	 training accuracy:0.9882352941176471
Epoch:1154	training loss:0.7103437185287476	 training accuracy:0.9882352941176471
Epoch:1155	training loss:0.7095000147819519	 training accuracy:0.9882352941176471
Epoch:1156	training loss:0.7086586952209473	 training accuracy:0.9882352941176471
Epoch:1157	training loss:0.7078205347061157	 training accuracy:0.9882352941176471
Epoch:1158	training loss:0.7069845199584961	 training accuracy:0.9882352941176471
Epoch:1159	training loss:0.7061499357223511	 training accuracy:0.9882352941176471
Epoch:1160	training loss:0.7053163051605225	 training accuracy:0.9882352941176471
Epoch:1161	training loss:0.7044855356216431	 training accuracy:0.9882352941176471
Epoch:1162	training loss:0.703656792640686	 training accuracy:0.9882352941176471
Epoch:1163	training loss:0.702829897403717	 training accuracy:0.9882352941176471
Epoch:1164	training loss:0.7020055651664734	 training accuracy:0.9882352941176471
Epoch:1165	training loss:0.7011829614639282	 training accuracy:0.9882352941176471
Epoch:1166	training loss:0.7003621459007263	 training accuracy:0.9882352941176471
Epoch:1167	training loss:0.699542760848999	 training accuracy:0.9882352941176471
Epoch:1168	training loss:0.6987254619598389	 training accuracy:0.9882352941176471
Epoch:1169	training loss:0.6979108452796936	 training accuracy:0.9882352941176471
Epoch:1170	training loss:0.6970986723899841	 training accuracy:0.9882352941176471
Epoch:1171	training loss:0.6962880492210388	 training accuracy:0.9882352941176471
Epoch:1172	training loss:0.6954785585403442	 training accuracy:0.9882352941176471
Epoch:1173	training loss:0.6946707963943481	 training accuracy:0.9882352941176471
Epoch:1174	training loss:0.6938647627830505	 training accuracy:0.9882352941176471
Epoch:1175	training loss:0.693061113357544	 training accuracy:0.9882352941176471
Epoch:1176	training loss:0.692260205745697	 training accuracy:0.9882352941176471
Epoch:1177	training loss:0.691461443901062	 training accuracy:0.9882352941176471
Epoch:1178	training loss:0.69066321849823	 training accuracy:0.9882352941176471
Epoch:1179	training loss:0.6898665428161621	 training accuracy:0.9882352941176471
Epoch:1180	training loss:0.6890721321105957	 training accuracy:0.9882352941176471
Epoch:1181	training loss:0.6882805824279785	 training accuracy:0.9882352941176471
Epoch:1182	training loss:0.6874914169311523	 training accuracy:0.9882352941176471
Epoch:1183	training loss:0.6867039203643799	 training accuracy:0.9882352941176471
Epoch:1184	training loss:0.6859169602394104	 training accuracy:0.9882352941176471
Epoch:1185	training loss:0.6851319074630737	 training accuracy:0.9882352941176471
Epoch:1186	training loss:0.6843491792678833	 training accuracy:0.9882352941176471
Epoch:1187	training loss:0.6835689544677734	 training accuracy:0.9882352941176471
Epoch:1188	training loss:0.6827901005744934	 training accuracy:0.9882352941176471
Epoch:1189	training loss:0.6820130348205566	 training accuracy:0.9882352941176471
Epoch:1190	training loss:0.6812376379966736	 training accuracy:0.9882352941176471
Epoch:1191	training loss:0.6804640889167786	 training accuracy:0.9882352941176471
Epoch:1192	training loss:0.679692268371582	 training accuracy:0.9882352941176471
Epoch:1193	training loss:0.678922176361084	 training accuracy:0.9882352941176471
Epoch:1194	training loss:0.6781541705131531	 training accuracy:0.9882352941176471
Epoch:1195	training loss:0.6773881316184998	 training accuracy:0.9882352941176471
Epoch:1196	training loss:0.676624059677124	 training accuracy:0.9882352941176471
Epoch:1197	training loss:0.6758612990379333	 training accuracy:0.9882352941176471
Epoch:1198	training loss:0.6751003265380859	 training accuracy:0.9882352941176471
Epoch:1199	training loss:0.6743417978286743	 training accuracy:0.9882352941176471
Epoch:1200	training loss:0.6735854744911194	 training accuracy:0.9882352941176471
Epoch:1201	training loss:0.6728310585021973	 training accuracy:0.9882352941176471
Epoch:1202	training loss:0.6720772385597229	 training accuracy:0.9882352941176471
Epoch:1203	training loss:0.6713248491287231	 training accuracy:0.9882352941176471
Epoch:1204	training loss:0.6705743074417114	 training accuracy:0.9882352941176471
Epoch:1205	training loss:0.6698263883590698	 training accuracy:0.9882352941176471
Epoch:1206	training loss:0.6690804958343506	 training accuracy:0.9882352941176471
Epoch:1207	training loss:0.6683364510536194	 training accuracy:0.9882352941176471
Epoch:1208	training loss:0.6675931215286255	 training accuracy:0.9882352941176471
Epoch:1209	training loss:0.6668515801429749	 training accuracy:0.9882352941176471
Epoch:1210	training loss:0.666111946105957	 training accuracy:0.9882352941176471
Epoch:1211	training loss:0.6653748750686646	 training accuracy:0.9882352941176471
Epoch:1212	training loss:0.6646397113800049	 training accuracy:0.9882352941176471
Epoch:1213	training loss:0.6639060974121094	 training accuracy:0.9882352941176471
Epoch:1214	training loss:0.6631731390953064	 training accuracy:0.9882352941176471
Epoch:1215	training loss:0.6624415516853333	 training accuracy:0.9882352941176471
Epoch:1216	training loss:0.6617122888565063	 training accuracy:0.9882352941176471
Epoch:1217	training loss:0.6609852910041809	 training accuracy:0.9882352941176471
Epoch:1218	training loss:0.6602604389190674	 training accuracy:0.9882352941176471
Epoch:1219	training loss:0.6595369577407837	 training accuracy:0.9882352941176471
Epoch:1220	training loss:0.658814549446106	 training accuracy:0.9882352941176471
Epoch:1221	training loss:0.6580941677093506	 training accuracy:0.9882352941176471
Epoch:1222	training loss:0.6573753952980042	 training accuracy:0.9882352941176471
Epoch:1223	training loss:0.6566580533981323	 training accuracy:0.9882352941176471
Epoch:1224	training loss:0.6559426784515381	 training accuracy:0.9882352941176471
Epoch:1225	training loss:0.6552295088768005	 training accuracy:0.9882352941176471
Epoch:1226	training loss:0.6545173525810242	 training accuracy:0.9882352941176471
Epoch:1227	training loss:0.6538066864013672	 training accuracy:0.9882352941176471
Epoch:1228	training loss:0.6530972719192505	 training accuracy:0.9882352941176471
Epoch:1229	training loss:0.65239018201828	 training accuracy:0.9882352941176471
Epoch:1230	training loss:0.6516854166984558	 training accuracy:0.9882352941176471
Epoch:1231	training loss:0.6509817838668823	 training accuracy:0.9882352941176471
Epoch:1232	training loss:0.65027916431427	 training accuracy:0.9882352941176471
Epoch:1233	training loss:0.649578332901001	 training accuracy:0.9882352941176471
Epoch:1234	training loss:0.648878812789917	 training accuracy:0.9882352941176471
Epoch:1235	training loss:0.6481814980506897	 training accuracy:0.9882352941176471
Epoch:1236	training loss:0.647486686706543	 training accuracy:0.9882352941176471
Epoch:1237	training loss:0.6467933654785156	 training accuracy:0.9882352941176471
Epoch:1238	training loss:0.6461006999015808	 training accuracy:0.9882352941176471
Epoch:1239	training loss:0.6454089879989624	 training accuracy:0.9882352941176471
Epoch:1240	training loss:0.6447191834449768	 training accuracy:0.9882352941176471
Epoch:1241	training loss:0.6440322399139404	 training accuracy:0.9882352941176471
Epoch:1242	training loss:0.6433470845222473	 training accuracy:0.9882352941176471
Epoch:1243	training loss:0.6426628828048706	 training accuracy:0.9882352941176471
Epoch:1244	training loss:0.6419795751571655	 training accuracy:0.9882352941176471
Epoch:1245	training loss:0.6412977576255798	 training accuracy:0.9882352941176471
Epoch:1246	training loss:0.6406176686286926	 training accuracy:0.9882352941176471
Epoch:1247	training loss:0.6399396657943726	 training accuracy:0.9882352941176471
Epoch:1248	training loss:0.6392632722854614	 training accuracy:0.9882352941176471
Epoch:1249	training loss:0.6385886073112488	 training accuracy:0.9882352941176471
Epoch:1250	training loss:0.6379148364067078	 training accuracy:0.9882352941176471
Epoch:1251	training loss:0.6372422575950623	 training accuracy:0.9882352941176471
Epoch:1252	training loss:0.6365715861320496	 training accuracy:0.9882352941176471
Epoch:1253	training loss:0.6359028220176697	 training accuracy:0.9882352941176471
Epoch:1254	training loss:0.6352362036705017	 training accuracy:0.9882352941176471
Epoch:1255	training loss:0.6345710754394531	 training accuracy:0.9882352941176471
Epoch:1256	training loss:0.6339067816734314	 training accuracy:0.9882352941176471
Epoch:1257	training loss:0.6332436800003052	 training accuracy:0.9882352941176471
Epoch:1258	training loss:0.6325818300247192	 training accuracy:0.9882352941176471
Epoch:1259	training loss:0.6319225430488586	 training accuracy:0.9882352941176471
Epoch:1260	training loss:0.6312646865844727	 training accuracy:0.9882352941176471
Epoch:1261	training loss:0.630608081817627	 training accuracy:0.9882352941176471
Epoch:1262	training loss:0.6299523115158081	 training accuracy:0.9882352941176471
Epoch:1263	training loss:0.629298210144043	 training accuracy:0.9882352941176471
Epoch:1264	training loss:0.6286455392837524	 training accuracy:0.9882352941176471
Epoch:1265	training loss:0.6279945373535156	 training accuracy:0.9882352941176471
Epoch:1266	training loss:0.6273457407951355	 training accuracy:0.9882352941176471
Epoch:1267	training loss:0.6266987323760986	 training accuracy:0.9882352941176471
Epoch:1268	training loss:0.6260522603988647	 training accuracy:0.9882352941176471
Epoch:1269	training loss:0.6254069805145264	 training accuracy:0.9882352941176471
Epoch:1270	training loss:0.6247632503509521	 training accuracy:0.9882352941176471
Epoch:1271	training loss:0.6241214275360107	 training accuracy:0.9882352941176471
Epoch:1272	training loss:0.6234818696975708	 training accuracy:0.9882352941176471
Epoch:1273	training loss:0.6228433847427368	 training accuracy:0.9882352941176471
Epoch:1274	training loss:0.6222056150436401	 training accuracy:0.9882352941176471
Epoch:1275	training loss:0.6215683817863464	 training accuracy:0.9882352941176471
Epoch:1276	training loss:0.6209330558776855	 training accuracy:0.9882352941176471
Epoch:1277	training loss:0.6203001737594604	 training accuracy:0.9882352941176471
Epoch:1278	training loss:0.6196689605712891	 training accuracy:0.9882352941176471
Epoch:1279	training loss:0.6190385222434998	 training accuracy:0.9882352941176471
Epoch:1280	training loss:0.6184086203575134	 training accuracy:0.9882352941176471
Epoch:1281	training loss:0.6177809238433838	 training accuracy:0.9882352941176471
Epoch:1282	training loss:0.6171545386314392	 training accuracy:0.9882352941176471
Epoch:1283	training loss:0.6165297627449036	 training accuracy:0.9882352941176471
Epoch:1284	training loss:0.6159066557884216	 training accuracy:0.9882352941176471
Epoch:1285	training loss:0.6152845025062561	 training accuracy:0.9882352941176471
Epoch:1286	training loss:0.6146634221076965	 training accuracy:0.9882352941176471
Epoch:1287	training loss:0.6140438914299011	 training accuracy:0.9882352941176471
Epoch:1288	training loss:0.6134258508682251	 training accuracy:0.9882352941176471
Epoch:1289	training loss:0.6128095388412476	 training accuracy:0.9882352941176471
Epoch:1290	training loss:0.6121948957443237	 training accuracy:0.9882352941176471
Epoch:1291	training loss:0.6115818023681641	 training accuracy:0.9882352941176471
Epoch:1292	training loss:0.6109693646430969	 training accuracy:0.9882352941176471
Epoch:1293	training loss:0.6103578209877014	 training accuracy:0.9882352941176471
Epoch:1294	training loss:0.6097476482391357	 training accuracy:0.9882352941176471
Epoch:1295	training loss:0.6091391444206238	 training accuracy:0.9882352941176471
Epoch:1296	training loss:0.6085324287414551	 training accuracy:0.9882352941176471
Epoch:1297	training loss:0.6079273223876953	 training accuracy:0.9882352941176471
Epoch:1298	training loss:0.6073226928710938	 training accuracy:0.9882352941176471
Epoch:1299	training loss:0.6067186594009399	 training accuracy:0.9882352941176471
Epoch:1300	training loss:0.6061160564422607	 training accuracy:0.9882352941176471
Epoch:1301	training loss:0.6055160164833069	 training accuracy:0.9882352941176471
Epoch:1302	training loss:0.6049177050590515	 training accuracy:0.9882352941176471
Epoch:1303	training loss:0.604320228099823	 training accuracy:0.9882352941176471
Epoch:1304	training loss:0.6037232875823975	 training accuracy:0.9882352941176471
Epoch:1305	training loss:0.6031274795532227	 training accuracy:0.9882352941176471
Epoch:1306	training loss:0.6025336384773254	 training accuracy:0.9882352941176471
Epoch:1307	training loss:0.6019413471221924	 training accuracy:0.9882352941176471
Epoch:1308	training loss:0.6013507843017578	 training accuracy:0.9882352941176471
Epoch:1309	training loss:0.6007612347602844	 training accuracy:0.9882352941176471
Epoch:1310	training loss:0.6001726388931274	 training accuracy:0.9882352941176471
Epoch:1311	training loss:0.5995851755142212	 training accuracy:0.9882352941176471
Epoch:1312	training loss:0.5989989638328552	 training accuracy:0.9882352941176471
Epoch:1313	training loss:0.5984146595001221	 training accuracy:0.9882352941176471
Epoch:1314	training loss:0.5978313088417053	 training accuracy:0.9882352941176471
Epoch:1315	training loss:0.5972492694854736	 training accuracy:0.9882352941176471
Epoch:1316	training loss:0.5966682434082031	 training accuracy:0.9882352941176471
Epoch:1317	training loss:0.5960884094238281	 training accuracy:0.9882352941176471
Epoch:1318	training loss:0.59550940990448	 training accuracy:0.9882352941176471
Epoch:1319	training loss:0.5949320197105408	 training accuracy:0.9882352941176471
Epoch:1320	training loss:0.5943562984466553	 training accuracy:0.9882352941176471
Epoch:1321	training loss:0.5937821865081787	 training accuracy:0.9882352941176471
Epoch:1322	training loss:0.5932084321975708	 training accuracy:0.9882352941176471
Epoch:1323	training loss:0.592635452747345	 training accuracy:0.9882352941176471
Epoch:1324	training loss:0.5920636653900146	 training accuracy:0.9882352941176471
Epoch:1325	training loss:0.591494083404541	 training accuracy:0.9882352941176471
Epoch:1326	training loss:0.5909267067909241	 training accuracy:0.9882352941176471
Epoch:1327	training loss:0.5903602242469788	 training accuracy:0.9882352941176471
Epoch:1328	training loss:0.5897937417030334	 training accuracy:0.9882352941176471
Epoch:1329	training loss:0.589228093624115	 training accuracy:0.9882352941176471
Epoch:1330	training loss:0.5886643528938293	 training accuracy:0.9882352941176471
Epoch:1331	training loss:0.5881022810935974	 training accuracy:0.9882352941176471
Epoch:1332	training loss:0.5875418186187744	 training accuracy:0.9882352941176471
Epoch:1333	training loss:0.5869821310043335	 training accuracy:0.9882352941176471
Epoch:1334	training loss:0.586422860622406	 training accuracy:0.9882352941176471
Epoch:1335	training loss:0.5858644843101501	 training accuracy:0.9882352941176471
Epoch:1336	training loss:0.5853078365325928	 training accuracy:0.9882352941176471
Epoch:1337	training loss:0.5847527980804443	 training accuracy:0.9882352941176471
Epoch:1338	training loss:0.5841993689537048	 training accuracy:0.9882352941176471
Epoch:1339	training loss:0.5836471319198608	 training accuracy:0.9882352941176471
Epoch:1340	training loss:0.583095371723175	 training accuracy:0.9882352941176471
Epoch:1341	training loss:0.5825446844100952	 training accuracy:0.9882352941176471
Epoch:1342	training loss:0.5819950103759766	 training accuracy:0.9882352941176471
Epoch:1343	training loss:0.5814468860626221	 training accuracy:0.9882352941176471
Epoch:1344	training loss:0.5809005498886108	 training accuracy:0.9882352941176471
Epoch:1345	training loss:0.5803552865982056	 training accuracy:0.9882352941176471
Epoch:1346	training loss:0.579810380935669	 training accuracy:0.9882352941176471
Epoch:1347	training loss:0.5792663097381592	 training accuracy:0.9882352941176471
Epoch:1348	training loss:0.5787234306335449	 training accuracy:0.9882352941176471
Epoch:1349	training loss:0.5781823396682739	 training accuracy:0.9882352941176471
Epoch:1350	training loss:0.5776427984237671	 training accuracy:0.9882352941176471
Epoch:1351	training loss:0.5771039724349976	 training accuracy:0.9882352941176471
Epoch:1352	training loss:0.5765655040740967	 training accuracy:0.9882352941176471
Epoch:1353	training loss:0.5760284662246704	 training accuracy:0.9882352941176471
Epoch:1354	training loss:0.5754925012588501	 training accuracy:0.9882352941176471
Epoch:1355	training loss:0.5749579668045044	 training accuracy:0.9882352941176471
Epoch:1356	training loss:0.574425220489502	 training accuracy:0.9882352941176471
Epoch:1357	training loss:0.5738934874534607	 training accuracy:0.9882352941176471
Epoch:1358	training loss:0.5733621716499329	 training accuracy:0.9882352941176471
Epoch:1359	training loss:0.5728314518928528	 training accuracy:0.9882352941176471
Epoch:1360	training loss:0.5723021030426025	 training accuracy:0.9882352941176471
Epoch:1361	training loss:0.571774959564209	 training accuracy:0.9882352941176471
Epoch:1362	training loss:0.57124924659729	 training accuracy:0.9882352941176471
Epoch:1363	training loss:0.5707241296768188	 training accuracy:0.9882352941176471
Epoch:1364	training loss:0.5701994895935059	 training accuracy:0.9882352941176471
Epoch:1365	training loss:0.569675624370575	 training accuracy:0.9882352941176471
Epoch:1366	training loss:0.5691534876823425	 training accuracy:0.9882352941176471
Epoch:1367	training loss:0.5686330795288086	 training accuracy:0.9882352941176471
Epoch:1368	training loss:0.568113386631012	 training accuracy:0.9882352941176471
Epoch:1369	training loss:0.5675947070121765	 training accuracy:0.9882352941176471
Epoch:1370	training loss:0.5670762062072754	 training accuracy:0.9882352941176471
Epoch:1371	training loss:0.5665588974952698	 training accuracy:0.9882352941176471
Epoch:1372	training loss:0.5660429000854492	 training accuracy:0.9882352941176471
Epoch:1373	training loss:0.5655279159545898	 training accuracy:0.9882352941176471
Epoch:1374	training loss:0.5650140643119812	 training accuracy:0.9882352941176471
Epoch:1375	training loss:0.5645016431808472	 training accuracy:0.9882352941176471
Epoch:1376	training loss:0.5639898180961609	 training accuracy:0.9882352941176471
Epoch:1377	training loss:0.5634791851043701	 training accuracy:0.9882352941176471
Epoch:1378	training loss:0.5629695057868958	 training accuracy:0.9882352941176471
Epoch:1379	training loss:0.562461256980896	 training accuracy:0.9882352941176471
Epoch:1380	training loss:0.5619543194770813	 training accuracy:0.9882352941176471
Epoch:1381	training loss:0.5614486336708069	 training accuracy:0.9882352941176471
Epoch:1382	training loss:0.5609433650970459	 training accuracy:0.9882352941176471
Epoch:1383	training loss:0.5604383945465088	 training accuracy:0.9882352941176471
Epoch:1384	training loss:0.5599344968795776	 training accuracy:0.9882352941176471
Epoch:1385	training loss:0.5594323873519897	 training accuracy:0.9882352941176471
Epoch:1386	training loss:0.558931827545166	 training accuracy:0.9882352941176471
Epoch:1387	training loss:0.5584322810173035	 training accuracy:0.9882352941176471
Epoch:1388	training loss:0.55793297290802	 training accuracy:0.9882352941176471
Epoch:1389	training loss:0.557434618473053	 training accuracy:0.9882352941176471
Epoch:1390	training loss:0.5569371581077576	 training accuracy:0.9882352941176471
Epoch:1391	training loss:0.5564411282539368	 training accuracy:0.9882352941176471
Epoch:1392	training loss:0.5559466481208801	 training accuracy:0.9882352941176471
Epoch:1393	training loss:0.5554533004760742	 training accuracy:0.9882352941176471
Epoch:1394	training loss:0.5549600124359131	 training accuracy:0.9882352941176471
Epoch:1395	training loss:0.5544672012329102	 training accuracy:0.9882352941176471
Epoch:1396	training loss:0.5539758801460266	 training accuracy:0.9882352941176471
Epoch:1397	training loss:0.5534862875938416	 training accuracy:0.9882352941176471
Epoch:1398	training loss:0.5529981851577759	 training accuracy:0.9882352941176471
Epoch:1399	training loss:0.5525105595588684	 training accuracy:0.9882352941176471
Epoch:1400	training loss:0.5520232915878296	 training accuracy:0.9882352941176471
Epoch:1401	training loss:0.5515370965003967	 training accuracy:0.9882352941176471
Epoch:1402	training loss:0.5510517358779907	 training accuracy:0.9882352941176471
Epoch:1403	training loss:0.5505676865577698	 training accuracy:0.9882352941176471
Epoch:1404	training loss:0.5500847101211548	 training accuracy:0.9882352941176471
Epoch:1405	training loss:0.5496025681495667	 training accuracy:0.9882352941176471
Epoch:1406	training loss:0.5491211414337158	 training accuracy:0.9882352941176471
Epoch:1407	training loss:0.5486406087875366	 training accuracy:0.9882352941176471
Epoch:1408	training loss:0.5481607913970947	 training accuracy:0.9882352941176471
Epoch:1409	training loss:0.5476826429367065	 training accuracy:0.9882352941176471
Epoch:1410	training loss:0.5472061634063721	 training accuracy:0.9882352941176471
Epoch:1411	training loss:0.5467300415039062	 training accuracy:0.9882352941176471
Epoch:1412	training loss:0.5462542176246643	 training accuracy:0.9882352941176471
Epoch:1413	training loss:0.545779287815094	 training accuracy:0.9882352941176471
Epoch:1414	training loss:0.5453052520751953	 training accuracy:0.9882352941176471
Epoch:1415	training loss:0.5448324084281921	 training accuracy:0.9882352941176471
Epoch:1416	training loss:0.5443614721298218	 training accuracy:0.9882352941176471
Epoch:1417	training loss:0.5438919067382812	 training accuracy:0.9882352941176471
Epoch:1418	training loss:0.5434219837188721	 training accuracy:0.9882352941176471
Epoch:1419	training loss:0.5429521799087524	 training accuracy:0.9882352941176471
Epoch:1420	training loss:0.5424836874008179	 training accuracy:0.9882352941176471
Epoch:1421	training loss:0.5420175194740295	 training accuracy:0.9882352941176471
Epoch:1422	training loss:0.5415526032447815	 training accuracy:0.9882352941176471
Epoch:1423	training loss:0.5410882234573364	 training accuracy:0.9882352941176471
Epoch:1424	training loss:0.5406235456466675	 training accuracy:0.9882352941176471
Epoch:1425	training loss:0.5401598215103149	 training accuracy:0.9882352941176471
Epoch:1426	training loss:0.5396971106529236	 training accuracy:0.9882352941176471
Epoch:1427	training loss:0.5392361879348755	 training accuracy:0.9882352941176471
Epoch:1428	training loss:0.538776159286499	 training accuracy:0.9882352941176471
Epoch:1429	training loss:0.5383167862892151	 training accuracy:0.9882352941176471
Epoch:1430	training loss:0.537857711315155	 training accuracy:0.9882352941176471
Epoch:1431	training loss:0.5373998880386353	 training accuracy:0.9882352941176471
Epoch:1432	training loss:0.5369430184364319	 training accuracy:0.9882352941176471
Epoch:1433	training loss:0.5364868640899658	 training accuracy:0.9882352941176471
Epoch:1434	training loss:0.5360321998596191	 training accuracy:0.9882352941176471
Epoch:1435	training loss:0.5355786681175232	 training accuracy:0.9882352941176471
Epoch:1436	training loss:0.5351253747940063	 training accuracy:0.9882352941176471
Epoch:1437	training loss:0.534672737121582	 training accuracy:0.9882352941176471
Epoch:1438	training loss:0.5342209339141846	 training accuracy:0.9882352941176471
Epoch:1439	training loss:0.5337703227996826	 training accuracy:0.9882352941176471
Epoch:1440	training loss:0.5333208441734314	 training accuracy:0.9882352941176471
Epoch:1441	training loss:0.5328725576400757	 training accuracy:0.9882352941176471
Epoch:1442	training loss:0.5324243903160095	 training accuracy:0.9882352941176471
Epoch:1443	training loss:0.5319768190383911	 training accuracy:0.9882352941176471
Epoch:1444	training loss:0.5315300226211548	 training accuracy:0.9882352941176471
Epoch:1445	training loss:0.5310847163200378	 training accuracy:0.9882352941176471
Epoch:1446	training loss:0.5306408405303955	 training accuracy:0.9882352941176471
Epoch:1447	training loss:0.5301977396011353	 training accuracy:0.9882352941176471
Epoch:1448	training loss:0.5297545194625854	 training accuracy:0.9882352941176471
Epoch:1449	training loss:0.5293123722076416	 training accuracy:0.9882352941176471
Epoch:1450	training loss:0.5288714170455933	 training accuracy:0.9882352941176471
Epoch:1451	training loss:0.5284320116043091	 training accuracy:0.9882352941176471
Epoch:1452	training loss:0.5279937982559204	 training accuracy:0.9882352941176471
Epoch:1453	training loss:0.5275558233261108	 training accuracy:0.9882352941176471
Epoch:1454	training loss:0.5271179676055908	 training accuracy:0.9882352941176471
Epoch:1455	training loss:0.526680588722229	 training accuracy:0.9882352941176471
Epoch:1456	training loss:0.5262447595596313	 training accuracy:0.9882352941176471
Epoch:1457	training loss:0.525810182094574	 training accuracy:0.9882352941176471
Epoch:1458	training loss:0.5253762006759644	 training accuracy:0.9882352941176471
Epoch:1459	training loss:0.5249429941177368	 training accuracy:0.9882352941176471
Epoch:1460	training loss:0.5245102643966675	 training accuracy:0.9882352941176471
Epoch:1461	training loss:0.5240784883499146	 training accuracy:0.9882352941176471
Epoch:1462	training loss:0.5236474275588989	 training accuracy:0.9882352941176471
Epoch:1463	training loss:0.5232172608375549	 training accuracy:0.9882352941176471
Epoch:1464	training loss:0.5227881669998169	 training accuracy:0.9882352941176471
Epoch:1465	training loss:0.5223603248596191	 training accuracy:0.9882352941176471
Epoch:1466	training loss:0.52193284034729	 training accuracy:0.9882352941176471
Epoch:1467	training loss:0.52150559425354	 training accuracy:0.9882352941176471
Epoch:1468	training loss:0.5210790038108826	 training accuracy:0.9882352941176471
Epoch:1469	training loss:0.5206541419029236	 training accuracy:0.9882352941176471
Epoch:1470	training loss:0.5202309489250183	 training accuracy:0.9882352941176471
Epoch:1471	training loss:0.5198081731796265	 training accuracy:0.9882352941176471
Epoch:1472	training loss:0.5193852186203003	 training accuracy:0.9882352941176471
Epoch:1473	training loss:0.518963098526001	 training accuracy:0.9882352941176471
Epoch:1474	training loss:0.5185417532920837	 training accuracy:0.9882352941176471
Epoch:1475	training loss:0.5181215405464172	 training accuracy:0.9882352941176471
Epoch:1476	training loss:0.5177030563354492	 training accuracy:0.9882352941176471
Epoch:1477	training loss:0.5172848701477051	 training accuracy:0.9882352941176471
Epoch:1478	training loss:0.5168671607971191	 training accuracy:0.9882352941176471
Epoch:1479	training loss:0.5164497494697571	 training accuracy:0.9882352941176471
Epoch:1480	training loss:0.5160331726074219	 training accuracy:0.9882352941176471
Epoch:1481	training loss:0.5156181454658508	 training accuracy:0.9882352941176471
Epoch:1482	training loss:0.5152041912078857	 training accuracy:0.9882352941176471
Epoch:1483	training loss:0.5147910118103027	 training accuracy:0.9882352941176471
Epoch:1484	training loss:0.5143779516220093	 training accuracy:0.9882352941176471
Epoch:1485	training loss:0.513965368270874	 training accuracy:0.9882352941176471
Epoch:1486	training loss:0.5135536789894104	 training accuracy:0.9882352941176471
Epoch:1487	training loss:0.5131435394287109	 training accuracy:0.9882352941176471
Epoch:1488	training loss:0.5127343535423279	 training accuracy:0.9882352941176471
Epoch:1489	training loss:0.5123261213302612	 training accuracy:0.9882352941176471
Epoch:1490	training loss:0.5119175910949707	 training accuracy:0.9882352941176471
Epoch:1491	training loss:0.5115094184875488	 training accuracy:0.9882352941176471
Epoch:1492	training loss:0.5111021399497986	 training accuracy:0.9882352941176471
Epoch:1493	training loss:0.5106966495513916	 training accuracy:0.9882352941176471
Epoch:1494	training loss:0.5102919340133667	 training accuracy:0.9882352941176471
Epoch:1495	training loss:0.5098873972892761	 training accuracy:0.9882352941176471
Epoch:1496	training loss:0.509483277797699	 training accuracy:0.9882352941176471
Epoch:1497	training loss:0.5090802907943726	 training accuracy:0.9882352941176471
Epoch:1498	training loss:0.5086780786514282	 training accuracy:0.9882352941176471
Epoch:1499	training loss:0.5082767009735107	 training accuracy:0.9882352941176471
Epoch:1500	training loss:0.5078761577606201	 training accuracy:0.9882352941176471
Epoch:1501	training loss:0.5074768662452698	 training accuracy:0.9882352941176471
Epoch:1502	training loss:0.5070776343345642	 training accuracy:0.9882352941176471
Epoch:1503	training loss:0.5066786408424377	 training accuracy:0.9882352941176471
Epoch:1504	training loss:0.506280779838562	 training accuracy:0.9882352941176471
Epoch:1505	training loss:0.5058838129043579	 training accuracy:0.9882352941176471
Epoch:1506	training loss:0.5054888725280762	 training accuracy:0.9882352941176471
Epoch:1507	training loss:0.5050947666168213	 training accuracy:0.9882352941176471
Epoch:1508	training loss:0.5047005414962769	 training accuracy:0.9882352941176471
Epoch:1509	training loss:0.5043061971664429	 training accuracy:0.9882352941176471
Epoch:1510	training loss:0.5039125084877014	 training accuracy:0.9882352941176471
Epoch:1511	training loss:0.503520667552948	 training accuracy:0.9882352941176471
Epoch:1512	training loss:0.503129780292511	 training accuracy:0.9882352941176471
Epoch:1513	training loss:0.5027393698692322	 training accuracy:0.9882352941176471
Epoch:1514	training loss:0.5023486018180847	 training accuracy:0.9882352941176471
Epoch:1515	training loss:0.5019583106040955	 training accuracy:0.9882352941176471
Epoch:1516	training loss:0.5015692710876465	 training accuracy:0.9882352941176471
Epoch:1517	training loss:0.5011813640594482	 training accuracy:0.9882352941176471
Epoch:1518	training loss:0.5007944703102112	 training accuracy:0.9882352941176471
Epoch:1519	training loss:0.5004081130027771	 training accuracy:0.9882352941176471
Epoch:1520	training loss:0.5000215768814087	 training accuracy:0.9882352941176471
Epoch:1521	training loss:0.49963659048080444	 training accuracy:0.9882352941176471
Epoch:1522	training loss:0.4992521405220032	 training accuracy:0.9882352941176471
Epoch:1523	training loss:0.49886852502822876	 training accuracy:0.9882352941176471
Epoch:1524	training loss:0.4984860122203827	 training accuracy:0.9882352941176471
Epoch:1525	training loss:0.49810388684272766	 training accuracy:0.9882352941176471
Epoch:1526	training loss:0.497722327709198	 training accuracy:0.9882352941176471
Epoch:1527	training loss:0.4973411560058594	 training accuracy:0.9882352941176471
Epoch:1528	training loss:0.49696069955825806	 training accuracy:0.9882352941176471
Epoch:1529	training loss:0.4965816140174866	 training accuracy:0.9882352941176471
Epoch:1530	training loss:0.4962035119533539	 training accuracy:0.9882352941176471
Epoch:1531	training loss:0.49582576751708984	 training accuracy:0.9882352941176471
Epoch:1532	training loss:0.4954482913017273	 training accuracy:0.9882352941176471
Epoch:1533	training loss:0.4950714707374573	 training accuracy:0.9882352941176471
Epoch:1534	training loss:0.49469515681266785	 training accuracy:0.9882352941176471
Epoch:1535	training loss:0.4943197965621948	 training accuracy:0.9882352941176471
Epoch:1536	training loss:0.49394601583480835	 training accuracy:0.9882352941176471
Epoch:1537	training loss:0.49357283115386963	 training accuracy:0.9882352941176471
Epoch:1538	training loss:0.4931994378566742	 training accuracy:0.9882352941176471
Epoch:1539	training loss:0.4928259253501892	 training accuracy:0.9882352941176471
Epoch:1540	training loss:0.49245357513427734	 training accuracy:0.9882352941176471
Epoch:1541	training loss:0.49208295345306396	 training accuracy:0.9882352941176471
Epoch:1542	training loss:0.49171364307403564	 training accuracy:0.9882352941176471
Epoch:1543	training loss:0.49134451150894165	 training accuracy:0.9882352941176471
Epoch:1544	training loss:0.490975022315979	 training accuracy:0.9882352941176471
Epoch:1545	training loss:0.4906061291694641	 training accuracy:0.9882352941176471
Epoch:1546	training loss:0.49023836851119995	 training accuracy:0.9882352941176471
Epoch:1547	training loss:0.4898719787597656	 training accuracy:0.9882352941176471
Epoch:1548	training loss:0.4895058274269104	 training accuracy:0.9882352941176471
Epoch:1549	training loss:0.4891403913497925	 training accuracy:0.9882352941176471
Epoch:1550	training loss:0.4887750446796417	 training accuracy:0.9882352941176471
Epoch:1551	training loss:0.48841041326522827	 training accuracy:0.9882352941176471
Epoch:1552	training loss:0.4880463480949402	 training accuracy:0.9882352941176471
Epoch:1553	training loss:0.4876832365989685	 training accuracy:0.9882352941176471
Epoch:1554	training loss:0.48732101917266846	 training accuracy:0.9882352941176471
Epoch:1555	training loss:0.4869596064090729	 training accuracy:0.9882352941176471
Epoch:1556	training loss:0.48659858107566833	 training accuracy:0.9882352941176471
Epoch:1557	training loss:0.4862380027770996	 training accuracy:0.9882352941176471
Epoch:1558	training loss:0.4858778715133667	 training accuracy:0.9882352941176471
Epoch:1559	training loss:0.48551860451698303	 training accuracy:0.9882352941176471
Epoch:1560	training loss:0.485160768032074	 training accuracy:0.9882352941176471
Epoch:1561	training loss:0.48480379581451416	 training accuracy:0.9882352941176471
Epoch:1562	training loss:0.48444664478302	 training accuracy:0.9882352941176471
Epoch:1563	training loss:0.48408958315849304	 training accuracy:0.9882352941176471
Epoch:1564	training loss:0.48373329639434814	 training accuracy:0.9882352941176471
Epoch:1565	training loss:0.4833783507347107	 training accuracy:0.9882352941176471
Epoch:1566	training loss:0.48302435874938965	 training accuracy:0.9882352941176471
Epoch:1567	training loss:0.4826709032058716	 training accuracy:0.9882352941176471
Epoch:1568	training loss:0.48231714963912964	 training accuracy:0.9882352941176471
Epoch:1569	training loss:0.48196399211883545	 training accuracy:0.9882352941176471
Epoch:1570	training loss:0.48161154985427856	 training accuracy:0.9882352941176471
Epoch:1571	training loss:0.4812605679035187	 training accuracy:0.9882352941176471
Epoch:1572	training loss:0.48091039061546326	 training accuracy:0.9882352941176471
Epoch:1573	training loss:0.48056066036224365	 training accuracy:0.9882352941176471
Epoch:1574	training loss:0.4802108407020569	 training accuracy:0.9882352941176471
Epoch:1575	training loss:0.47986137866973877	 training accuracy:0.9882352941176471
Epoch:1576	training loss:0.4795130491256714	 training accuracy:0.9882352941176471
Epoch:1577	training loss:0.47916609048843384	 training accuracy:0.9882352941176471
Epoch:1578	training loss:0.4788198471069336	 training accuracy:0.9882352941176471
Epoch:1579	training loss:0.47847387194633484	 training accuracy:0.9882352941176471
Epoch:1580	training loss:0.47812801599502563	 training accuracy:0.9882352941176471
Epoch:1581	training loss:0.47778281569480896	 training accuracy:0.9882352941176471
Epoch:1582	training loss:0.4774381220340729	 training accuracy:0.9882352941176471
Epoch:1583	training loss:0.4770940840244293	 training accuracy:0.9882352941176471
Epoch:1584	training loss:0.4767509400844574	 training accuracy:0.9882352941176471
Epoch:1585	training loss:0.47640877962112427	 training accuracy:0.9882352941176471
Epoch:1586	training loss:0.47606682777404785	 training accuracy:0.9882352941176471
Epoch:1587	training loss:0.4757249355316162	 training accuracy:0.9882352941176471
Epoch:1588	training loss:0.475383460521698	 training accuracy:0.9882352941176471
Epoch:1589	training loss:0.4750434160232544	 training accuracy:0.9882352941176471
Epoch:1590	training loss:0.47470465302467346	 training accuracy:0.9882352941176471
Epoch:1591	training loss:0.4743664562702179	 training accuracy:0.9882352941176471
Epoch:1592	training loss:0.4740278124809265	 training accuracy:0.9882352941176471
Epoch:1593	training loss:0.47368961572647095	 training accuracy:0.9882352941176471
Epoch:1594	training loss:0.47335171699523926	 training accuracy:0.9882352941176471
Epoch:1595	training loss:0.47301533818244934	 training accuracy:0.9882352941176471
Epoch:1596	training loss:0.4726804494857788	 training accuracy:0.9882352941176471
Epoch:1597	training loss:0.472345769405365	 training accuracy:0.9882352941176471
Epoch:1598	training loss:0.4720107316970825	 training accuracy:0.9882352941176471
Epoch:1599	training loss:0.47167617082595825	 training accuracy:0.9882352941176471
Epoch:1600	training loss:0.47134238481521606	 training accuracy:0.9882352941176471
Epoch:1601	training loss:0.47101008892059326	 training accuracy:0.9882352941176471
Epoch:1602	training loss:0.4706784188747406	 training accuracy:0.9882352941176471
Epoch:1603	training loss:0.4703470468521118	 training accuracy:0.9882352941176471
Epoch:1604	training loss:0.4700155258178711	 training accuracy:0.9882352941176471
Epoch:1605	training loss:0.46968454122543335	 training accuracy:0.9882352941176471
Epoch:1606	training loss:0.4693542718887329	 training accuracy:0.9882352941176471
Epoch:1607	training loss:0.46902501583099365	 training accuracy:0.9882352941176471
Epoch:1608	training loss:0.4686964750289917	 training accuracy:0.9882352941176471
Epoch:1609	training loss:0.46836864948272705	 training accuracy:0.9882352941176471
Epoch:1610	training loss:0.46804070472717285	 training accuracy:0.9882352941176471
Epoch:1611	training loss:0.4677131772041321	 training accuracy:0.9882352941176471
Epoch:1612	training loss:0.4673863649368286	 training accuracy:0.9882352941176471
Epoch:1613	training loss:0.46706053614616394	 training accuracy:0.9882352941176471
Epoch:1614	training loss:0.4667357802391052	 training accuracy:0.9882352941176471
Epoch:1615	training loss:0.4664112329483032	 training accuracy:0.9882352941176471
Epoch:1616	training loss:0.4660869240760803	 training accuracy:0.9882352941176471
Epoch:1617	training loss:0.465763121843338	 training accuracy:0.9882352941176471
Epoch:1618	training loss:0.4654400944709778	 training accuracy:0.9882352941176471
Epoch:1619	training loss:0.46511828899383545	 training accuracy:0.9882352941176471
Epoch:1620	training loss:0.4647969603538513	 training accuracy:0.9882352941176471
Epoch:1621	training loss:0.4644760489463806	 training accuracy:0.9882352941176471
Epoch:1622	training loss:0.4641548991203308	 training accuracy:0.9882352941176471
Epoch:1623	training loss:0.463834285736084	 training accuracy:0.9882352941176471
Epoch:1624	training loss:0.4635143280029297	 training accuracy:0.9882352941176471
Epoch:1625	training loss:0.4631952941417694	 training accuracy:0.9882352941176471
Epoch:1626	training loss:0.4628772437572479	 training accuracy:0.9882352941176471
Epoch:1627	training loss:0.46256017684936523	 training accuracy:0.9882352941176471
Epoch:1628	training loss:0.4622427821159363	 training accuracy:0.9882352941176471
Epoch:1629	training loss:0.46192556619644165	 training accuracy:0.9882352941176471
Epoch:1630	training loss:0.4616091847419739	 training accuracy:0.9882352941176471
Epoch:1631	training loss:0.4612938463687897	 training accuracy:0.9882352941176471
Epoch:1632	training loss:0.4609795808792114	 training accuracy:0.9882352941176471
Epoch:1633	training loss:0.4606660306453705	 training accuracy:0.9882352941176471
Epoch:1634	training loss:0.46035170555114746	 training accuracy:0.9882352941176471
Epoch:1635	training loss:0.46003711223602295	 training accuracy:0.9882352941176471
Epoch:1636	training loss:0.4597238004207611	 training accuracy:0.9882352941176471
Epoch:1637	training loss:0.4594118595123291	 training accuracy:0.9882352941176471
Epoch:1638	training loss:0.45910078287124634	 training accuracy:0.9882352941176471
Epoch:1639	training loss:0.4587896168231964	 training accuracy:0.9882352941176471
Epoch:1640	training loss:0.45847806334495544	 training accuracy:0.9882352941176471
Epoch:1641	training loss:0.45816805958747864	 training accuracy:0.9882352941176471
Epoch:1642	training loss:0.45785844326019287	 training accuracy:0.9882352941176471
Epoch:1643	training loss:0.4575490653514862	 training accuracy:0.9882352941176471
Epoch:1644	training loss:0.4572407603263855	 training accuracy:0.9882352941176471
Epoch:1645	training loss:0.45693302154541016	 training accuracy:0.9882352941176471
Epoch:1646	training loss:0.45662572979927063	 training accuracy:0.9882352941176471
Epoch:1647	training loss:0.45631882548332214	 training accuracy:0.9882352941176471
Epoch:1648	training loss:0.45601218938827515	 training accuracy:0.9882352941176471
Epoch:1649	training loss:0.45570650696754456	 training accuracy:0.9882352941176471
Epoch:1650	training loss:0.45540207624435425	 training accuracy:0.9882352941176471
Epoch:1651	training loss:0.45509806275367737	 training accuracy:0.9882352941176471
Epoch:1652	training loss:0.4547940492630005	 training accuracy:0.9882352941176471
Epoch:1653	training loss:0.45449018478393555	 training accuracy:0.9882352941176471
Epoch:1654	training loss:0.45418620109558105	 training accuracy:0.9882352941176471
Epoch:1655	training loss:0.4538835883140564	 training accuracy:0.9882352941176471
Epoch:1656	training loss:0.4535820484161377	 training accuracy:0.9882352941176471
Epoch:1657	training loss:0.453281044960022	 training accuracy:0.9882352941176471
Epoch:1658	training loss:0.45297959446907043	 training accuracy:0.9882352941176471
Epoch:1659	training loss:0.45267820358276367	 training accuracy:0.9882352941176471
Epoch:1660	training loss:0.4523772895336151	 training accuracy:0.9882352941176471
Epoch:1661	training loss:0.4520782232284546	 training accuracy:0.9882352941176471
Epoch:1662	training loss:0.45178014039993286	 training accuracy:0.9882352941176471
Epoch:1663	training loss:0.45148202776908875	 training accuracy:0.9882352941176471
Epoch:1664	training loss:0.451183557510376	 training accuracy:0.9882352941176471
Epoch:1665	training loss:0.4508855938911438	 training accuracy:0.9882352941176471
Epoch:1666	training loss:0.450588583946228	 training accuracy:0.9882352941176471
Epoch:1667	training loss:0.45029252767562866	 training accuracy:0.9882352941176471
Epoch:1668	training loss:0.4499971270561218	 training accuracy:0.9882352941176471
Epoch:1669	training loss:0.4497021436691284	 training accuracy:0.9882352941176471
Epoch:1670	training loss:0.4494071900844574	 training accuracy:0.9882352941176471
Epoch:1671	training loss:0.4491121768951416	 training accuracy:0.9882352941176471
Epoch:1672	training loss:0.4488181471824646	 training accuracy:0.9882352941176471
Epoch:1673	training loss:0.44852495193481445	 training accuracy:0.9882352941176471
Epoch:1674	training loss:0.44823259115219116	 training accuracy:0.9882352941176471
Epoch:1675	training loss:0.4479406177997589	 training accuracy:0.9882352941176471
Epoch:1676	training loss:0.4476487636566162	 training accuracy:0.9882352941176471
Epoch:1677	training loss:0.447357177734375	 training accuracy:0.9882352941176471
Epoch:1678	training loss:0.44706571102142334	 training accuracy:0.9882352941176471
Epoch:1679	training loss:0.4467753767967224	 training accuracy:0.9882352941176471
Epoch:1680	training loss:0.44648581743240356	 training accuracy:0.9882352941176471
Epoch:1681	training loss:0.44619691371917725	 training accuracy:0.9882352941176471
Epoch:1682	training loss:0.4459075927734375	 training accuracy:0.9882352941176471
Epoch:1683	training loss:0.44561856985092163	 training accuracy:0.9882352941176471
Epoch:1684	training loss:0.44533026218414307	 training accuracy:0.9882352941176471
Epoch:1685	training loss:0.4450429379940033	 training accuracy:0.9882352941176471
Epoch:1686	training loss:0.44475680589675903	 training accuracy:0.9882352941176471
Epoch:1687	training loss:0.4444712996482849	 training accuracy:0.9882352941176471
Epoch:1688	training loss:0.4441848397254944	 training accuracy:0.9882352941176471
Epoch:1689	training loss:0.4438990354537964	 training accuracy:0.9882352941176471
Epoch:1690	training loss:0.4436138868331909	 training accuracy:0.9882352941176471
Epoch:1691	training loss:0.4433298707008362	 training accuracy:0.9882352941176471
Epoch:1692	training loss:0.443046510219574	 training accuracy:0.9882352941176471
Epoch:1693	training loss:0.44276317954063416	 training accuracy:0.9882352941176471
Epoch:1694	training loss:0.44247967004776	 training accuracy:0.9882352941176471
Epoch:1695	training loss:0.4421965181827545	 training accuracy:0.9882352941176471
Epoch:1696	training loss:0.44191431999206543	 training accuracy:0.9882352941176471
Epoch:1697	training loss:0.4416329264640808	 training accuracy:0.9882352941176471
Epoch:1698	training loss:0.4413520097732544	 training accuracy:0.9882352941176471
Epoch:1699	training loss:0.4410715103149414	 training accuracy:0.9882352941176471
Epoch:1700	training loss:0.4407910108566284	 training accuracy:0.9882352941176471
Epoch:1701	training loss:0.44051122665405273	 training accuracy:0.9882352941176471
Epoch:1702	training loss:0.4402320086956024	 training accuracy:0.9882352941176471
Epoch:1703	training loss:0.43995344638824463	 training accuracy:0.9882352941176471
Epoch:1704	training loss:0.43967577815055847	 training accuracy:0.9882352941176471
Epoch:1705	training loss:0.4393985867500305	 training accuracy:0.9882352941176471
Epoch:1706	training loss:0.43912121653556824	 training accuracy:0.9882352941176471
Epoch:1707	training loss:0.4388440251350403	 training accuracy:0.9882352941176471
Epoch:1708	training loss:0.43856728076934814	 training accuracy:0.9882352941176471
Epoch:1709	training loss:0.4382917881011963	 training accuracy:0.9882352941176471
Epoch:1710	training loss:0.4380166232585907	 training accuracy:0.9882352941176471
Epoch:1711	training loss:0.43774181604385376	 training accuracy:0.9882352941176471
Epoch:1712	training loss:0.43746697902679443	 training accuracy:0.9882352941176471
Epoch:1713	training loss:0.43719246983528137	 training accuracy:0.9882352941176471
Epoch:1714	training loss:0.43691831827163696	 training accuracy:0.9882352941176471
Epoch:1715	training loss:0.4366450011730194	 training accuracy:0.9882352941176471
Epoch:1716	training loss:0.4363727867603302	 training accuracy:0.9882352941176471
Epoch:1717	training loss:0.43610119819641113	 training accuracy:0.9882352941176471
Epoch:1718	training loss:0.43582937121391296	 training accuracy:0.9882352941176471
Epoch:1719	training loss:0.4355572462081909	 training accuracy:0.9882352941176471
Epoch:1720	training loss:0.4352858066558838	 training accuracy:0.9882352941176471
Epoch:1721	training loss:0.4350159168243408	 training accuracy:0.9882352941176471
Epoch:1722	training loss:0.43474698066711426	 training accuracy:0.9882352941176471
Epoch:1723	training loss:0.43447819352149963	 training accuracy:0.9882352941176471
Epoch:1724	training loss:0.4342089891433716	 training accuracy:0.9882352941176471
Epoch:1725	training loss:0.43393993377685547	 training accuracy:0.9882352941176471
Epoch:1726	training loss:0.4336715340614319	 training accuracy:0.9882352941176471
Epoch:1727	training loss:0.43340402841567993	 training accuracy:0.9882352941176471
Epoch:1728	training loss:0.4331371784210205	 training accuracy:0.9882352941176471
Epoch:1729	training loss:0.43287092447280884	 training accuracy:0.9882352941176471
Epoch:1730	training loss:0.43260449171066284	 training accuracy:0.9882352941176471
Epoch:1731	training loss:0.4323384165763855	 training accuracy:0.9882352941176471
Epoch:1732	training loss:0.43207263946533203	 training accuracy:0.9882352941176471
Epoch:1733	training loss:0.43180757761001587	 training accuracy:0.9882352941176471
Epoch:1734	training loss:0.43154311180114746	 training accuracy:0.9882352941176471
Epoch:1735	training loss:0.4312793016433716	 training accuracy:0.9882352941176471
Epoch:1736	training loss:0.4310154318809509	 training accuracy:0.9882352941176471
Epoch:1737	training loss:0.43075186014175415	 training accuracy:0.9882352941176471
Epoch:1738	training loss:0.430488646030426	 training accuracy:0.9882352941176471
Epoch:1739	training loss:0.4302263855934143	 training accuracy:0.9882352941176471
Epoch:1740	training loss:0.4299653172492981	 training accuracy:0.9882352941176471
Epoch:1741	training loss:0.4297042787075043	 training accuracy:0.9882352941176471
Epoch:1742	training loss:0.42944300174713135	 training accuracy:0.9882352941176471
Epoch:1743	training loss:0.42918169498443604	 training accuracy:0.9882352941176471
Epoch:1744	training loss:0.4289208650588989	 training accuracy:0.9882352941176471
Epoch:1745	training loss:0.4286612272262573	 training accuracy:0.9882352941176471
Epoch:1746	training loss:0.42840278148651123	 training accuracy:0.9882352941176471
Epoch:1747	training loss:0.42814427614212036	 training accuracy:0.9882352941176471
Epoch:1748	training loss:0.42788541316986084	 training accuracy:0.9882352941176471
Epoch:1749	training loss:0.42762696743011475	 training accuracy:0.9882352941176471
Epoch:1750	training loss:0.42736899852752686	 training accuracy:0.9882352941176471
Epoch:1751	training loss:0.4271119236946106	 training accuracy:0.9882352941176471
Epoch:1752	training loss:0.42685574293136597	 training accuracy:0.9882352941176471
Epoch:1753	training loss:0.4266000986099243	 training accuracy:0.9882352941176471
Epoch:1754	training loss:0.426343709230423	 training accuracy:0.9882352941176471
Epoch:1755	training loss:0.42608723044395447	 training accuracy:0.9882352941176471
Epoch:1756	training loss:0.4258318543434143	 training accuracy:0.9882352941176471
Epoch:1757	training loss:0.4255777597427368	 training accuracy:0.9882352941176471
Epoch:1758	training loss:0.42532455921173096	 training accuracy:0.9882352941176471
Epoch:1759	training loss:0.4250712990760803	 training accuracy:0.9882352941176471
Epoch:1760	training loss:0.42481744289398193	 training accuracy:0.9882352941176471
Epoch:1761	training loss:0.4245643615722656	 training accuracy:0.9882352941176471
Epoch:1762	training loss:0.42431166768074036	 training accuracy:0.9882352941176471
Epoch:1763	training loss:0.4240599274635315	 training accuracy:0.9882352941176471
Epoch:1764	training loss:0.4238082766532898	 training accuracy:0.9882352941176471
Epoch:1765	training loss:0.423556923866272	 training accuracy:0.9882352941176471
Epoch:1766	training loss:0.42330557107925415	 training accuracy:0.9882352941176471
Epoch:1767	training loss:0.42305490374565125	 training accuracy:0.9882352941176471
Epoch:1768	training loss:0.422804594039917	 training accuracy:0.9882352941176471
Epoch:1769	training loss:0.42255473136901855	 training accuracy:0.9882352941176471
Epoch:1770	training loss:0.42230573296546936	 training accuracy:0.9882352941176471
Epoch:1771	training loss:0.4220573306083679	 training accuracy:0.9882352941176471
Epoch:1772	training loss:0.4218086302280426	 training accuracy:0.9882352941176471
Epoch:1773	training loss:0.42156025767326355	 training accuracy:0.9882352941176471
Epoch:1774	training loss:0.4213120937347412	 training accuracy:0.9882352941176471
Epoch:1775	training loss:0.4210646450519562	 training accuracy:0.9882352941176471
Epoch:1776	training loss:0.4208185374736786	 training accuracy:0.9882352941176471
Epoch:1777	training loss:0.4205727279186249	 training accuracy:0.9882352941176471
Epoch:1778	training loss:0.4203265607357025	 training accuracy:0.9882352941176471
Epoch:1779	training loss:0.42007988691329956	 training accuracy:0.9882352941176471
Epoch:1780	training loss:0.41983404755592346	 training accuracy:0.9882352941176471
Epoch:1781	training loss:0.4195898175239563	 training accuracy:0.9882352941176471
Epoch:1782	training loss:0.41934627294540405	 training accuracy:0.9882352941176471
Epoch:1783	training loss:0.41910243034362793	 training accuracy:0.9882352941176471
Epoch:1784	training loss:0.418858140707016	 training accuracy:0.9882352941176471
Epoch:1785	training loss:0.4186142683029175	 training accuracy:0.9882352941176471
Epoch:1786	training loss:0.4183712601661682	 training accuracy:0.9882352941176471
Epoch:1787	training loss:0.4181293547153473	 training accuracy:0.9882352941176471
Epoch:1788	training loss:0.4178876280784607	 training accuracy:0.9882352941176471
Epoch:1789	training loss:0.4176461100578308	 training accuracy:0.9882352941176471
Epoch:1790	training loss:0.4174043536186218	 training accuracy:0.9882352941176471
Epoch:1791	training loss:0.41716301441192627	 training accuracy:0.9882352941176471
Epoch:1792	training loss:0.4169222414493561	 training accuracy:0.9882352941176471
Epoch:1793	training loss:0.41668206453323364	 training accuracy:0.9882352941176471
Epoch:1794	training loss:0.4164425730705261	 training accuracy:0.9882352941176471
Epoch:1795	training loss:0.4162037670612335	 training accuracy:0.9882352941176471
Epoch:1796	training loss:0.4159649610519409	 training accuracy:0.9882352941176471
Epoch:1797	training loss:0.4157260060310364	 training accuracy:0.9882352941176471
Epoch:1798	training loss:0.41548725962638855	 training accuracy:0.9882352941176471
Epoch:1799	training loss:0.41524946689605713	 training accuracy:0.9882352941176471
Epoch:1800	training loss:0.4150121510028839	 training accuracy:0.9882352941176471
Epoch:1801	training loss:0.4147755205631256	 training accuracy:0.9882352941176471
Epoch:1802	training loss:0.4145386219024658	 training accuracy:0.9882352941176471
Epoch:1803	training loss:0.414301335811615	 training accuracy:0.9882352941176471
Epoch:1804	training loss:0.4140644371509552	 training accuracy:0.9882352941176471
Epoch:1805	training loss:0.4138285517692566	 training accuracy:0.9882352941176471
Epoch:1806	training loss:0.41359397768974304	 training accuracy:0.9882352941176471
Epoch:1807	training loss:0.41335970163345337	 training accuracy:0.9882352941176471
Epoch:1808	training loss:0.4131247401237488	 training accuracy:0.9882352941176471
Epoch:1809	training loss:0.41289013624191284	 training accuracy:0.9882352941176471
Epoch:1810	training loss:0.41265612840652466	 training accuracy:0.9882352941176471
Epoch:1811	training loss:0.41242295503616333	 training accuracy:0.9882352941176471
Epoch:1812	training loss:0.4121907651424408	 training accuracy:0.9882352941176471
Epoch:1813	training loss:0.41195857524871826	 training accuracy:0.9882352941176471
Epoch:1814	training loss:0.411726176738739	 training accuracy:0.9882352941176471
Epoch:1815	training loss:0.41149377822875977	 training accuracy:0.9882352941176471
Epoch:1816	training loss:0.41126203536987305	 training accuracy:0.9882352941176471
Epoch:1817	training loss:0.41103124618530273	 training accuracy:0.9882352941176471
Epoch:1818	training loss:0.41080087423324585	 training accuracy:0.9882352941176471
Epoch:1819	training loss:0.4105706214904785	 training accuracy:0.9882352941176471
Epoch:1820	training loss:0.41034018993377686	 training accuracy:0.9882352941176471
Epoch:1821	training loss:0.41011035442352295	 training accuracy:0.9882352941176471
Epoch:1822	training loss:0.40988051891326904	 training accuracy:0.9882352941176471
Epoch:1823	training loss:0.4096512794494629	 training accuracy:0.9882352941176471
Epoch:1824	training loss:0.4094228148460388	 training accuracy:0.9882352941176471
Epoch:1825	training loss:0.4091947078704834	 training accuracy:0.9882352941176471
Epoch:1826	training loss:0.4089664816856384	 training accuracy:0.9882352941176471
Epoch:1827	training loss:0.40873825550079346	 training accuracy:0.9882352941176471
Epoch:1828	training loss:0.4085104465484619	 training accuracy:0.9882352941176471
Epoch:1829	training loss:0.4082837700843811	 training accuracy:0.9882352941176471
Epoch:1830	training loss:0.40805816650390625	 training accuracy:0.9882352941176471
Epoch:1831	training loss:0.40783244371414185	 training accuracy:0.9882352941176471
Epoch:1832	training loss:0.4076061248779297	 training accuracy:0.9882352941176471
Epoch:1833	training loss:0.4073801040649414	 training accuracy:0.9882352941176471
Epoch:1834	training loss:0.40715450048446655	 training accuracy:0.9882352941176471
Epoch:1835	training loss:0.4069296419620514	 training accuracy:0.9882352941176471
Epoch:1836	training loss:0.40670573711395264	 training accuracy:0.9882352941176471
Epoch:1837	training loss:0.40648216009140015	 training accuracy:0.9882352941176471
Epoch:1838	training loss:0.4062582850456238	 training accuracy:0.9882352941176471
Epoch:1839	training loss:0.40603411197662354	 training accuracy:0.9882352941176471
Epoch:1840	training loss:0.4058106541633606	 training accuracy:0.9882352941176471
Epoch:1841	training loss:0.4055883586406708	 training accuracy:0.9882352941176471
Epoch:1842	training loss:0.4053668975830078	 training accuracy:0.9882352941176471
Epoch:1843	training loss:0.4051455855369568	 training accuracy:0.9882352941176471
Epoch:1844	training loss:0.4049237370491028	 training accuracy:0.9882352941176471
Epoch:1845	training loss:0.4047018885612488	 training accuracy:0.9882352941176471
Epoch:1846	training loss:0.404480516910553	 training accuracy:0.9882352941176471
Epoch:1847	training loss:0.40426015853881836	 training accuracy:0.9882352941176471
Epoch:1848	training loss:0.40404051542282104	 training accuracy:0.9882352941176471
Epoch:1849	training loss:0.4038211703300476	 training accuracy:0.9882352941176471
Epoch:1850	training loss:0.4036012589931488	 training accuracy:0.9882352941176471
Epoch:1851	training loss:0.40338149666786194	 training accuracy:0.9882352941176471
Epoch:1852	training loss:0.40316227078437805	 training accuracy:0.9882352941176471
Epoch:1853	training loss:0.4029436707496643	 training accuracy:0.9882352941176471
Epoch:1854	training loss:0.4027255177497864	 training accuracy:0.9882352941176471
Epoch:1855	training loss:0.4025075435638428	 training accuracy:0.9882352941176471
Epoch:1856	training loss:0.40228942036628723	 training accuracy:0.9882352941176471
Epoch:1857	training loss:0.40207186341285706	 training accuracy:0.9882352941176471
Epoch:1858	training loss:0.40185463428497314	 training accuracy:0.9882352941176471
Epoch:1859	training loss:0.4016380310058594	 training accuracy:0.9882352941176471
Epoch:1860	training loss:0.4014221131801605	 training accuracy:1.0
Epoch:1861	training loss:0.40120643377304077	 training accuracy:1.0
Epoch:1862	training loss:0.40099063515663147	 training accuracy:1.0
Epoch:1863	training loss:0.40077489614486694	 training accuracy:1.0
Epoch:1864	training loss:0.4005593955516815	 training accuracy:1.0
Epoch:1865	training loss:0.4003447890281677	 training accuracy:1.0
Epoch:1866	training loss:0.40013134479522705	 training accuracy:1.0
Epoch:1867	training loss:0.39991825819015503	 training accuracy:1.0
Epoch:1868	training loss:0.39970457553863525	 training accuracy:1.0
Epoch:1869	training loss:0.39949071407318115	 training accuracy:1.0
Epoch:1870	training loss:0.39927756786346436	 training accuracy:1.0
Epoch:1871	training loss:0.3990654945373535	 training accuracy:1.0
Epoch:1872	training loss:0.39885416626930237	 training accuracy:1.0
Epoch:1873	training loss:0.39864248037338257	 training accuracy:1.0
Epoch:1874	training loss:0.39843010902404785	 training accuracy:1.0
Epoch:1875	training loss:0.3982178568840027	 training accuracy:1.0
Epoch:1876	training loss:0.39800649881362915	 training accuracy:1.0
Epoch:1877	training loss:0.3977959156036377	 training accuracy:1.0
Epoch:1878	training loss:0.3975856304168701	 training accuracy:1.0
Epoch:1879	training loss:0.39737558364868164	 training accuracy:1.0
Epoch:1880	training loss:0.3971651792526245	 training accuracy:1.0
Epoch:1881	training loss:0.39695560932159424	 training accuracy:1.0
Epoch:1882	training loss:0.3967464566230774	 training accuracy:1.0
Epoch:1883	training loss:0.39653778076171875	 training accuracy:1.0
Epoch:1884	training loss:0.3963295817375183	 training accuracy:1.0
Epoch:1885	training loss:0.3961217403411865	 training accuracy:1.0
Epoch:1886	training loss:0.39591389894485474	 training accuracy:1.0
Epoch:1887	training loss:0.39570584893226624	 training accuracy:1.0
Epoch:1888	training loss:0.3954980671405792	 training accuracy:1.0
Epoch:1889	training loss:0.39529138803482056	 training accuracy:1.0
Epoch:1890	training loss:0.39508527517318726	 training accuracy:1.0
Epoch:1891	training loss:0.39487916231155396	 training accuracy:1.0
Epoch:1892	training loss:0.39467284083366394	 training accuracy:1.0
Epoch:1893	training loss:0.3944668769836426	 training accuracy:1.0
Epoch:1894	training loss:0.3942610025405884	 training accuracy:1.0
Epoch:1895	training loss:0.3940553665161133	 training accuracy:1.0
Epoch:1896	training loss:0.3938509225845337	 training accuracy:1.0
Epoch:1897	training loss:0.39364731311798096	 training accuracy:1.0
Epoch:1898	training loss:0.3934430778026581	 training accuracy:1.0
Epoch:1899	training loss:0.393238365650177	 training accuracy:1.0
Epoch:1900	training loss:0.3930342495441437	 training accuracy:1.0
Epoch:1901	training loss:0.3928314447402954	 training accuracy:1.0
Epoch:1902	training loss:0.3926294445991516	 training accuracy:1.0
Epoch:1903	training loss:0.3924274444580078	 training accuracy:1.0
Epoch:1904	training loss:0.39222484827041626	 training accuracy:1.0
Epoch:1905	training loss:0.3920223116874695	 training accuracy:1.0
Epoch:1906	training loss:0.3918202519416809	 training accuracy:1.0
Epoch:1907	training loss:0.39161932468414307	 training accuracy:1.0
Epoch:1908	training loss:0.3914185166358948	 training accuracy:1.0
Epoch:1909	training loss:0.3912176191806793	 training accuracy:1.0
Epoch:1910	training loss:0.3910166621208191	 training accuracy:1.0
Epoch:1911	training loss:0.3908160924911499	 training accuracy:1.0
Epoch:1912	training loss:0.3906157612800598	 training accuracy:1.0
Epoch:1913	training loss:0.3904160261154175	 training accuracy:1.0
Epoch:1914	training loss:0.39021676778793335	 training accuracy:1.0
Epoch:1915	training loss:0.3900178074836731	 training accuracy:1.0
Epoch:1916	training loss:0.3898189961910248	 training accuracy:1.0
Epoch:1917	training loss:0.3896201252937317	 training accuracy:1.0
Epoch:1918	training loss:0.38942164182662964	 training accuracy:1.0
Epoch:1919	training loss:0.389223575592041	 training accuracy:1.0
Epoch:1920	training loss:0.38902637362480164	 training accuracy:1.0
Epoch:1921	training loss:0.38882970809936523	 training accuracy:1.0
Epoch:1922	training loss:0.38863250613212585	 training accuracy:1.0
Epoch:1923	training loss:0.3884347677230835	 training accuracy:1.0
Epoch:1924	training loss:0.3882376253604889	 training accuracy:1.0
Epoch:1925	training loss:0.3880416750907898	 training accuracy:1.0
Epoch:1926	training loss:0.3878467082977295	 training accuracy:1.0
Epoch:1927	training loss:0.38765183091163635	 training accuracy:1.0
Epoch:1928	training loss:0.38745617866516113	 training accuracy:1.0
Epoch:1929	training loss:0.38726070523262024	 training accuracy:1.0
Epoch:1930	training loss:0.3870655298233032	 training accuracy:1.0
Epoch:1931	training loss:0.386871337890625	 training accuracy:1.0
Epoch:1932	training loss:0.3866778612136841	 training accuracy:1.0
Epoch:1933	training loss:0.3864842653274536	 training accuracy:1.0
Epoch:1934	training loss:0.3862900137901306	 training accuracy:1.0
Epoch:1935	training loss:0.38609597086906433	 training accuracy:1.0
Epoch:1936	training loss:0.38590267300605774	 training accuracy:1.0
Epoch:1937	training loss:0.38571006059646606	 training accuracy:1.0
Epoch:1938	training loss:0.38551822304725647	 training accuracy:1.0
Epoch:1939	training loss:0.385326623916626	 training accuracy:1.0
Epoch:1940	training loss:0.38513433933258057	 training accuracy:1.0
Epoch:1941	training loss:0.3849424719810486	 training accuracy:1.0
Epoch:1942	training loss:0.3847508430480957	 training accuracy:1.0
Epoch:1943	training loss:0.38455939292907715	 training accuracy:1.0
Epoch:1944	training loss:0.3843686580657959	 training accuracy:1.0
Epoch:1945	training loss:0.3841782510280609	 training accuracy:1.0
Epoch:1946	training loss:0.3839876651763916	 training accuracy:1.0
Epoch:1947	training loss:0.3837970495223999	 training accuracy:1.0
Epoch:1948	training loss:0.38360661268234253	 training accuracy:1.0
Epoch:1949	training loss:0.38341712951660156	 training accuracy:1.0
Epoch:1950	training loss:0.3832286298274994	 training accuracy:1.0
Epoch:1951	training loss:0.38303977251052856	 training accuracy:1.0
Epoch:1952	training loss:0.3828504681587219	 training accuracy:1.0
Epoch:1953	training loss:0.3826615810394287	 training accuracy:1.0
Epoch:1954	training loss:0.3824731707572937	 training accuracy:1.0
Epoch:1955	training loss:0.382285475730896	 training accuracy:1.0
Epoch:1956	training loss:0.382098913192749	 training accuracy:1.0
Epoch:1957	training loss:0.3819120228290558	 training accuracy:1.0
Epoch:1958	training loss:0.3817247152328491	 training accuracy:1.0
Epoch:1959	training loss:0.3815372884273529	 training accuracy:1.0
Epoch:1960	training loss:0.3813502788543701	 training accuracy:1.0
Epoch:1961	training loss:0.3811646103858948	 training accuracy:1.0
Epoch:1962	training loss:0.38097894191741943	 training accuracy:1.0
Epoch:1963	training loss:0.3807936906814575	 training accuracy:1.0
Epoch:1964	training loss:0.3806079626083374	 training accuracy:1.0
Epoch:1965	training loss:0.3804221749305725	 training accuracy:1.0
Epoch:1966	training loss:0.3802368640899658	 training accuracy:1.0
Epoch:1967	training loss:0.3800522983074188	 training accuracy:1.0
Epoch:1968	training loss:0.37986791133880615	 training accuracy:1.0
Epoch:1969	training loss:0.3796843886375427	 training accuracy:1.0
Epoch:1970	training loss:0.3795003294944763	 training accuracy:1.0
Epoch:1971	training loss:0.37931591272354126	 training accuracy:1.0
Epoch:1972	training loss:0.3791320323944092	 training accuracy:1.0
Epoch:1973	training loss:0.3789489269256592	 training accuracy:1.0
Epoch:1974	training loss:0.37876665592193604	 training accuracy:1.0
Epoch:1975	training loss:0.3785841166973114	 training accuracy:1.0
Epoch:1976	training loss:0.37840157747268677	 training accuracy:1.0
Epoch:1977	training loss:0.37821927666664124	 training accuracy:1.0
Epoch:1978	training loss:0.3780372142791748	 training accuracy:1.0
Epoch:1979	training loss:0.3778555393218994	 training accuracy:1.0
Epoch:1980	training loss:0.377674400806427	 training accuracy:1.0
Epoch:1981	training loss:0.3774934709072113	 training accuracy:1.0
Epoch:1982	training loss:0.3773125410079956	 training accuracy:1.0
Epoch:1983	training loss:0.3771316111087799	 training accuracy:1.0
Epoch:1984	training loss:0.37695080041885376	 training accuracy:1.0
Epoch:1985	training loss:0.3767704367637634	 training accuracy:1.0
Epoch:1986	training loss:0.3765910267829895	 training accuracy:1.0
Epoch:1987	training loss:0.376412034034729	 training accuracy:1.0
Epoch:1988	training loss:0.37623268365859985	 training accuracy:1.0
Epoch:1989	training loss:0.37605300545692444	 training accuracy:1.0
Epoch:1990	training loss:0.3758735656738281	 training accuracy:1.0
Epoch:1991	training loss:0.37569519877433777	 training accuracy:1.0
Epoch:1992	training loss:0.37551772594451904	 training accuracy:1.0
Epoch:1993	training loss:0.3753402531147003	 training accuracy:1.0
Epoch:1994	training loss:0.3751620054244995	 training accuracy:1.0
Epoch:1995	training loss:0.3749834895133972	 training accuracy:1.0
Epoch:1996	training loss:0.3748055398464203	 training accuracy:1.0
Epoch:1997	training loss:0.3746289908885956	 training accuracy:1.0
Epoch:1998	training loss:0.37445271015167236	 training accuracy:1.0
Epoch:1999	training loss:0.37427592277526855	 training accuracy:1.0
Epoch:2000	training loss:0.37409859895706177	 training accuracy:1.0
Epoch:2001	training loss:0.3739580512046814	 training accuracy:1.0
Epoch:2002	training loss:0.3738180100917816	 training accuracy:1.0
Epoch:2003	training loss:0.37368208169937134	 training accuracy:1.0
Epoch:2004	training loss:0.37354910373687744	 training accuracy:1.0
Epoch:2005	training loss:0.37341517210006714	 training accuracy:1.0
Epoch:2006	training loss:0.3732788562774658	 training accuracy:1.0
Epoch:2007	training loss:0.3731418550014496	 training accuracy:1.0
Epoch:2008	training loss:0.373005747795105	 training accuracy:1.0
Epoch:2009	training loss:0.3728720247745514	 training accuracy:1.0
Epoch:2010	training loss:0.3727377951145172	 training accuracy:1.0
Epoch:2011	training loss:0.37260305881500244	 training accuracy:1.0
Epoch:2012	training loss:0.3724680244922638	 training accuracy:1.0
Epoch:2013	training loss:0.372332900762558	 training accuracy:1.0
Epoch:2014	training loss:0.37219882011413574	 training accuracy:1.0
Epoch:2015	training loss:0.372065007686615	 training accuracy:1.0
Epoch:2016	training loss:0.37193045020103455	 training accuracy:1.0
Epoch:2017	training loss:0.3717966377735138	 training accuracy:1.0
Epoch:2018	training loss:0.3716631531715393	 training accuracy:1.0
Epoch:2019	training loss:0.37152940034866333	 training accuracy:1.0
Epoch:2020	training loss:0.3713960647583008	 training accuracy:1.0
Epoch:2021	training loss:0.3712630867958069	 training accuracy:1.0
Epoch:2022	training loss:0.3711300492286682	 training accuracy:1.0
Epoch:2023	training loss:0.37099701166152954	 training accuracy:1.0
Epoch:2024	training loss:0.3708644509315491	 training accuracy:1.0
Epoch:2025	training loss:0.37073174118995667	 training accuracy:1.0
Epoch:2026	training loss:0.37059906125068665	 training accuracy:1.0
Epoch:2027	training loss:0.37046703696250916	 training accuracy:1.0
Epoch:2028	training loss:0.37033504247665405	 training accuracy:1.0
Epoch:2029	training loss:0.3702031672000885	 training accuracy:1.0
Epoch:2030	training loss:0.3700714409351349	 training accuracy:1.0
Epoch:2031	training loss:0.3699394464492798	 training accuracy:1.0
Epoch:2032	training loss:0.3698078989982605	 training accuracy:1.0
Epoch:2033	training loss:0.3696773648262024	 training accuracy:1.0
Epoch:2034	training loss:0.3695460259914398	 training accuracy:1.0
Epoch:2035	training loss:0.3694140911102295	 training accuracy:1.0
Epoch:2036	training loss:0.36928296089172363	 training accuracy:1.0
Epoch:2037	training loss:0.369151771068573	 training accuracy:1.0
Epoch:2038	training loss:0.3690210282802582	 training accuracy:1.0
Epoch:2039	training loss:0.36889052391052246	 training accuracy:1.0
Epoch:2040	training loss:0.36875972151756287	 training accuracy:1.0
Epoch:2041	training loss:0.3686293363571167	 training accuracy:1.0
Epoch:2042	training loss:0.36849915981292725	 training accuracy:1.0
Epoch:2043	training loss:0.368368923664093	 training accuracy:1.0
Epoch:2044	training loss:0.3682388663291931	 training accuracy:1.0
Epoch:2045	training loss:0.3681090474128723	 training accuracy:1.0
Epoch:2046	training loss:0.3679792582988739	 training accuracy:1.0
Epoch:2047	training loss:0.3678494691848755	 training accuracy:1.0
Epoch:2048	training loss:0.36771953105926514	 training accuracy:1.0
Epoch:2049	training loss:0.3675900101661682	 training accuracy:1.0
Epoch:2050	training loss:0.36746084690093994	 training accuracy:1.0
Epoch:2051	training loss:0.36733195185661316	 training accuracy:1.0
Epoch:2052	training loss:0.36720311641693115	 training accuracy:1.0
Epoch:2053	training loss:0.3670741617679596	 training accuracy:1.0
Epoch:2054	training loss:0.3669450581073761	 training accuracy:1.0
Epoch:2055	training loss:0.36681583523750305	 training accuracy:1.0
Epoch:2056	training loss:0.3666874170303345	 training accuracy:1.0
Epoch:2057	training loss:0.3665594756603241	 training accuracy:1.0
Epoch:2058	training loss:0.3664312958717346	 training accuracy:1.0
Epoch:2059	training loss:0.36630257964134216	 training accuracy:1.0
Epoch:2060	training loss:0.36617428064346313	 training accuracy:1.0
Epoch:2061	training loss:0.3660467267036438	 training accuracy:1.0
Epoch:2062	training loss:0.3659190535545349	 training accuracy:1.0
Epoch:2063	training loss:0.36579135060310364	 training accuracy:1.0
Epoch:2064	training loss:0.36566370725631714	 training accuracy:1.0
Epoch:2065	training loss:0.3655361235141754	 training accuracy:1.0
Epoch:2066	training loss:0.365408718585968	 training accuracy:1.0
Epoch:2067	training loss:0.36528122425079346	 training accuracy:1.0
Epoch:2068	training loss:0.36515384912490845	 training accuracy:1.0
Epoch:2069	training loss:0.36502718925476074	 training accuracy:1.0
Epoch:2070	training loss:0.36490029096603394	 training accuracy:1.0
Epoch:2071	training loss:0.36477336287498474	 training accuracy:1.0
Epoch:2072	training loss:0.36464637517929077	 training accuracy:1.0
Epoch:2073	training loss:0.3645196259021759	 training accuracy:1.0
Epoch:2074	training loss:0.3643936514854431	 training accuracy:1.0
Epoch:2075	training loss:0.36426758766174316	 training accuracy:1.0
Epoch:2076	training loss:0.36414167284965515	 training accuracy:1.0
Epoch:2077	training loss:0.36401546001434326	 training accuracy:1.0
Epoch:2078	training loss:0.3638891279697418	 training accuracy:1.0
Epoch:2079	training loss:0.3637630343437195	 training accuracy:1.0
Epoch:2080	training loss:0.3636370897293091	 training accuracy:1.0
Epoch:2081	training loss:0.36351197957992554	 training accuracy:1.0
Epoch:2082	training loss:0.3633866012096405	 training accuracy:1.0
Epoch:2083	training loss:0.36326098442077637	 training accuracy:1.0
Epoch:2084	training loss:0.36313533782958984	 training accuracy:1.0
Epoch:2085	training loss:0.36300981044769287	 training accuracy:1.0
Epoch:2086	training loss:0.362885057926178	 training accuracy:1.0
Epoch:2087	training loss:0.3627605438232422	 training accuracy:1.0
Epoch:2088	training loss:0.36263564229011536	 training accuracy:1.0
Epoch:2089	training loss:0.3625109791755676	 training accuracy:1.0
Epoch:2090	training loss:0.36238616704940796	 training accuracy:1.0
Epoch:2091	training loss:0.36226171255111694	 training accuracy:1.0
Epoch:2092	training loss:0.36213815212249756	 training accuracy:1.0
Epoch:2093	training loss:0.3620142638683319	 training accuracy:1.0
Epoch:2094	training loss:0.3618900179862976	 training accuracy:1.0
Epoch:2095	training loss:0.36176562309265137	 training accuracy:1.0
Epoch:2096	training loss:0.361641526222229	 training accuracy:1.0
Epoch:2097	training loss:0.3615177869796753	 training accuracy:1.0
Epoch:2098	training loss:0.36139410734176636	 training accuracy:1.0
Epoch:2099	training loss:0.3612705171108246	 training accuracy:1.0
Epoch:2100	training loss:0.36114683747291565	 training accuracy:1.0
Epoch:2101	training loss:0.361023873090744	 training accuracy:1.0
Epoch:2102	training loss:0.3609004318714142	 training accuracy:1.0
Epoch:2103	training loss:0.3607766330242157	 training accuracy:1.0
Epoch:2104	training loss:0.3606536388397217	 training accuracy:1.0
Epoch:2105	training loss:0.36053135991096497	 training accuracy:1.0
Epoch:2106	training loss:0.3604089021682739	 training accuracy:1.0
Epoch:2107	training loss:0.3602857291698456	 training accuracy:1.0
Epoch:2108	training loss:0.3601626455783844	 training accuracy:1.0
Epoch:2109	training loss:0.36004024744033813	 training accuracy:1.0
Epoch:2110	training loss:0.3599182963371277	 training accuracy:1.0
Epoch:2111	training loss:0.3597961664199829	 training accuracy:1.0
Epoch:2112	training loss:0.3596740961074829	 training accuracy:1.0
Epoch:2113	training loss:0.3595520853996277	 training accuracy:1.0
Epoch:2114	training loss:0.3594302535057068	 training accuracy:1.0
Epoch:2115	training loss:0.35930848121643066	 training accuracy:1.0
Epoch:2116	training loss:0.35918694734573364	 training accuracy:1.0
Epoch:2117	training loss:0.3590656518936157	 training accuracy:1.0
Epoch:2118	training loss:0.3589441180229187	 training accuracy:1.0
Epoch:2119	training loss:0.35882246494293213	 training accuracy:1.0
Epoch:2120	training loss:0.35870084166526794	 training accuracy:1.0
Epoch:2121	training loss:0.35857951641082764	 training accuracy:1.0
Epoch:2122	training loss:0.35845863819122314	 training accuracy:1.0
Epoch:2123	training loss:0.3583385646343231	 training accuracy:1.0
Epoch:2124	training loss:0.3582182824611664	 training accuracy:1.0
Epoch:2125	training loss:0.3580971360206604	 training accuracy:1.0
Epoch:2126	training loss:0.35797613859176636	 training accuracy:1.0
Epoch:2127	training loss:0.35785552859306335	 training accuracy:1.0
Epoch:2128	training loss:0.35773539543151855	 training accuracy:1.0
Epoch:2129	training loss:0.35761559009552	 training accuracy:1.0
Epoch:2130	training loss:0.35749551653862	 training accuracy:1.0
Epoch:2131	training loss:0.35737499594688416	 training accuracy:1.0
Epoch:2132	training loss:0.35725489258766174	 training accuracy:1.0
Epoch:2133	training loss:0.3571351170539856	 training accuracy:1.0
Epoch:2134	training loss:0.35701555013656616	 training accuracy:1.0
Epoch:2135	training loss:0.3568958640098572	 training accuracy:1.0
Epoch:2136	training loss:0.35677629709243774	 training accuracy:1.0
Epoch:2137	training loss:0.35665708780288696	 training accuracy:1.0
Epoch:2138	training loss:0.35653772950172424	 training accuracy:1.0
Epoch:2139	training loss:0.35641804337501526	 training accuracy:1.0
Epoch:2140	training loss:0.3562984764575958	 training accuracy:1.0
Epoch:2141	training loss:0.35617995262145996	 training accuracy:1.0
Epoch:2142	training loss:0.3560613691806793	 training accuracy:1.0
Epoch:2143	training loss:0.35594242811203003	 training accuracy:1.0
Epoch:2144	training loss:0.3558235466480255	 training accuracy:1.0
Epoch:2145	training loss:0.3557049036026001	 training accuracy:1.0
Epoch:2146	training loss:0.35558685660362244	 training accuracy:1.0
Epoch:2147	training loss:0.3554689586162567	 training accuracy:1.0
Epoch:2148	training loss:0.35535097122192383	 training accuracy:1.0
Epoch:2149	training loss:0.3552325367927551	 training accuracy:1.0
Epoch:2150	training loss:0.35511407256126404	 training accuracy:1.0
Epoch:2151	training loss:0.3549962341785431	 training accuracy:1.0
Epoch:2152	training loss:0.35487857460975647	 training accuracy:1.0
Epoch:2153	training loss:0.3547612130641937	 training accuracy:1.0
Epoch:2154	training loss:0.35464340448379517	 training accuracy:1.0
Epoch:2155	training loss:0.3545253276824951	 training accuracy:1.0
Epoch:2156	training loss:0.3544076681137085	 training accuracy:1.0
Epoch:2157	training loss:0.35429033637046814	 training accuracy:1.0
Epoch:2158	training loss:0.3541732132434845	 training accuracy:1.0
Epoch:2159	training loss:0.3540562093257904	 training accuracy:1.0
Epoch:2160	training loss:0.3539387583732605	 training accuracy:1.0
Epoch:2161	training loss:0.35382211208343506	 training accuracy:1.0
Epoch:2162	training loss:0.35370543599128723	 training accuracy:1.0
Epoch:2163	training loss:0.3535884618759155	 training accuracy:1.0
Epoch:2164	training loss:0.3534720540046692	 training accuracy:1.0
Epoch:2165	training loss:0.3533557653427124	 training accuracy:1.0
Epoch:2166	training loss:0.3532394766807556	 training accuracy:1.0
Epoch:2167	training loss:0.353122740983963	 training accuracy:1.0
Epoch:2168	training loss:0.35300618410110474	 training accuracy:1.0
Epoch:2169	training loss:0.35289013385772705	 training accuracy:1.0
Epoch:2170	training loss:0.3527746796607971	 training accuracy:1.0
Epoch:2171	training loss:0.35265904664993286	 training accuracy:1.0
Epoch:2172	training loss:0.35254359245300293	 training accuracy:1.0
Epoch:2173	training loss:0.3524278402328491	 training accuracy:1.0
Epoch:2174	training loss:0.3523116707801819	 training accuracy:1.0
Epoch:2175	training loss:0.3521954119205475	 training accuracy:1.0
Epoch:2176	training loss:0.35208001732826233	 training accuracy:1.0
Epoch:2177	training loss:0.3519655466079712	 training accuracy:1.0
Epoch:2178	training loss:0.35185033082962036	 training accuracy:1.0
Epoch:2179	training loss:0.3517346978187561	 training accuracy:1.0
Epoch:2180	training loss:0.3516191244125366	 training accuracy:1.0
Epoch:2181	training loss:0.35150450468063354	 training accuracy:1.0
Epoch:2182	training loss:0.3513902425765991	 training accuracy:1.0
Epoch:2183	training loss:0.35127580165863037	 training accuracy:1.0
Epoch:2184	training loss:0.3511611819267273	 training accuracy:1.0
Epoch:2185	training loss:0.3510465621948242	 training accuracy:1.0
Epoch:2186	training loss:0.350932240486145	 training accuracy:1.0
Epoch:2187	training loss:0.3508177399635315	 training accuracy:1.0
Epoch:2188	training loss:0.35070329904556274	 training accuracy:1.0
Epoch:2189	training loss:0.35058918595314026	 training accuracy:1.0
Epoch:2190	training loss:0.35047537088394165	 training accuracy:1.0
Epoch:2191	training loss:0.3503613770008087	 training accuracy:1.0
Epoch:2192	training loss:0.35024726390838623	 training accuracy:1.0
Epoch:2193	training loss:0.3501330614089966	 training accuracy:1.0
Epoch:2194	training loss:0.35001933574676514	 training accuracy:1.0
Epoch:2195	training loss:0.3499060273170471	 training accuracy:1.0
Epoch:2196	training loss:0.3497927784919739	 training accuracy:1.0
Epoch:2197	training loss:0.34967920184135437	 training accuracy:1.0
Epoch:2198	training loss:0.34956565499305725	 training accuracy:1.0
Epoch:2199	training loss:0.3494524657726288	 training accuracy:1.0
Epoch:2200	training loss:0.34933966398239136	 training accuracy:1.0
Epoch:2201	training loss:0.34922733902931213	 training accuracy:1.0
Epoch:2202	training loss:0.34911447763442993	 training accuracy:1.0
Epoch:2203	training loss:0.34900128841400146	 training accuracy:1.0
Epoch:2204	training loss:0.34888842701911926	 training accuracy:1.0
Epoch:2205	training loss:0.3487757444381714	 training accuracy:1.0
Epoch:2206	training loss:0.3486631214618683	 training accuracy:1.0
Epoch:2207	training loss:0.348550945520401	 training accuracy:1.0
Epoch:2208	training loss:0.3484385013580322	 training accuracy:1.0
Epoch:2209	training loss:0.3483262062072754	 training accuracy:1.0
Epoch:2210	training loss:0.34821391105651855	 training accuracy:1.0
Epoch:2211	training loss:0.3481018543243408	 training accuracy:1.0
Epoch:2212	training loss:0.3479902446269989	 training accuracy:1.0
Epoch:2213	training loss:0.34787896275520325	 training accuracy:1.0
Epoch:2214	training loss:0.3477671444416046	 training accuracy:1.0
Epoch:2215	training loss:0.3476547598838806	 training accuracy:1.0
Epoch:2216	training loss:0.3475427031517029	 training accuracy:1.0
Epoch:2217	training loss:0.3474312722682953	 training accuracy:1.0
Epoch:2218	training loss:0.3473203778266907	 training accuracy:1.0
Epoch:2219	training loss:0.34720930457115173	 training accuracy:1.0
Epoch:2220	training loss:0.3470979928970337	 training accuracy:1.0
Epoch:2221	training loss:0.3469870686531067	 training accuracy:1.0
Epoch:2222	training loss:0.3468760550022125	 training accuracy:1.0
Epoch:2223	training loss:0.3467647433280945	 training accuracy:1.0
Epoch:2224	training loss:0.3466538190841675	 training accuracy:1.0
Epoch:2225	training loss:0.3465435802936554	 training accuracy:1.0
Epoch:2226	training loss:0.34643322229385376	 training accuracy:1.0
Epoch:2227	training loss:0.34632250666618347	 training accuracy:1.0
Epoch:2228	training loss:0.34621161222457886	 training accuracy:1.0
Epoch:2229	training loss:0.3461010456085205	 training accuracy:1.0
Epoch:2230	training loss:0.3459908664226532	 training accuracy:1.0
Epoch:2231	training loss:0.34588080644607544	 training accuracy:1.0
Epoch:2232	training loss:0.3457706570625305	 training accuracy:1.0
Epoch:2233	training loss:0.34566062688827515	 training accuracy:1.0
Epoch:2234	training loss:0.3455504775047302	 training accuracy:1.0
Epoch:2235	training loss:0.3454403281211853	 training accuracy:1.0
Epoch:2236	training loss:0.34533098340034485	 training accuracy:1.0
Epoch:2237	training loss:0.345221608877182	 training accuracy:1.0
Epoch:2238	training loss:0.3451119363307953	 training accuracy:1.0
Epoch:2239	training loss:0.34500208497047424	 training accuracy:1.0
Epoch:2240	training loss:0.34489214420318604	 training accuracy:1.0
Epoch:2241	training loss:0.344783216714859	 training accuracy:1.0
Epoch:2242	training loss:0.3446744680404663	 training accuracy:1.0
Epoch:2243	training loss:0.34456557035446167	 training accuracy:1.0
Epoch:2244	training loss:0.34445667266845703	 training accuracy:1.0
Epoch:2245	training loss:0.34434759616851807	 training accuracy:1.0
Epoch:2246	training loss:0.3442386984825134	 training accuracy:1.0
Epoch:2247	training loss:0.3441295623779297	 training accuracy:1.0
Epoch:2248	training loss:0.3440204858779907	 training accuracy:1.0
Epoch:2249	training loss:0.3439125418663025	 training accuracy:1.0
Epoch:2250	training loss:0.3438042402267456	 training accuracy:1.0
Epoch:2251	training loss:0.3436955213546753	 training accuracy:1.0
Epoch:2252	training loss:0.3435870110988617	 training accuracy:1.0
Epoch:2253	training loss:0.3434786796569824	 training accuracy:1.0
Epoch:2254	training loss:0.3433711528778076	 training accuracy:1.0
Epoch:2255	training loss:0.3432633876800537	 training accuracy:1.0
Epoch:2256	training loss:0.3431555926799774	 training accuracy:1.0
Epoch:2257	training loss:0.3430476784706116	 training accuracy:1.0
Epoch:2258	training loss:0.342939555644989	 training accuracy:1.0
Epoch:2259	training loss:0.34283173084259033	 training accuracy:1.0
Epoch:2260	training loss:0.34272393584251404	 training accuracy:1.0
Epoch:2261	training loss:0.34261658787727356	 training accuracy:1.0
Epoch:2262	training loss:0.34250909090042114	 training accuracy:1.0
Epoch:2263	training loss:0.3424016833305359	 training accuracy:1.0
Epoch:2264	training loss:0.3422940969467163	 training accuracy:1.0
Epoch:2265	training loss:0.34218645095825195	 training accuracy:1.0
Epoch:2266	training loss:0.34207940101623535	 training accuracy:1.0
Epoch:2267	training loss:0.3419730067253113	 training accuracy:1.0
Epoch:2268	training loss:0.34186631441116333	 training accuracy:1.0
Epoch:2269	training loss:0.3417591452598572	 training accuracy:1.0
Epoch:2270	training loss:0.3416520059108734	 training accuracy:1.0
Epoch:2271	training loss:0.34154513478279114	 training accuracy:1.0
Epoch:2272	training loss:0.3414390981197357	 training accuracy:1.0
Epoch:2273	training loss:0.34133344888687134	 training accuracy:1.0
Epoch:2274	training loss:0.3412272334098816	 training accuracy:1.0
Epoch:2275	training loss:0.34112006425857544	 training accuracy:1.0
Epoch:2276	training loss:0.3410135507583618	 training accuracy:1.0
Epoch:2277	training loss:0.3409074544906616	 training accuracy:1.0
Epoch:2278	training loss:0.3408013880252838	 training accuracy:1.0
Epoch:2279	training loss:0.34069526195526123	 training accuracy:1.0
Epoch:2280	training loss:0.3405889868736267	 training accuracy:1.0
Epoch:2281	training loss:0.340483695268631	 training accuracy:1.0
Epoch:2282	training loss:0.3403781056404114	 training accuracy:1.0
Epoch:2283	training loss:0.3402720093727112	 training accuracy:1.0
Epoch:2284	training loss:0.34016644954681396	 training accuracy:1.0
Epoch:2285	training loss:0.3400611877441406	 training accuracy:1.0
Epoch:2286	training loss:0.33995574712753296	 training accuracy:1.0
Epoch:2287	training loss:0.33985018730163574	 training accuracy:1.0
Epoch:2288	training loss:0.33974477648735046	 training accuracy:1.0
Epoch:2289	training loss:0.3396396040916443	 training accuracy:1.0
Epoch:2290	training loss:0.3395349383354187	 training accuracy:1.0
Epoch:2291	training loss:0.3394303321838379	 training accuracy:1.0
Epoch:2292	training loss:0.3393257260322571	 training accuracy:1.0
Epoch:2293	training loss:0.3392207622528076	 training accuracy:1.0
Epoch:2294	training loss:0.339115709066391	 training accuracy:1.0
Epoch:2295	training loss:0.3390108048915863	 training accuracy:1.0
Epoch:2296	training loss:0.33890628814697266	 training accuracy:1.0
Epoch:2297	training loss:0.3388020396232605	 training accuracy:1.0
Epoch:2298	training loss:0.3386975824832916	 training accuracy:1.0
Epoch:2299	training loss:0.3385927677154541	 training accuracy:1.0
Epoch:2300	training loss:0.3384879231452942	 training accuracy:1.0
Epoch:2301	training loss:0.33838385343551636	 training accuracy:1.0
Epoch:2302	training loss:0.3382801115512848	 training accuracy:1.0
Epoch:2303	training loss:0.338176429271698	 training accuracy:1.0
Epoch:2304	training loss:0.33807235956192017	 training accuracy:1.0
Epoch:2305	training loss:0.3379683792591095	 training accuracy:1.0
Epoch:2306	training loss:0.33786463737487793	 training accuracy:1.0
Epoch:2307	training loss:0.3377608060836792	 training accuracy:1.0
Epoch:2308	training loss:0.33765724301338196	 training accuracy:1.0
Epoch:2309	training loss:0.33755409717559814	 training accuracy:1.0
Epoch:2310	training loss:0.33745092153549194	 training accuracy:1.0
Epoch:2311	training loss:0.3373473584651947	 training accuracy:1.0
Epoch:2312	training loss:0.3372441828250885	 training accuracy:1.0
Epoch:2313	training loss:0.33714112639427185	 training accuracy:1.0
Epoch:2314	training loss:0.33703818917274475	 training accuracy:1.0
Epoch:2315	training loss:0.33693522214889526	 training accuracy:1.0
Epoch:2316	training loss:0.3368324935436249	 training accuracy:1.0
Epoch:2317	training loss:0.33672961592674255	 training accuracy:1.0
Epoch:2318	training loss:0.3366262912750244	 training accuracy:1.0
Epoch:2319	training loss:0.3365230858325958	 training accuracy:1.0
Epoch:2320	training loss:0.33642005920410156	 training accuracy:1.0
Epoch:2321	training loss:0.3363182842731476	 training accuracy:1.0
Epoch:2322	training loss:0.3362159729003906	 training accuracy:1.0
Epoch:2323	training loss:0.3361130356788635	 training accuracy:1.0
Epoch:2324	training loss:0.3360103964805603	 training accuracy:1.0
Epoch:2325	training loss:0.3359079360961914	 training accuracy:1.0
Epoch:2326	training loss:0.3358061909675598	 training accuracy:1.0
Epoch:2327	training loss:0.3357044458389282	 training accuracy:1.0
Epoch:2328	training loss:0.335602343082428	 training accuracy:1.0
Epoch:2329	training loss:0.3355000615119934	 training accuracy:1.0
Epoch:2330	training loss:0.33539825677871704	 training accuracy:1.0
Epoch:2331	training loss:0.3352964520454407	 training accuracy:1.0
Epoch:2332	training loss:0.33519482612609863	 training accuracy:1.0
Epoch:2333	training loss:0.33509361743927	 training accuracy:1.0
Epoch:2334	training loss:0.33499211072921753	 training accuracy:1.0
Epoch:2335	training loss:0.33489009737968445	 training accuracy:1.0
Epoch:2336	training loss:0.33478835225105286	 training accuracy:1.0
Epoch:2337	training loss:0.33468687534332275	 training accuracy:1.0
Epoch:2338	training loss:0.33458593487739563	 training accuracy:1.0
Epoch:2339	training loss:0.3344852924346924	 training accuracy:1.0
Epoch:2340	training loss:0.33438438177108765	 training accuracy:1.0
Epoch:2341	training loss:0.33428338170051575	 training accuracy:1.0
Epoch:2342	training loss:0.33418208360671997	 training accuracy:1.0
Epoch:2343	training loss:0.33408090472221375	 training accuracy:1.0
Epoch:2344	training loss:0.33398061990737915	 training accuracy:1.0
Epoch:2345	training loss:0.33388039469718933	 training accuracy:1.0
Epoch:2346	training loss:0.3337796926498413	 training accuracy:1.0
Epoch:2347	training loss:0.3336789011955261	 training accuracy:1.0
Epoch:2348	training loss:0.3335780203342438	 training accuracy:1.0
Epoch:2349	training loss:0.33347752690315247	 training accuracy:1.0
Epoch:2350	training loss:0.3333771824836731	 training accuracy:1.0
Epoch:2351	training loss:0.3332769274711609	 training accuracy:1.0
Epoch:2352	training loss:0.3331766128540039	 training accuracy:1.0
Epoch:2353	training loss:0.33307668566703796	 training accuracy:1.0
Epoch:2354	training loss:0.33297643065452576	 training accuracy:1.0
Epoch:2355	training loss:0.33287593722343445	 training accuracy:1.0
Epoch:2356	training loss:0.33277615904808044	 training accuracy:1.0
Epoch:2357	training loss:0.33267679810523987	 training accuracy:1.0
Epoch:2358	training loss:0.3325771689414978	 training accuracy:1.0
Epoch:2359	training loss:0.3324768841266632	 training accuracy:1.0
Epoch:2360	training loss:0.3323765993118286	 training accuracy:1.0
Epoch:2361	training loss:0.3322775661945343	 training accuracy:1.0
Epoch:2362	training loss:0.33217889070510864	 training accuracy:1.0
Epoch:2363	training loss:0.33207985758781433	 training accuracy:1.0
Epoch:2364	training loss:0.33198055624961853	 training accuracy:1.0
Epoch:2365	training loss:0.3318810760974884	 training accuracy:1.0
Epoch:2366	training loss:0.3317820131778717	 training accuracy:1.0
Epoch:2367	training loss:0.33168306946754456	 training accuracy:1.0
Epoch:2368	training loss:0.33158406615257263	 training accuracy:1.0
Epoch:2369	training loss:0.3314855098724365	 training accuracy:1.0
Epoch:2370	training loss:0.3313864767551422	 training accuracy:1.0
Epoch:2371	training loss:0.33128756284713745	 training accuracy:1.0
Epoch:2372	training loss:0.3311888873577118	 training accuracy:1.0
Epoch:2373	training loss:0.33108967542648315	 training accuracy:1.0
Epoch:2374	training loss:0.33099085092544556	 training accuracy:1.0
Epoch:2375	training loss:0.33089250326156616	 training accuracy:1.0
Epoch:2376	training loss:0.33079421520233154	 training accuracy:1.0
Epoch:2377	training loss:0.33069583773612976	 training accuracy:1.0
Epoch:2378	training loss:0.3305974006652832	 training accuracy:1.0
Epoch:2379	training loss:0.33049899339675903	 training accuracy:1.0
Epoch:2380	training loss:0.33040088415145874	 training accuracy:1.0
Epoch:2381	training loss:0.3303033709526062	 training accuracy:1.0
Epoch:2382	training loss:0.33020567893981934	 training accuracy:1.0
Epoch:2383	training loss:0.3301074206829071	 training accuracy:1.0
Epoch:2384	training loss:0.3300090730190277	 training accuracy:1.0
Epoch:2385	training loss:0.3299112617969513	 training accuracy:1.0
Epoch:2386	training loss:0.32981377840042114	 training accuracy:1.0
Epoch:2387	training loss:0.32971644401550293	 training accuracy:1.0
Epoch:2388	training loss:0.32961881160736084	 training accuracy:1.0
Epoch:2389	training loss:0.3295212984085083	 training accuracy:1.0
Epoch:2390	training loss:0.3294236660003662	 training accuracy:1.0
Epoch:2391	training loss:0.3293258845806122	 training accuracy:1.0
Epoch:2392	training loss:0.3292286694049835	 training accuracy:1.0
Epoch:2393	training loss:0.32913222908973694	 training accuracy:1.0
Epoch:2394	training loss:0.32903531193733215	 training accuracy:1.0
Epoch:2395	training loss:0.32893773913383484	 training accuracy:1.0
Epoch:2396	training loss:0.32884061336517334	 training accuracy:1.0
Epoch:2397	training loss:0.32874375581741333	 training accuracy:1.0
Epoch:2398	training loss:0.328647255897522	 training accuracy:1.0
Epoch:2399	training loss:0.3285504877567291	 training accuracy:1.0
Epoch:2400	training loss:0.32845374941825867	 training accuracy:1.0
Epoch:2401	training loss:0.3283572793006897	 training accuracy:1.0
Epoch:2402	training loss:0.3282606899738312	 training accuracy:1.0
Epoch:2403	training loss:0.3281639814376831	 training accuracy:1.0
Epoch:2404	training loss:0.32806771993637085	 training accuracy:1.0
Epoch:2405	training loss:0.32797133922576904	 training accuracy:1.0
Epoch:2406	training loss:0.3278749883174896	 training accuracy:1.0
Epoch:2407	training loss:0.3277786672115326	 training accuracy:1.0
Epoch:2408	training loss:0.3276819884777069	 training accuracy:1.0
Epoch:2409	training loss:0.3275858163833618	 training accuracy:1.0
Epoch:2410	training loss:0.32749006152153015	 training accuracy:1.0
Epoch:2411	training loss:0.3273944556713104	 training accuracy:1.0
Epoch:2412	training loss:0.3272988200187683	 training accuracy:1.0
Epoch:2413	training loss:0.32720279693603516	 training accuracy:1.0
Epoch:2414	training loss:0.3271065354347229	 training accuracy:1.0
Epoch:2415	training loss:0.32701048254966736	 training accuracy:1.0
Epoch:2416	training loss:0.3269151747226715	 training accuracy:1.0
Epoch:2417	training loss:0.3268202543258667	 training accuracy:1.0
Epoch:2418	training loss:0.3267248868942261	 training accuracy:1.0
Epoch:2419	training loss:0.32662883400917053	 training accuracy:1.0
Epoch:2420	training loss:0.3265330195426941	 training accuracy:1.0
Epoch:2421	training loss:0.32643812894821167	 training accuracy:1.0
Epoch:2422	training loss:0.3263435661792755	 training accuracy:1.0
Epoch:2423	training loss:0.32624876499176025	 training accuracy:1.0
Epoch:2424	training loss:0.3261537551879883	 training accuracy:1.0
Epoch:2425	training loss:0.32605886459350586	 training accuracy:1.0
Epoch:2426	training loss:0.32596367597579956	 training accuracy:1.0
Epoch:2427	training loss:0.32586848735809326	 training accuracy:1.0
Epoch:2428	training loss:0.32577359676361084	 training accuracy:1.0
Epoch:2429	training loss:0.3256792426109314	 training accuracy:1.0
Epoch:2430	training loss:0.3255845904350281	 training accuracy:1.0
Epoch:2431	training loss:0.3254898488521576	 training accuracy:1.0
Epoch:2432	training loss:0.3253951668739319	 training accuracy:1.0
Epoch:2433	training loss:0.325300395488739	 training accuracy:1.0
Epoch:2434	training loss:0.32520627975463867	 training accuracy:1.0
Epoch:2435	training loss:0.32511240243911743	 training accuracy:1.0
Epoch:2436	training loss:0.3250183165073395	 training accuracy:1.0
Epoch:2437	training loss:0.3249238133430481	 training accuracy:1.0
Epoch:2438	training loss:0.32482925057411194	 training accuracy:1.0
Epoch:2439	training loss:0.3247348964214325	 training accuracy:1.0
Epoch:2440	training loss:0.3246406316757202	 training accuracy:1.0
Epoch:2441	training loss:0.3245471715927124	 training accuracy:1.0
Epoch:2442	training loss:0.32445353269577026	 training accuracy:1.0
Epoch:2443	training loss:0.324359655380249	 training accuracy:1.0
Epoch:2444	training loss:0.3242657482624054	 training accuracy:1.0
Epoch:2445	training loss:0.3241717517375946	 training accuracy:1.0
Epoch:2446	training loss:0.32407811284065247	 training accuracy:1.0
Epoch:2447	training loss:0.32398486137390137	 training accuracy:1.0
Epoch:2448	training loss:0.3238912522792816	 training accuracy:1.0
Epoch:2449	training loss:0.32379791140556335	 training accuracy:1.0
Epoch:2450	training loss:0.32370465993881226	 training accuracy:1.0
Epoch:2451	training loss:0.3236114978790283	 training accuracy:1.0
Epoch:2452	training loss:0.3235188126564026	 training accuracy:1.0
Epoch:2453	training loss:0.3234260082244873	 training accuracy:1.0
Epoch:2454	training loss:0.3233329653739929	 training accuracy:1.0
Epoch:2455	training loss:0.32323938608169556	 training accuracy:1.0
Epoch:2456	training loss:0.32314643263816833	 training accuracy:1.0
Epoch:2457	training loss:0.32305359840393066	 training accuracy:1.0
Epoch:2458	training loss:0.3229605555534363	 training accuracy:1.0
Epoch:2459	training loss:0.3228679299354553	 training accuracy:1.0
Epoch:2460	training loss:0.32277509570121765	 training accuracy:1.0
Epoch:2461	training loss:0.3226827383041382	 training accuracy:1.0
Epoch:2462	training loss:0.32258978486061096	 training accuracy:1.0
Epoch:2463	training loss:0.3224968910217285	 training accuracy:1.0
Epoch:2464	training loss:0.3224044442176819	 training accuracy:1.0
Epoch:2465	training loss:0.3223126530647278	 training accuracy:1.0
Epoch:2466	training loss:0.3222205638885498	 training accuracy:1.0
Epoch:2467	training loss:0.32212772965431213	 training accuracy:1.0
Epoch:2468	training loss:0.322035014629364	 training accuracy:1.0
Epoch:2469	training loss:0.3219429552555084	 training accuracy:1.0
Epoch:2470	training loss:0.3218514025211334	 training accuracy:1.0
Epoch:2471	training loss:0.3217596411705017	 training accuracy:1.0
Epoch:2472	training loss:0.3216676712036133	 training accuracy:1.0
Epoch:2473	training loss:0.321575790643692	 training accuracy:1.0
Epoch:2474	training loss:0.3214839696884155	 training accuracy:1.0
Epoch:2475	training loss:0.3213918209075928	 training accuracy:1.0
Epoch:2476	training loss:0.3213001489639282	 training accuracy:1.0
Epoch:2477	training loss:0.3212086856365204	 training accuracy:1.0
Epoch:2478	training loss:0.3211172819137573	 training accuracy:1.0
Epoch:2479	training loss:0.321025550365448	 training accuracy:1.0
Epoch:2480	training loss:0.3209335207939148	 training accuracy:1.0
Epoch:2481	training loss:0.3208421468734741	 training accuracy:1.0
Epoch:2482	training loss:0.3207511305809021	 training accuracy:1.0
Epoch:2483	training loss:0.3206605613231659	 training accuracy:1.0
Epoch:2484	training loss:0.32056963443756104	 training accuracy:1.0
Epoch:2485	training loss:0.32047826051712036	 training accuracy:1.0
Epoch:2486	training loss:0.3203868865966797	 training accuracy:1.0
Epoch:2487	training loss:0.3202958106994629	 training accuracy:1.0
Epoch:2488	training loss:0.3202049136161804	 training accuracy:1.0
Epoch:2489	training loss:0.3201146125793457	 training accuracy:1.0
Epoch:2490	training loss:0.320023775100708	 training accuracy:1.0
Epoch:2491	training loss:0.3199326694011688	 training accuracy:1.0
Epoch:2492	training loss:0.31984180212020874	 training accuracy:1.0
Epoch:2493	training loss:0.3197512626647949	 training accuracy:1.0
Epoch:2494	training loss:0.3196607530117035	 training accuracy:1.0
Epoch:2495	training loss:0.3195700943470001	 training accuracy:1.0
Epoch:2496	training loss:0.31947940587997437	 training accuracy:1.0
Epoch:2497	training loss:0.3193891644477844	 training accuracy:1.0
Epoch:2498	training loss:0.3192988634109497	 training accuracy:1.0
Epoch:2499	training loss:0.31920814514160156	 training accuracy:1.0
Epoch:2500	training loss:0.3191174864768982	 training accuracy:1.0
Epoch:2501	training loss:0.319027841091156	 training accuracy:1.0
Epoch:2502	training loss:0.31893789768218994	 training accuracy:1.0
Epoch:2503	training loss:0.31884753704071045	 training accuracy:1.0
Epoch:2504	training loss:0.31875720620155334	 training accuracy:1.0
Epoch:2505	training loss:0.3186669647693634	 training accuracy:1.0
Epoch:2506	training loss:0.31857776641845703	 training accuracy:1.0
Epoch:2507	training loss:0.3184886574745178	 training accuracy:1.0
Epoch:2508	training loss:0.3183993101119995	 training accuracy:1.0
Epoch:2509	training loss:0.31830939650535583	 training accuracy:1.0
Epoch:2510	training loss:0.31821948289871216	 training accuracy:1.0
Epoch:2511	training loss:0.31812989711761475	 training accuracy:1.0
Epoch:2512	training loss:0.31804075837135315	 training accuracy:1.0
Epoch:2513	training loss:0.31795185804367065	 training accuracy:1.0
Epoch:2514	training loss:0.317862331867218	 training accuracy:1.0
Epoch:2515	training loss:0.3177725672721863	 training accuracy:1.0
Epoch:2516	training loss:0.31768307089805603	 training accuracy:1.0
Epoch:2517	training loss:0.3175935745239258	 training accuracy:1.0
Epoch:2518	training loss:0.31750422716140747	 training accuracy:1.0
Epoch:2519	training loss:0.31741538643836975	 training accuracy:1.0
Epoch:2520	training loss:0.3173260986804962	 training accuracy:1.0
Epoch:2521	training loss:0.3172372579574585	 training accuracy:1.0
Epoch:2522	training loss:0.3171483874320984	 training accuracy:1.0
Epoch:2523	training loss:0.3170592486858368	 training accuracy:1.0
Epoch:2524	training loss:0.3169708549976349	 training accuracy:1.0
Epoch:2525	training loss:0.3168823719024658	 training accuracy:1.0
Epoch:2526	training loss:0.3167937994003296	 training accuracy:1.0
Epoch:2527	training loss:0.3167048394680023	 training accuracy:1.0
Epoch:2528	training loss:0.31661587953567505	 training accuracy:1.0
Epoch:2529	training loss:0.3165275752544403	 training accuracy:1.0
Epoch:2530	training loss:0.3164393901824951	 training accuracy:1.0
Epoch:2531	training loss:0.31635111570358276	 training accuracy:1.0
Epoch:2532	training loss:0.3162629306316376	 training accuracy:1.0
Epoch:2533	training loss:0.31617480516433716	 training accuracy:1.0
Epoch:2534	training loss:0.31608638167381287	 training accuracy:1.0
Epoch:2535	training loss:0.3159976601600647	 training accuracy:1.0
Epoch:2536	training loss:0.3159096837043762	 training accuracy:1.0
Epoch:2537	training loss:0.31582245230674744	 training accuracy:1.0
Epoch:2538	training loss:0.3157344460487366	 training accuracy:1.0
Epoch:2539	training loss:0.3156457245349884	 training accuracy:1.0
Epoch:2540	training loss:0.3155573308467865	 training accuracy:1.0
Epoch:2541	training loss:0.31546974182128906	 training accuracy:1.0
Epoch:2542	training loss:0.31538259983062744	 training accuracy:1.0
Epoch:2543	training loss:0.3152952790260315	 training accuracy:1.0
Epoch:2544	training loss:0.3152076005935669	 training accuracy:1.0
Epoch:2545	training loss:0.31511974334716797	 training accuracy:1.0
Epoch:2546	training loss:0.3150322437286377	 training accuracy:1.0
Epoch:2547	training loss:0.31494489312171936	 training accuracy:1.0
Epoch:2548	training loss:0.31485751271247864	 training accuracy:1.0
Epoch:2549	training loss:0.3147701323032379	 training accuracy:1.0
Epoch:2550	training loss:0.3146827518939972	 training accuracy:1.0
Epoch:2551	training loss:0.31459546089172363	 training accuracy:1.0
Epoch:2552	training loss:0.3145081102848053	 training accuracy:1.0
Epoch:2553	training loss:0.31442081928253174	 training accuracy:1.0
Epoch:2554	training loss:0.314333975315094	 training accuracy:1.0
Epoch:2555	training loss:0.3142472803592682	 training accuracy:1.0
Epoch:2556	training loss:0.31416046619415283	 training accuracy:1.0
Epoch:2557	training loss:0.3140732944011688	 training accuracy:1.0
Epoch:2558	training loss:0.3139861226081848	 training accuracy:1.0
Epoch:2559	training loss:0.31389909982681274	 training accuracy:1.0
Epoch:2560	training loss:0.31381240487098694	 training accuracy:1.0
Epoch:2561	training loss:0.3137263059616089	 training accuracy:1.0
Epoch:2562	training loss:0.31363993883132935	 training accuracy:1.0
Epoch:2563	training loss:0.3135530650615692	 training accuracy:1.0
Epoch:2564	training loss:0.3134664297103882	 training accuracy:1.0
Epoch:2565	training loss:0.3133799731731415	 training accuracy:1.0
Epoch:2566	training loss:0.31329360604286194	 training accuracy:1.0
Epoch:2567	training loss:0.3132072687149048	 training accuracy:1.0
Epoch:2568	training loss:0.3131207227706909	 training accuracy:1.0
Epoch:2569	training loss:0.31303441524505615	 training accuracy:1.0
Epoch:2570	training loss:0.3129481077194214	 training accuracy:1.0
Epoch:2571	training loss:0.3128618896007538	 training accuracy:1.0
Epoch:2572	training loss:0.3127758502960205	 training accuracy:1.0
Epoch:2573	training loss:0.31269019842147827	 training accuracy:1.0
Epoch:2574	training loss:0.31260424852371216	 training accuracy:1.0
Epoch:2575	training loss:0.3125178813934326	 training accuracy:1.0
Epoch:2576	training loss:0.3124317526817322	 training accuracy:1.0
Epoch:2577	training loss:0.31234607100486755	 training accuracy:1.0
Epoch:2578	training loss:0.3122607171535492	 training accuracy:1.0
Epoch:2579	training loss:0.3121751844882965	 training accuracy:1.0
Epoch:2580	training loss:0.3120896816253662	 training accuracy:1.0
Epoch:2581	training loss:0.3120042383670807	 training accuracy:1.0
Epoch:2582	training loss:0.3119186758995056	 training accuracy:1.0
Epoch:2583	training loss:0.31183260679244995	 training accuracy:1.0
Epoch:2584	training loss:0.31174707412719727	 training accuracy:1.0
Epoch:2585	training loss:0.3116621971130371	 training accuracy:1.0
Epoch:2586	training loss:0.31157708168029785	 training accuracy:1.0
Epoch:2587	training loss:0.3114914894104004	 training accuracy:1.0
Epoch:2588	training loss:0.31140580773353577	 training accuracy:1.0
Epoch:2589	training loss:0.31132036447525024	 training accuracy:1.0
Epoch:2590	training loss:0.311235636472702	 training accuracy:1.0
Epoch:2591	training loss:0.31115102767944336	 training accuracy:1.0
Epoch:2592	training loss:0.31106606125831604	 training accuracy:1.0
Epoch:2593	training loss:0.3109811246395111	 training accuracy:1.0
Epoch:2594	training loss:0.3108958303928375	 training accuracy:1.0
Epoch:2595	training loss:0.31081056594848633	 training accuracy:1.0
Epoch:2596	training loss:0.3107261657714844	 training accuracy:1.0
Epoch:2597	training loss:0.3106417655944824	 training accuracy:1.0
Epoch:2598	training loss:0.3105570077896118	 training accuracy:1.0
Epoch:2599	training loss:0.31047213077545166	 training accuracy:1.0
Epoch:2600	training loss:0.31038713455200195	 training accuracy:1.0
Epoch:2601	training loss:0.3103029131889343	 training accuracy:1.0
Epoch:2602	training loss:0.3102187216281891	 training accuracy:1.0
Epoch:2603	training loss:0.3101345896720886	 training accuracy:1.0
Epoch:2604	training loss:0.3100503385066986	 training accuracy:1.0
Epoch:2605	training loss:0.3099658489227295	 training accuracy:1.0
Epoch:2606	training loss:0.3098812401294708	 training accuracy:1.0
Epoch:2607	training loss:0.3097965717315674	 training accuracy:1.0
Epoch:2608	training loss:0.3097122311592102	 training accuracy:1.0
Epoch:2609	training loss:0.3096286654472351	 training accuracy:1.0
Epoch:2610	training loss:0.3095448315143585	 training accuracy:1.0
Epoch:2611	training loss:0.30946049094200134	 training accuracy:1.0
Epoch:2612	training loss:0.3093763291835785	 training accuracy:1.0
Epoch:2613	training loss:0.3092922866344452	 training accuracy:1.0
Epoch:2614	training loss:0.30920878052711487	 training accuracy:1.0
Epoch:2615	training loss:0.3091249465942383	 training accuracy:1.0
Epoch:2616	training loss:0.3090411126613617	 training accuracy:1.0
Epoch:2617	training loss:0.30895739793777466	 training accuracy:1.0
Epoch:2618	training loss:0.30887386202812195	 training accuracy:1.0
Epoch:2619	training loss:0.3087903559207916	 training accuracy:1.0
Epoch:2620	training loss:0.30870676040649414	 training accuracy:1.0
Epoch:2621	training loss:0.30862361192703247	 training accuracy:1.0
Epoch:2622	training loss:0.308540016412735	 training accuracy:1.0
Epoch:2623	training loss:0.3084564805030823	 training accuracy:1.0
Epoch:2624	training loss:0.3083729147911072	 training accuracy:1.0
Epoch:2625	training loss:0.30828917026519775	 training accuracy:1.0
Epoch:2626	training loss:0.30820587277412415	 training accuracy:1.0
Epoch:2627	training loss:0.30812332034111023	 training accuracy:1.0
Epoch:2628	training loss:0.30804044008255005	 training accuracy:1.0
Epoch:2629	training loss:0.3079569935798645	 training accuracy:1.0
Epoch:2630	training loss:0.30787360668182373	 training accuracy:1.0
Epoch:2631	training loss:0.30779051780700684	 training accuracy:1.0
Epoch:2632	training loss:0.30770814418792725	 training accuracy:1.0
Epoch:2633	training loss:0.307625949382782	 training accuracy:1.0
Epoch:2634	training loss:0.3075431287288666	 training accuracy:1.0
Epoch:2635	training loss:0.3074595332145691	 training accuracy:1.0
Epoch:2636	training loss:0.3073764443397522	 training accuracy:1.0
Epoch:2637	training loss:0.30729374289512634	 training accuracy:1.0
Epoch:2638	training loss:0.3072112500667572	 training accuracy:1.0
Epoch:2639	training loss:0.30712854862213135	 training accuracy:1.0
Epoch:2640	training loss:0.30704545974731445	 training accuracy:1.0
Epoch:2641	training loss:0.3069634735584259	 training accuracy:1.0
Epoch:2642	training loss:0.3068811297416687	 training accuracy:1.0
Epoch:2643	training loss:0.30679813027381897	 training accuracy:1.0
Epoch:2644	training loss:0.30671554803848267	 training accuracy:1.0
Epoch:2645	training loss:0.3066336214542389	 training accuracy:1.0
Epoch:2646	training loss:0.30655157566070557	 training accuracy:1.0
Epoch:2647	training loss:0.3064691424369812	 training accuracy:1.0
Epoch:2648	training loss:0.30638664960861206	 training accuracy:1.0
Epoch:2649	training loss:0.30630454421043396	 training accuracy:1.0
Epoch:2650	training loss:0.30622291564941406	 training accuracy:1.0
Epoch:2651	training loss:0.30614107847213745	 training accuracy:1.0
Epoch:2652	training loss:0.30605965852737427	 training accuracy:1.0
Epoch:2653	training loss:0.3059776723384857	 training accuracy:1.0
Epoch:2654	training loss:0.30589544773101807	 training accuracy:1.0
Epoch:2655	training loss:0.3058132827281952	 training accuracy:1.0
Epoch:2656	training loss:0.3057313561439514	 training accuracy:1.0
Epoch:2657	training loss:0.30564993619918823	 training accuracy:1.0
Epoch:2658	training loss:0.30556821823120117	 training accuracy:1.0
Epoch:2659	training loss:0.30548614263534546	 training accuracy:1.0
Epoch:2660	training loss:0.3054039180278778	 training accuracy:1.0
Epoch:2661	training loss:0.30532243847846985	 training accuracy:1.0
Epoch:2662	training loss:0.30524134635925293	 training accuracy:1.0
Epoch:2663	training loss:0.305160254240036	 training accuracy:1.0
Epoch:2664	training loss:0.30507898330688477	 training accuracy:1.0
Epoch:2665	training loss:0.3049975037574768	 training accuracy:1.0
Epoch:2666	training loss:0.304916113615036	 training accuracy:1.0
Epoch:2667	training loss:0.30483484268188477	 training accuracy:1.0
Epoch:2668	training loss:0.3047536611557007	 training accuracy:1.0
Epoch:2669	training loss:0.30467280745506287	 training accuracy:1.0
Epoch:2670	training loss:0.3045918047428131	 training accuracy:1.0
Epoch:2671	training loss:0.30451035499572754	 training accuracy:1.0
Epoch:2672	training loss:0.30442917346954346	 training accuracy:1.0
Epoch:2673	training loss:0.3043481409549713	 training accuracy:1.0
Epoch:2674	training loss:0.3042677044868469	 training accuracy:1.0
Epoch:2675	training loss:0.30418699979782104	 training accuracy:1.0
Epoch:2676	training loss:0.30410653352737427	 training accuracy:1.0
Epoch:2677	training loss:0.30402570962905884	 training accuracy:1.0
Epoch:2678	training loss:0.3039443790912628	 training accuracy:1.0
Epoch:2679	training loss:0.3038632273674011	 training accuracy:1.0
Epoch:2680	training loss:0.3037824332714081	 training accuracy:1.0
Epoch:2681	training loss:0.3037024438381195	 training accuracy:1.0
Epoch:2682	training loss:0.30362194776535034	 training accuracy:1.0
Epoch:2683	training loss:0.3035411238670349	 training accuracy:1.0
Epoch:2684	training loss:0.30346038937568665	 training accuracy:1.0
Epoch:2685	training loss:0.3033798336982727	 training accuracy:1.0
Epoch:2686	training loss:0.30329975485801697	 training accuracy:1.0
Epoch:2687	training loss:0.3032197058200836	 training accuracy:1.0
Epoch:2688	training loss:0.30313926935195923	 training accuracy:1.0
Epoch:2689	training loss:0.30305901169776917	 training accuracy:1.0
Epoch:2690	training loss:0.3029788136482239	 training accuracy:1.0
Epoch:2691	training loss:0.3028986155986786	 training accuracy:1.0
Epoch:2692	training loss:0.30281877517700195	 training accuracy:1.0
Epoch:2693	training loss:0.30273890495300293	 training accuracy:1.0
Epoch:2694	training loss:0.3026588559150696	 training accuracy:1.0
Epoch:2695	training loss:0.3025785982608795	 training accuracy:1.0
Epoch:2696	training loss:0.3024984300136566	 training accuracy:1.0
Epoch:2697	training loss:0.3024183511734009	 training accuracy:1.0
Epoch:2698	training loss:0.30233845114707947	 training accuracy:1.0
Epoch:2699	training loss:0.3022588789463043	 training accuracy:1.0
Epoch:2700	training loss:0.3021789789199829	 training accuracy:1.0
Epoch:2701	training loss:0.30209946632385254	 training accuracy:1.0
Epoch:2702	training loss:0.30201977491378784	 training accuracy:1.0
Epoch:2703	training loss:0.30194005370140076	 training accuracy:1.0
Epoch:2704	training loss:0.3018609583377838	 training accuracy:1.0
Epoch:2705	training loss:0.3017820119857788	 training accuracy:1.0
Epoch:2706	training loss:0.30170270800590515	 training accuracy:1.0
Epoch:2707	training loss:0.3016229271888733	 training accuracy:1.0
Epoch:2708	training loss:0.30154335498809814	 training accuracy:1.0
Epoch:2709	training loss:0.3014640808105469	 training accuracy:1.0
Epoch:2710	training loss:0.3013848662376404	 training accuracy:1.0
Epoch:2711	training loss:0.30130547285079956	 training accuracy:1.0
Epoch:2712	training loss:0.30122634768486023	 training accuracy:1.0
Epoch:2713	training loss:0.3011474013328552	 training accuracy:1.0
Epoch:2714	training loss:0.30106812715530396	 training accuracy:1.0
Epoch:2715	training loss:0.30098849534988403	 training accuracy:1.0
Epoch:2716	training loss:0.30090945959091187	 training accuracy:1.0
Epoch:2717	training loss:0.3008308708667755	 training accuracy:1.0
Epoch:2718	training loss:0.3007522225379944	 training accuracy:1.0
Epoch:2719	training loss:0.30067265033721924	 training accuracy:1.0
Epoch:2720	training loss:0.30059319734573364	 training accuracy:1.0
Epoch:2721	training loss:0.300514817237854	 training accuracy:1.0
Epoch:2722	training loss:0.30043673515319824	 training accuracy:1.0
Epoch:2723	training loss:0.3003585934638977	 training accuracy:1.0
Epoch:2724	training loss:0.3002800941467285	 training accuracy:1.0
Epoch:2725	training loss:0.30020105838775635	 training accuracy:1.0
Epoch:2726	training loss:0.30012229084968567	 training accuracy:1.0
Epoch:2727	training loss:0.30004364252090454	 training accuracy:1.0
Epoch:2728	training loss:0.2999649941921234	 training accuracy:1.0
Epoch:2729	training loss:0.2998870611190796	 training accuracy:1.0
Epoch:2730	training loss:0.29980894923210144	 training accuracy:1.0
Epoch:2731	training loss:0.29973065853118896	 training accuracy:1.0
Epoch:2732	training loss:0.2996522784233093	 training accuracy:1.0
Epoch:2733	training loss:0.2995736598968506	 training accuracy:1.0
Epoch:2734	training loss:0.2994953393936157	 training accuracy:1.0
Epoch:2735	training loss:0.2994174063205719	 training accuracy:1.0
Epoch:2736	training loss:0.29933950304985046	 training accuracy:1.0
Epoch:2737	training loss:0.299261212348938	 training accuracy:1.0
Epoch:2738	training loss:0.29918280243873596	 training accuracy:1.0
Epoch:2739	training loss:0.29910457134246826	 training accuracy:1.0
Epoch:2740	training loss:0.2990267872810364	 training accuracy:1.0
Epoch:2741	training loss:0.29894933104515076	 training accuracy:1.0
Epoch:2742	training loss:0.2988714575767517	 training accuracy:1.0
Epoch:2743	training loss:0.2987932562828064	 training accuracy:1.0
Epoch:2744	training loss:0.29871517419815063	 training accuracy:1.0
Epoch:2745	training loss:0.298637330532074	 training accuracy:1.0
Epoch:2746	training loss:0.2985599637031555	 training accuracy:1.0
Epoch:2747	training loss:0.2984824776649475	 training accuracy:1.0
Epoch:2748	training loss:0.298404723405838	 training accuracy:1.0
Epoch:2749	training loss:0.29832711815834045	 training accuracy:1.0
Epoch:2750	training loss:0.2982495129108429	 training accuracy:1.0
Epoch:2751	training loss:0.2981717586517334	 training accuracy:1.0
Epoch:2752	training loss:0.2980944514274597	 training accuracy:1.0
Epoch:2753	training loss:0.29801779985427856	 training accuracy:1.0
Epoch:2754	training loss:0.29794055223464966	 training accuracy:1.0
Epoch:2755	training loss:0.29786252975463867	 training accuracy:1.0
Epoch:2756	training loss:0.29778510332107544	 training accuracy:1.0
Epoch:2757	training loss:0.29770806431770325	 training accuracy:1.0
Epoch:2758	training loss:0.2976313829421997	 training accuracy:1.0
Epoch:2759	training loss:0.2975544333457947	 training accuracy:1.0
Epoch:2760	training loss:0.29747694730758667	 training accuracy:1.0
Epoch:2761	training loss:0.29740017652511597	 training accuracy:1.0
Epoch:2762	training loss:0.2973233461380005	 training accuracy:1.0
Epoch:2763	training loss:0.29724615812301636	 training accuracy:1.0
Epoch:2764	training loss:0.29716938734054565	 training accuracy:1.0
Epoch:2765	training loss:0.297092467546463	 training accuracy:1.0
Epoch:2766	training loss:0.2970154285430908	 training accuracy:1.0
Epoch:2767	training loss:0.29693856835365295	 training accuracy:1.0
Epoch:2768	training loss:0.296861469745636	 training accuracy:1.0
Epoch:2769	training loss:0.29678449034690857	 training accuracy:1.0
Epoch:2770	training loss:0.2967079281806946	 training accuracy:1.0
Epoch:2771	training loss:0.29663166403770447	 training accuracy:1.0
Epoch:2772	training loss:0.2965552508831024	 training accuracy:1.0
Epoch:2773	training loss:0.2964785695075989	 training accuracy:1.0
Epoch:2774	training loss:0.2964016795158386	 training accuracy:1.0
Epoch:2775	training loss:0.29632484912872314	 training accuracy:1.0
Epoch:2776	training loss:0.2962487041950226	 training accuracy:1.0
Epoch:2777	training loss:0.2961728572845459	 training accuracy:1.0
Epoch:2778	training loss:0.2960965931415558	 training accuracy:1.0
Epoch:2779	training loss:0.296019583940506	 training accuracy:1.0
Epoch:2780	training loss:0.29594290256500244	 training accuracy:1.0
Epoch:2781	training loss:0.29586708545684814	 training accuracy:1.0
Epoch:2782	training loss:0.29579123854637146	 training accuracy:1.0
Epoch:2783	training loss:0.2957153022289276	 training accuracy:1.0
Epoch:2784	training loss:0.2956390082836151	 training accuracy:1.0
Epoch:2785	training loss:0.2955630123615265	 training accuracy:1.0
Epoch:2786	training loss:0.2954871654510498	 training accuracy:1.0
Epoch:2787	training loss:0.2954111099243164	 training accuracy:1.0
Epoch:2788	training loss:0.2953351140022278	 training accuracy:1.0
Epoch:2789	training loss:0.2952597141265869	 training accuracy:1.0
Epoch:2790	training loss:0.2951838970184326	 training accuracy:1.0
Epoch:2791	training loss:0.29510772228240967	 training accuracy:1.0
Epoch:2792	training loss:0.2950318157672882	 training accuracy:1.0
Epoch:2793	training loss:0.294955849647522	 training accuracy:1.0
Epoch:2794	training loss:0.2948804795742035	 training accuracy:1.0
Epoch:2795	training loss:0.29480525851249695	 training accuracy:1.0
Epoch:2796	training loss:0.2947300672531128	 training accuracy:1.0
Epoch:2797	training loss:0.29465436935424805	 training accuracy:1.0
Epoch:2798	training loss:0.2945784032344818	 training accuracy:1.0
Epoch:2799	training loss:0.29450279474258423	 training accuracy:1.0
Epoch:2800	training loss:0.2944272756576538	 training accuracy:1.0
Epoch:2801	training loss:0.29435235261917114	 training accuracy:1.0
Epoch:2802	training loss:0.2942771315574646	 training accuracy:1.0
Epoch:2803	training loss:0.29420149326324463	 training accuracy:1.0
Epoch:2804	training loss:0.2941257059574127	 training accuracy:1.0
Epoch:2805	training loss:0.29405009746551514	 training accuracy:1.0
Epoch:2806	training loss:0.2939750552177429	 training accuracy:1.0
Epoch:2807	training loss:0.2939002811908722	 training accuracy:1.0
Epoch:2808	training loss:0.29382506012916565	 training accuracy:1.0
Epoch:2809	training loss:0.29374992847442627	 training accuracy:1.0
Epoch:2810	training loss:0.2936747372150421	 training accuracy:1.0
Epoch:2811	training loss:0.2935997545719147	 training accuracy:1.0
Epoch:2812	training loss:0.2935252785682678	 training accuracy:1.0
Epoch:2813	training loss:0.2934507131576538	 training accuracy:1.0
Epoch:2814	training loss:0.29337599873542786	 training accuracy:1.0
Epoch:2815	training loss:0.2933007478713989	 training accuracy:1.0
Epoch:2816	training loss:0.29322582483291626	 training accuracy:1.0
Epoch:2817	training loss:0.2931511402130127	 training accuracy:1.0
Epoch:2818	training loss:0.2930765151977539	 training accuracy:1.0
Epoch:2819	training loss:0.29300186038017273	 training accuracy:1.0
Epoch:2820	training loss:0.29292723536491394	 training accuracy:1.0
Epoch:2821	training loss:0.29285290837287903	 training accuracy:1.0
Epoch:2822	training loss:0.29277804493904114	 training accuracy:1.0
Epoch:2823	training loss:0.29270318150520325	 training accuracy:1.0
Epoch:2824	training loss:0.292628675699234	 training accuracy:1.0
Epoch:2825	training loss:0.29255470633506775	 training accuracy:1.0
Epoch:2826	training loss:0.2924802899360657	 training accuracy:1.0
Epoch:2827	training loss:0.29240554571151733	 training accuracy:1.0
Epoch:2828	training loss:0.292330801486969	 training accuracy:1.0
Epoch:2829	training loss:0.29225653409957886	 training accuracy:1.0
Epoch:2830	training loss:0.29218265414237976	 training accuracy:1.0
Epoch:2831	training loss:0.2921086549758911	 training accuracy:1.0
Epoch:2832	training loss:0.29203444719314575	 training accuracy:1.0
Epoch:2833	training loss:0.29196032881736755	 training accuracy:1.0
Epoch:2834	training loss:0.29188618063926697	 training accuracy:1.0
Epoch:2835	training loss:0.2918117344379425	 training accuracy:1.0
Epoch:2836	training loss:0.2917376160621643	 training accuracy:1.0
Epoch:2837	training loss:0.2916639745235443	 training accuracy:1.0
Epoch:2838	training loss:0.2915900647640228	 training accuracy:1.0
Epoch:2839	training loss:0.2915158271789551	 training accuracy:1.0
Epoch:2840	training loss:0.29144150018692017	 training accuracy:1.0
Epoch:2841	training loss:0.29136770963668823	 training accuracy:1.0
Epoch:2842	training loss:0.29129451513290405	 training accuracy:1.0
Epoch:2843	training loss:0.2912214994430542	 training accuracy:1.0
Epoch:2844	training loss:0.2911480665206909	 training accuracy:1.0
Epoch:2845	training loss:0.29107415676116943	 training accuracy:1.0
Epoch:2846	training loss:0.29100024700164795	 training accuracy:1.0
Epoch:2847	training loss:0.29092633724212646	 training accuracy:1.0
Epoch:2848	training loss:0.29085296392440796	 training accuracy:1.0
Epoch:2849	training loss:0.2907800078392029	 training accuracy:1.0
Epoch:2850	training loss:0.2907066345214844	 training accuracy:1.0
Epoch:2851	training loss:0.2906329929828644	 training accuracy:1.0
Epoch:2852	training loss:0.29055947065353394	 training accuracy:1.0
Epoch:2853	training loss:0.2904859781265259	 training accuracy:1.0
Epoch:2854	training loss:0.2904125452041626	 training accuracy:1.0
Epoch:2855	training loss:0.29033905267715454	 training accuracy:1.0
Epoch:2856	training loss:0.29026561975479126	 training accuracy:1.0
Epoch:2857	training loss:0.29019254446029663	 training accuracy:1.0
Epoch:2858	training loss:0.2901192009449005	 training accuracy:1.0
Epoch:2859	training loss:0.2900456488132477	 training accuracy:1.0
Epoch:2860	training loss:0.28997230529785156	 training accuracy:1.0
Epoch:2861	training loss:0.2898997366428375	 training accuracy:1.0
Epoch:2862	training loss:0.28982698917388916	 training accuracy:1.0
Epoch:2863	training loss:0.2897537350654602	 training accuracy:1.0
Epoch:2864	training loss:0.2896803915500641	 training accuracy:1.0
Epoch:2865	training loss:0.289607435464859	 training accuracy:1.0
Epoch:2866	training loss:0.2895350456237793	 training accuracy:1.0
Epoch:2867	training loss:0.2894626557826996	 training accuracy:1.0
Epoch:2868	training loss:0.2893899083137512	 training accuracy:1.0
Epoch:2869	training loss:0.2893167734146118	 training accuracy:1.0
Epoch:2870	training loss:0.2892439067363739	 training accuracy:1.0
Epoch:2871	training loss:0.2891715466976166	 training accuracy:1.0
Epoch:2872	training loss:0.28909945487976074	 training accuracy:1.0
Epoch:2873	training loss:0.28902727365493774	 training accuracy:1.0
Epoch:2874	training loss:0.2889544367790222	 training accuracy:1.0
Epoch:2875	training loss:0.28888139128685	 training accuracy:1.0
Epoch:2876	training loss:0.2888088524341583	 training accuracy:1.0
Epoch:2877	training loss:0.2887360453605652	 training accuracy:1.0
Epoch:2878	training loss:0.2886633574962616	 training accuracy:1.0
Epoch:2879	training loss:0.288591206073761	 training accuracy:1.0
Epoch:2880	training loss:0.28851860761642456	 training accuracy:1.0
Epoch:2881	training loss:0.28844642639160156	 training accuracy:1.0
Epoch:2882	training loss:0.2883741557598114	 training accuracy:1.0
Epoch:2883	training loss:0.2883016765117645	 training accuracy:1.0
Epoch:2884	training loss:0.2882300019264221	 training accuracy:1.0
Epoch:2885	training loss:0.2881581783294678	 training accuracy:1.0
Epoch:2886	training loss:0.2880862057209015	 training accuracy:1.0
Epoch:2887	training loss:0.2880135774612427	 training accuracy:1.0
Epoch:2888	training loss:0.2879410982131958	 training accuracy:1.0
Epoch:2889	training loss:0.28786930441856384	 training accuracy:1.0
Epoch:2890	training loss:0.28779762983322144	 training accuracy:1.0
Epoch:2891	training loss:0.2877257466316223	 training accuracy:1.0
Epoch:2892	training loss:0.2876538634300232	 training accuracy:1.0
Epoch:2893	training loss:0.28758224844932556	 training accuracy:1.0
Epoch:2894	training loss:0.28751006722450256	 training accuracy:1.0
Epoch:2895	training loss:0.287437379360199	 training accuracy:1.0
Epoch:2896	training loss:0.2873654067516327	 training accuracy:1.0
Epoch:2897	training loss:0.2872943878173828	 training accuracy:1.0
Epoch:2898	training loss:0.2872230112552643	 training accuracy:1.0
Epoch:2899	training loss:0.2871508300304413	 training accuracy:1.0
Epoch:2900	training loss:0.2870786786079407	 training accuracy:1.0
Epoch:2901	training loss:0.28700733184814453	 training accuracy:1.0
Epoch:2902	training loss:0.28693637251853943	 training accuracy:1.0
Epoch:2903	training loss:0.2868651747703552	 training accuracy:1.0
Epoch:2904	training loss:0.2867937684059143	 training accuracy:1.0
Epoch:2905	training loss:0.2867221236228943	 training accuracy:1.0
Epoch:2906	training loss:0.286650687456131	 training accuracy:1.0
Epoch:2907	training loss:0.2865794897079468	 training accuracy:1.0
Epoch:2908	training loss:0.28650787472724915	 training accuracy:1.0
Epoch:2909	training loss:0.28643637895584106	 training accuracy:1.0
Epoch:2910	training loss:0.2863650321960449	 training accuracy:1.0
Epoch:2911	training loss:0.28629398345947266	 training accuracy:1.0
Epoch:2912	training loss:0.2862226068973541	 training accuracy:1.0
Epoch:2913	training loss:0.28615105152130127	 training accuracy:1.0
Epoch:2914	training loss:0.28607994318008423	 training accuracy:1.0
Epoch:2915	training loss:0.2860091030597687	 training accuracy:1.0
Epoch:2916	training loss:0.2859382927417755	 training accuracy:1.0
Epoch:2917	training loss:0.2858671247959137	 training accuracy:1.0
Epoch:2918	training loss:0.2857958972454071	 training accuracy:1.0
Epoch:2919	training loss:0.28572455048561096	 training accuracy:1.0
Epoch:2920	training loss:0.28565359115600586	 training accuracy:1.0
Epoch:2921	training loss:0.28558334708213806	 training accuracy:1.0
Epoch:2922	training loss:0.28551268577575684	 training accuracy:1.0
Epoch:2923	training loss:0.2854413390159607	 training accuracy:1.0
Epoch:2924	training loss:0.28537023067474365	 training accuracy:1.0
Epoch:2925	training loss:0.28529950976371765	 training accuracy:1.0
Epoch:2926	training loss:0.28522923588752747	 training accuracy:1.0
Epoch:2927	training loss:0.2851588726043701	 training accuracy:1.0
Epoch:2928	training loss:0.2850881814956665	 training accuracy:1.0
Epoch:2929	training loss:0.2850176990032196	 training accuracy:1.0
Epoch:2930	training loss:0.28494685888290405	 training accuracy:1.0
Epoch:2931	training loss:0.2848760783672333	 training accuracy:1.0
Epoch:2932	training loss:0.2848058342933655	 training accuracy:1.0
Epoch:2933	training loss:0.2847360074520111	 training accuracy:1.0
Epoch:2934	training loss:0.28466546535491943	 training accuracy:1.0
Epoch:2935	training loss:0.2845945358276367	 training accuracy:1.0
Epoch:2936	training loss:0.28452378511428833	 training accuracy:1.0
Epoch:2937	training loss:0.2844533920288086	 training accuracy:1.0
Epoch:2938	training loss:0.2843834459781647	 training accuracy:1.0
Epoch:2939	training loss:0.2843136787414551	 training accuracy:1.0
Epoch:2940	training loss:0.2842433452606201	 training accuracy:1.0
Epoch:2941	training loss:0.2841731011867523	 training accuracy:1.0
Epoch:2942	training loss:0.28410276770591736	 training accuracy:1.0
Epoch:2943	training loss:0.28403225541114807	 training accuracy:1.0
Epoch:2944	training loss:0.28396227955818176	 training accuracy:1.0
Epoch:2945	training loss:0.2838924527168274	 training accuracy:1.0
Epoch:2946	training loss:0.2838224768638611	 training accuracy:1.0
Epoch:2947	training loss:0.2837522625923157	 training accuracy:1.0
Epoch:2948	training loss:0.28368186950683594	 training accuracy:1.0
Epoch:2949	training loss:0.2836117744445801	 training accuracy:1.0
Epoch:2950	training loss:0.2835420072078705	 training accuracy:1.0
Epoch:2951	training loss:0.2834722399711609	 training accuracy:1.0
Epoch:2952	training loss:0.2834025025367737	 training accuracy:1.0
Epoch:2953	training loss:0.28333282470703125	 training accuracy:1.0
Epoch:2954	training loss:0.28326305747032166	 training accuracy:1.0
Epoch:2955	training loss:0.2831932008266449	 training accuracy:1.0
Epoch:2956	training loss:0.2831239104270935	 training accuracy:1.0
Epoch:2957	training loss:0.28305456042289734	 training accuracy:1.0
Epoch:2958	training loss:0.28298482298851013	 training accuracy:1.0
Epoch:2959	training loss:0.28291478753089905	 training accuracy:1.0
Epoch:2960	training loss:0.28284499049186707	 training accuracy:1.0
Epoch:2961	training loss:0.28277575969696045	 training accuracy:1.0
Epoch:2962	training loss:0.2827063798904419	 training accuracy:1.0
Epoch:2963	training loss:0.28263720870018005	 training accuracy:1.0
Epoch:2964	training loss:0.2825680375099182	 training accuracy:1.0
Epoch:2965	training loss:0.28249841928482056	 training accuracy:1.0
Epoch:2966	training loss:0.2824287712574005	 training accuracy:1.0
Epoch:2967	training loss:0.28235912322998047	 training accuracy:1.0
Epoch:2968	training loss:0.28228962421417236	 training accuracy:1.0
Epoch:2969	training loss:0.2822210192680359	 training accuracy:1.0
Epoch:2970	training loss:0.28215205669403076	 training accuracy:1.0
Epoch:2971	training loss:0.2820824086666107	 training accuracy:1.0
Epoch:2972	training loss:0.28201305866241455	 training accuracy:1.0
Epoch:2973	training loss:0.2819439172744751	 training accuracy:1.0
Epoch:2974	training loss:0.28187522292137146	 training accuracy:1.0
Epoch:2975	training loss:0.2818062901496887	 training accuracy:1.0
Epoch:2976	training loss:0.28173720836639404	 training accuracy:1.0
Epoch:2977	training loss:0.2816682755947113	 training accuracy:1.0
Epoch:2978	training loss:0.2815992832183838	 training accuracy:1.0
Epoch:2979	training loss:0.28153014183044434	 training accuracy:1.0
Epoch:2980	training loss:0.2814609408378601	 training accuracy:1.0
Epoch:2981	training loss:0.28139230608940125	 training accuracy:1.0
Epoch:2982	training loss:0.28132370114326477	 training accuracy:1.0
Epoch:2983	training loss:0.2812548577785492	 training accuracy:1.0
Epoch:2984	training loss:0.2811858355998993	 training accuracy:1.0
Epoch:2985	training loss:0.28111669421195984	 training accuracy:1.0
Epoch:2986	training loss:0.281048059463501	 training accuracy:1.0
Epoch:2987	training loss:0.28098002076148987	 training accuracy:1.0
Epoch:2988	training loss:0.28091171383857727	 training accuracy:1.0
Epoch:2989	training loss:0.28084275126457214	 training accuracy:1.0
Epoch:2990	training loss:0.2807738184928894	 training accuracy:1.0
Epoch:2991	training loss:0.2807052731513977	 training accuracy:1.0
Epoch:2992	training loss:0.28063732385635376	 training accuracy:1.0
Epoch:2993	training loss:0.2805696129798889	 training accuracy:1.0
Epoch:2994	training loss:0.2805011570453644	 training accuracy:1.0
Epoch:2995	training loss:0.28043216466903687	 training accuracy:1.0
Epoch:2996	training loss:0.2803635895252228	 training accuracy:1.0
Epoch:2997	training loss:0.2802954316139221	 training accuracy:1.0
Epoch:2998	training loss:0.2802272140979767	 training accuracy:1.0
Epoch:2999	training loss:0.2801586985588074	 training accuracy:1.0
Epoch:3000	training loss:0.2800900638103485	 training accuracy:1.0
Epoch:3001	training loss:0.28003403544425964	 training accuracy:1.0
Epoch:3002	training loss:0.2799781858921051	 training accuracy:1.0
Epoch:3003	training loss:0.27992507815361023	 training accuracy:1.0
Epoch:3004	training loss:0.2798742651939392	 training accuracy:1.0
Epoch:3005	training loss:0.2798230051994324	 training accuracy:1.0
Epoch:3006	training loss:0.27976956963539124	 training accuracy:1.0
Epoch:3007	training loss:0.27971550822257996	 training accuracy:1.0
Epoch:3008	training loss:0.27966225147247314	 training accuracy:1.0
Epoch:3009	training loss:0.2796105742454529	 training accuracy:1.0
Epoch:3010	training loss:0.2795582711696625	 training accuracy:1.0
Epoch:3011	training loss:0.2795054316520691	 training accuracy:1.0
Epoch:3012	training loss:0.2794523537158966	 training accuracy:1.0
Epoch:3013	training loss:0.27939897775650024	 training accuracy:1.0
Epoch:3014	training loss:0.279346764087677	 training accuracy:1.0
Epoch:3015	training loss:0.2792946398258209	 training accuracy:1.0
Epoch:3016	training loss:0.2792414426803589	 training accuracy:1.0
Epoch:3017	training loss:0.2791888415813446	 training accuracy:1.0
Epoch:3018	training loss:0.27913644909858704	 training accuracy:1.0
Epoch:3019	training loss:0.2790839374065399	 training accuracy:1.0
Epoch:3020	training loss:0.27903178334236145	 training accuracy:1.0
Epoch:3021	training loss:0.27897942066192627	 training accuracy:1.0
Epoch:3022	training loss:0.2789267599582672	 training accuracy:1.0
Epoch:3023	training loss:0.27887436747550964	 training accuracy:1.0
Epoch:3024	training loss:0.2788222134113312	 training accuracy:1.0
Epoch:3025	training loss:0.2787700295448303	 training accuracy:1.0
Epoch:3026	training loss:0.27871766686439514	 training accuracy:1.0
Epoch:3027	training loss:0.2786656618118286	 training accuracy:1.0
Epoch:3028	training loss:0.27861347794532776	 training accuracy:1.0
Epoch:3029	training loss:0.27856141328811646	 training accuracy:1.0
Epoch:3030	training loss:0.2785095274448395	 training accuracy:1.0
Epoch:3031	training loss:0.2784573435783386	 training accuracy:1.0
Epoch:3032	training loss:0.2784052789211273	 training accuracy:1.0
Epoch:3033	training loss:0.27835381031036377	 training accuracy:1.0
Epoch:3034	training loss:0.27830183506011963	 training accuracy:1.0
Epoch:3035	training loss:0.2782493531703949	 training accuracy:1.0
Epoch:3036	training loss:0.27819737792015076	 training accuracy:1.0
Epoch:3037	training loss:0.27814510464668274	 training accuracy:1.0
Epoch:3038	training loss:0.2780931890010834	 training accuracy:1.0
Epoch:3039	training loss:0.2780414819717407	 training accuracy:1.0
Epoch:3040	training loss:0.2779892683029175	 training accuracy:1.0
Epoch:3041	training loss:0.27793756127357483	 training accuracy:1.0
Epoch:3042	training loss:0.277885764837265	 training accuracy:1.0
Epoch:3043	training loss:0.2778337299823761	 training accuracy:1.0
Epoch:3044	training loss:0.2777819335460663	 training accuracy:1.0
Epoch:3045	training loss:0.2777301073074341	 training accuracy:1.0
Epoch:3046	training loss:0.2776782214641571	 training accuracy:1.0
Epoch:3047	training loss:0.2776263952255249	 training accuracy:1.0
Epoch:3048	training loss:0.277574360370636	 training accuracy:1.0
Epoch:3049	training loss:0.2775227427482605	 training accuracy:1.0
Epoch:3050	training loss:0.2774711549282074	 training accuracy:1.0
Epoch:3051	training loss:0.2774195969104767	 training accuracy:1.0
Epoch:3052	training loss:0.27736788988113403	 training accuracy:1.0
Epoch:3053	training loss:0.277316153049469	 training accuracy:1.0
Epoch:3054	training loss:0.27726441621780396	 training accuracy:1.0
Epoch:3055	training loss:0.2772124409675598	 training accuracy:1.0
Epoch:3056	training loss:0.2771609425544739	 training accuracy:1.0
Epoch:3057	training loss:0.27710965275764465	 training accuracy:1.0
Epoch:3058	training loss:0.27705803513526917	 training accuracy:1.0
Epoch:3059	training loss:0.27700603008270264	 training accuracy:1.0
Epoch:3060	training loss:0.27695441246032715	 training accuracy:1.0
Epoch:3061	training loss:0.2769032418727875	 training accuracy:1.0
Epoch:3062	training loss:0.2768515348434448	 training accuracy:1.0
Epoch:3063	training loss:0.2767997682094574	 training accuracy:1.0
Epoch:3064	training loss:0.27674826979637146	 training accuracy:1.0
Epoch:3065	training loss:0.2766968607902527	 training accuracy:1.0
Epoch:3066	training loss:0.2766451835632324	 training accuracy:1.0
Epoch:3067	training loss:0.2765933871269226	 training accuracy:1.0
Epoch:3068	training loss:0.2765418589115143	 training accuracy:1.0
Epoch:3069	training loss:0.27649059891700745	 training accuracy:1.0
Epoch:3070	training loss:0.27643921971321106	 training accuracy:1.0
Epoch:3071	training loss:0.2763877809047699	 training accuracy:1.0
Epoch:3072	training loss:0.27633607387542725	 training accuracy:1.0
Epoch:3073	training loss:0.27628448605537415	 training accuracy:1.0
Epoch:3074	training loss:0.27623361349105835	 training accuracy:1.0
Epoch:3075	training loss:0.2761824131011963	 training accuracy:1.0
Epoch:3076	training loss:0.27613121271133423	 training accuracy:1.0
Epoch:3077	training loss:0.2760796546936035	 training accuracy:1.0
Epoch:3078	training loss:0.276028037071228	 training accuracy:1.0
Epoch:3079	training loss:0.2759765684604645	 training accuracy:1.0
Epoch:3080	training loss:0.27592504024505615	 training accuracy:1.0
Epoch:3081	training loss:0.27587419748306274	 training accuracy:1.0
Epoch:3082	training loss:0.2758229672908783	 training accuracy:1.0
Epoch:3083	training loss:0.27577149868011475	 training accuracy:1.0
Epoch:3084	training loss:0.27571988105773926	 training accuracy:1.0
Epoch:3085	training loss:0.27566835284233093	 training accuracy:1.0
Epoch:3086	training loss:0.27561745047569275	 training accuracy:1.0
Epoch:3087	training loss:0.27556663751602173	 training accuracy:1.0
Epoch:3088	training loss:0.27551525831222534	 training accuracy:1.0
Epoch:3089	training loss:0.2754640281200409	 training accuracy:1.0
Epoch:3090	training loss:0.27541282773017883	 training accuracy:1.0
Epoch:3091	training loss:0.27536168694496155	 training accuracy:1.0
Epoch:3092	training loss:0.2753112018108368	 training accuracy:1.0
Epoch:3093	training loss:0.27526021003723145	 training accuracy:1.0
Epoch:3094	training loss:0.2752090096473694	 training accuracy:1.0
Epoch:3095	training loss:0.275157630443573	 training accuracy:1.0
Epoch:3096	training loss:0.2751064598560333	 training accuracy:1.0
Epoch:3097	training loss:0.2750553786754608	 training accuracy:1.0
Epoch:3098	training loss:0.2750042974948883	 training accuracy:1.0
Epoch:3099	training loss:0.2749532163143158	 training accuracy:1.0
Epoch:3100	training loss:0.27490198612213135	 training accuracy:1.0
Epoch:3101	training loss:0.2748512029647827	 training accuracy:1.0
Epoch:3102	training loss:0.2748000919818878	 training accuracy:1.0
Epoch:3103	training loss:0.27474865317344666	 training accuracy:1.0
Epoch:3104	training loss:0.27469775080680847	 training accuracy:1.0
Epoch:3105	training loss:0.2746473550796509	 training accuracy:1.0
Epoch:3106	training loss:0.274596631526947	 training accuracy:1.0
Epoch:3107	training loss:0.274545282125473	 training accuracy:1.0
Epoch:3108	training loss:0.27449384331703186	 training accuracy:1.0
Epoch:3109	training loss:0.27444300055503845	 training accuracy:1.0
Epoch:3110	training loss:0.27439257502555847	 training accuracy:1.0
Epoch:3111	training loss:0.27434173226356506	 training accuracy:1.0
Epoch:3112	training loss:0.27429065108299255	 training accuracy:1.0
Epoch:3113	training loss:0.27423983812332153	 training accuracy:1.0
Epoch:3114	training loss:0.27418914437294006	 training accuracy:1.0
Epoch:3115	training loss:0.27413833141326904	 training accuracy:1.0
Epoch:3116	training loss:0.27408769726753235	 training accuracy:1.0
Epoch:3117	training loss:0.2740369439125061	 training accuracy:1.0
Epoch:3118	training loss:0.27398595213890076	 training accuracy:1.0
Epoch:3119	training loss:0.2739349603652954	 training accuracy:1.0
Epoch:3120	training loss:0.2738839387893677	 training accuracy:1.0
Epoch:3121	training loss:0.2738332748413086	 training accuracy:1.0
Epoch:3122	training loss:0.2737825810909271	 training accuracy:1.0
Epoch:3123	training loss:0.27373242378234863	 training accuracy:1.0
Epoch:3124	training loss:0.2736821174621582	 training accuracy:1.0
Epoch:3125	training loss:0.2736312448978424	 training accuracy:1.0
Epoch:3126	training loss:0.2735801339149475	 training accuracy:1.0
Epoch:3127	training loss:0.2735293507575989	 training accuracy:1.0
Epoch:3128	training loss:0.2734789252281189	 training accuracy:1.0
Epoch:3129	training loss:0.2734287977218628	 training accuracy:1.0
Epoch:3130	training loss:0.27337825298309326	 training accuracy:1.0
Epoch:3131	training loss:0.2733272910118103	 training accuracy:1.0
Epoch:3132	training loss:0.27327650785446167	 training accuracy:1.0
Epoch:3133	training loss:0.27322596311569214	 training accuracy:1.0
Epoch:3134	training loss:0.2731756865978241	 training accuracy:1.0
Epoch:3135	training loss:0.2731250524520874	 training accuracy:1.0
Epoch:3136	training loss:0.273074209690094	 training accuracy:1.0
Epoch:3137	training loss:0.2730240523815155	 training accuracy:1.0
Epoch:3138	training loss:0.27297356724739075	 training accuracy:1.0
Epoch:3139	training loss:0.27292272448539734	 training accuracy:1.0
Epoch:3140	training loss:0.27287188172340393	 training accuracy:1.0
Epoch:3141	training loss:0.2728216052055359	 training accuracy:1.0
Epoch:3142	training loss:0.27277135848999023	 training accuracy:1.0
Epoch:3143	training loss:0.27272093296051025	 training accuracy:1.0
Epoch:3144	training loss:0.2726704478263855	 training accuracy:1.0
Epoch:3145	training loss:0.27262014150619507	 training accuracy:1.0
Epoch:3146	training loss:0.27257004380226135	 training accuracy:1.0
Epoch:3147	training loss:0.27251991629600525	 training accuracy:1.0
Epoch:3148	training loss:0.27246975898742676	 training accuracy:1.0
Epoch:3149	training loss:0.2724192142486572	 training accuracy:1.0
Epoch:3150	training loss:0.27236855030059814	 training accuracy:1.0
Epoch:3151	training loss:0.27231845259666443	 training accuracy:1.0
Epoch:3152	training loss:0.2722683548927307	 training accuracy:1.0
Epoch:3153	training loss:0.2722182869911194	 training accuracy:1.0
Epoch:3154	training loss:0.2721679210662842	 training accuracy:1.0
Epoch:3155	training loss:0.27211737632751465	 training accuracy:1.0
Epoch:3156	training loss:0.2720668613910675	 training accuracy:1.0
Epoch:3157	training loss:0.2720165252685547	 training accuracy:1.0
Epoch:3158	training loss:0.2719663679599762	 training accuracy:1.0
Epoch:3159	training loss:0.27191632986068726	 training accuracy:1.0
Epoch:3160	training loss:0.2718656361103058	 training accuracy:1.0
Epoch:3161	training loss:0.27181586623191833	 training accuracy:1.0
Epoch:3162	training loss:0.2717658281326294	 training accuracy:1.0
Epoch:3163	training loss:0.2717154026031494	 training accuracy:1.0
Epoch:3164	training loss:0.27166545391082764	 training accuracy:1.0
Epoch:3165	training loss:0.2716154158115387	 training accuracy:1.0
Epoch:3166	training loss:0.2715652883052826	 training accuracy:1.0
Epoch:3167	training loss:0.2715149223804474	 training accuracy:1.0
Epoch:3168	training loss:0.2714645564556122	 training accuracy:1.0
Epoch:3169	training loss:0.27141472697257996	 training accuracy:1.0
Epoch:3170	training loss:0.2713651955127716	 training accuracy:1.0
Epoch:3171	training loss:0.27131524682044983	 training accuracy:1.0
Epoch:3172	training loss:0.27126532793045044	 training accuracy:1.0
Epoch:3173	training loss:0.27121537923812866	 training accuracy:1.0
Epoch:3174	training loss:0.2711649537086487	 training accuracy:1.0
Epoch:3175	training loss:0.27111443877220154	 training accuracy:1.0
Epoch:3176	training loss:0.27106449007987976	 training accuracy:1.0
Epoch:3177	training loss:0.27101510763168335	 training accuracy:1.0
Epoch:3178	training loss:0.2709650993347168	 training accuracy:1.0
Epoch:3179	training loss:0.270914763212204	 training accuracy:1.0
Epoch:3180	training loss:0.27086445689201355	 training accuracy:1.0
Epoch:3181	training loss:0.27081483602523804	 training accuracy:1.0
Epoch:3182	training loss:0.27076536417007446	 training accuracy:1.0
Epoch:3183	training loss:0.2707156240940094	 training accuracy:1.0
Epoch:3184	training loss:0.2706656754016876	 training accuracy:1.0
Epoch:3185	training loss:0.2706158757209778	 training accuracy:1.0
Epoch:3186	training loss:0.27056604623794556	 training accuracy:1.0
Epoch:3187	training loss:0.270516037940979	 training accuracy:1.0
Epoch:3188	training loss:0.2704661190509796	 training accuracy:1.0
Epoch:3189	training loss:0.270416259765625	 training accuracy:1.0
Epoch:3190	training loss:0.2703666687011719	 training accuracy:1.0
Epoch:3191	training loss:0.27031707763671875	 training accuracy:1.0
Epoch:3192	training loss:0.2702670991420746	 training accuracy:1.0
Epoch:3193	training loss:0.2702168822288513	 training accuracy:1.0
Epoch:3194	training loss:0.27016714215278625	 training accuracy:1.0
Epoch:3195	training loss:0.2701176702976227	 training accuracy:1.0
Epoch:3196	training loss:0.2700681984424591	 training accuracy:1.0
Epoch:3197	training loss:0.2700183093547821	 training accuracy:1.0
Epoch:3198	training loss:0.2699682414531708	 training accuracy:1.0
Epoch:3199	training loss:0.2699187397956848	 training accuracy:1.0
Epoch:3200	training loss:0.26986944675445557	 training accuracy:1.0
Epoch:3201	training loss:0.2698202133178711	 training accuracy:1.0
Epoch:3202	training loss:0.26977047324180603	 training accuracy:1.0
Epoch:3203	training loss:0.2697204351425171	 training accuracy:1.0
Epoch:3204	training loss:0.26967084407806396	 training accuracy:1.0
Epoch:3205	training loss:0.26962122321128845	 training accuracy:1.0
Epoch:3206	training loss:0.26957157254219055	 training accuracy:1.0
Epoch:3207	training loss:0.26952216029167175	 training accuracy:1.0
Epoch:3208	training loss:0.26947230100631714	 training accuracy:1.0
Epoch:3209	training loss:0.269422709941864	 training accuracy:1.0
Epoch:3210	training loss:0.26937323808670044	 training accuracy:1.0
Epoch:3211	training loss:0.26932382583618164	 training accuracy:1.0
Epoch:3212	training loss:0.2692744731903076	 training accuracy:1.0
Epoch:3213	training loss:0.26922520995140076	 training accuracy:1.0
Epoch:3214	training loss:0.2691756784915924	 training accuracy:1.0
Epoch:3215	training loss:0.2691258490085602	 training accuracy:1.0
Epoch:3216	training loss:0.26907601952552795	 training accuracy:1.0
Epoch:3217	training loss:0.26902663707733154	 training accuracy:1.0
Epoch:3218	training loss:0.26897770166397095	 training accuracy:1.0
Epoch:3219	training loss:0.26892849802970886	 training accuracy:1.0
Epoch:3220	training loss:0.26887887716293335	 training accuracy:1.0
Epoch:3221	training loss:0.26882970333099365	 training accuracy:1.0
Epoch:3222	training loss:0.26878035068511963	 training accuracy:1.0
Epoch:3223	training loss:0.26873070001602173	 training accuracy:1.0
Epoch:3224	training loss:0.2686814069747925	 training accuracy:1.0
Epoch:3225	training loss:0.2686324417591095	 training accuracy:1.0
Epoch:3226	training loss:0.2685832977294922	 training accuracy:1.0
Epoch:3227	training loss:0.268533855676651	 training accuracy:1.0
Epoch:3228	training loss:0.2684842646121979	 training accuracy:1.0
Epoch:3229	training loss:0.26843488216400146	 training accuracy:1.0
Epoch:3230	training loss:0.2683856785297394	 training accuracy:1.0
Epoch:3231	training loss:0.26833635568618774	 training accuracy:1.0
Epoch:3232	training loss:0.2682870626449585	 training accuracy:1.0
Epoch:3233	training loss:0.2682379186153412	 training accuracy:1.0
Epoch:3234	training loss:0.2681885361671448	 training accuracy:1.0
Epoch:3235	training loss:0.2681390643119812	 training accuracy:1.0
Epoch:3236	training loss:0.2680903375148773	 training accuracy:1.0
Epoch:3237	training loss:0.2680411636829376	 training accuracy:1.0
Epoch:3238	training loss:0.26799172163009644	 training accuracy:1.0
Epoch:3239	training loss:0.2679424285888672	 training accuracy:1.0
Epoch:3240	training loss:0.267892986536026	 training accuracy:1.0
Epoch:3241	training loss:0.26784417033195496	 training accuracy:1.0
Epoch:3242	training loss:0.26779529452323914	 training accuracy:1.0
Epoch:3243	training loss:0.2677462100982666	 training accuracy:1.0
Epoch:3244	training loss:0.267697274684906	 training accuracy:1.0
Epoch:3245	training loss:0.267648309469223	 training accuracy:1.0
Epoch:3246	training loss:0.2675990164279938	 training accuracy:1.0
Epoch:3247	training loss:0.2675497233867645	 training accuracy:1.0
Epoch:3248	training loss:0.2675004005432129	 training accuracy:1.0
Epoch:3249	training loss:0.2674519419670105	 training accuracy:1.0
Epoch:3250	training loss:0.26740309596061707	 training accuracy:1.0
Epoch:3251	training loss:0.267353892326355	 training accuracy:1.0
Epoch:3252	training loss:0.2673046290874481	 training accuracy:1.0
Epoch:3253	training loss:0.2672555148601532	 training accuracy:1.0
Epoch:3254	training loss:0.26720714569091797	 training accuracy:1.0
Epoch:3255	training loss:0.2671584188938141	 training accuracy:1.0
Epoch:3256	training loss:0.2671094536781311	 training accuracy:1.0
Epoch:3257	training loss:0.2670605182647705	 training accuracy:1.0
Epoch:3258	training loss:0.2670114040374756	 training accuracy:1.0
Epoch:3259	training loss:0.266962468624115	 training accuracy:1.0
Epoch:3260	training loss:0.2669134736061096	 training accuracy:1.0
Epoch:3261	training loss:0.2668645679950714	 training accuracy:1.0
Epoch:3262	training loss:0.26681554317474365	 training accuracy:1.0
Epoch:3263	training loss:0.2667667269706726	 training accuracy:1.0
Epoch:3264	training loss:0.26671773195266724	 training accuracy:1.0
Epoch:3265	training loss:0.2666686773300171	 training accuracy:1.0
Epoch:3266	training loss:0.26661980152130127	 training accuracy:1.0
Epoch:3267	training loss:0.2665715515613556	 training accuracy:1.0
Epoch:3268	training loss:0.26652297377586365	 training accuracy:1.0
Epoch:3269	training loss:0.2664739489555359	 training accuracy:1.0
Epoch:3270	training loss:0.26642492413520813	 training accuracy:1.0
Epoch:3271	training loss:0.2663760185241699	 training accuracy:1.0
Epoch:3272	training loss:0.26632776856422424	 training accuracy:1.0
Epoch:3273	training loss:0.26627957820892334	 training accuracy:1.0
Epoch:3274	training loss:0.26623111963272095	 training accuracy:1.0
Epoch:3275	training loss:0.2661818265914917	 training accuracy:1.0
Epoch:3276	training loss:0.2661327123641968	 training accuracy:1.0
Epoch:3277	training loss:0.2660840153694153	 training accuracy:1.0
Epoch:3278	training loss:0.2660355269908905	 training accuracy:1.0
Epoch:3279	training loss:0.26598674058914185	 training accuracy:1.0
Epoch:3280	training loss:0.2659377157688141	 training accuracy:1.0
Epoch:3281	training loss:0.26588961482048035	 training accuracy:1.0
Epoch:3282	training loss:0.2658410966396332	 training accuracy:1.0
Epoch:3283	training loss:0.26579219102859497	 training accuracy:1.0
Epoch:3284	training loss:0.265743613243103	 training accuracy:1.0
Epoch:3285	training loss:0.2656952440738678	 training accuracy:1.0
Epoch:3286	training loss:0.2656465172767639	 training accuracy:1.0
Epoch:3287	training loss:0.26559776067733765	 training accuracy:1.0
Epoch:3288	training loss:0.2655491530895233	 training accuracy:1.0
Epoch:3289	training loss:0.2655007243156433	 training accuracy:1.0
Epoch:3290	training loss:0.26545262336730957	 training accuracy:1.0
Epoch:3291	training loss:0.2654044032096863	 training accuracy:1.0
Epoch:3292	training loss:0.2653559744358063	 training accuracy:1.0
Epoch:3293	training loss:0.26530736684799194	 training accuracy:1.0
Epoch:3294	training loss:0.2652587890625	 training accuracy:1.0
Epoch:3295	training loss:0.26521036028862	 training accuracy:1.0
Epoch:3296	training loss:0.2651618421077728	 training accuracy:1.0
Epoch:3297	training loss:0.26511350274086	 training accuracy:1.0
Epoch:3298	training loss:0.26506495475769043	 training accuracy:1.0
Epoch:3299	training loss:0.26501622796058655	 training accuracy:1.0
Epoch:3300	training loss:0.2649674415588379	 training accuracy:1.0
Epoch:3301	training loss:0.2649191617965698	 training accuracy:1.0
Epoch:3302	training loss:0.2648710012435913	 training accuracy:1.0
Epoch:3303	training loss:0.2648228406906128	 training accuracy:1.0
Epoch:3304	training loss:0.264774352312088	 training accuracy:1.0
Epoch:3305	training loss:0.26472604274749756	 training accuracy:1.0
Epoch:3306	training loss:0.2646777033805847	 training accuracy:1.0
Epoch:3307	training loss:0.2646292448043823	 training accuracy:1.0
Epoch:3308	training loss:0.2645811140537262	 training accuracy:1.0
Epoch:3309	training loss:0.26453301310539246	 training accuracy:1.0
Epoch:3310	training loss:0.2644849121570587	 training accuracy:1.0
Epoch:3311	training loss:0.26443663239479065	 training accuracy:1.0
Epoch:3312	training loss:0.2643885612487793	 training accuracy:1.0
Epoch:3313	training loss:0.26434051990509033	 training accuracy:1.0
Epoch:3314	training loss:0.264292448759079	 training accuracy:1.0
Epoch:3315	training loss:0.2642441689968109	 training accuracy:1.0
Epoch:3316	training loss:0.2641961872577667	 training accuracy:1.0
Epoch:3317	training loss:0.2641479969024658	 training accuracy:1.0
Epoch:3318	training loss:0.2640993297100067	 training accuracy:1.0
Epoch:3319	training loss:0.26405102014541626	 training accuracy:1.0
Epoch:3320	training loss:0.26400256156921387	 training accuracy:1.0
Epoch:3321	training loss:0.2639550566673279	 training accuracy:1.0
Epoch:3322	training loss:0.26390692591667175	 training accuracy:1.0
Epoch:3323	training loss:0.26385849714279175	 training accuracy:1.0
Epoch:3324	training loss:0.2638102173805237	 training accuracy:1.0
Epoch:3325	training loss:0.26376205682754517	 training accuracy:1.0
Epoch:3326	training loss:0.26371440291404724	 training accuracy:1.0
Epoch:3327	training loss:0.263666570186615	 training accuracy:1.0
Epoch:3328	training loss:0.2636182904243469	 training accuracy:1.0
Epoch:3329	training loss:0.2635701298713684	 training accuracy:1.0
Epoch:3330	training loss:0.263522207736969	 training accuracy:1.0
Epoch:3331	training loss:0.2634742856025696	 training accuracy:1.0
Epoch:3332	training loss:0.26342642307281494	 training accuracy:1.0
Epoch:3333	training loss:0.2633785009384155	 training accuracy:1.0
Epoch:3334	training loss:0.2633305788040161	 training accuracy:1.0
Epoch:3335	training loss:0.2632824182510376	 training accuracy:1.0
Epoch:3336	training loss:0.26323413848876953	 training accuracy:1.0
Epoch:3337	training loss:0.2631860673427582	 training accuracy:1.0
Epoch:3338	training loss:0.26313838362693787	 training accuracy:1.0
Epoch:3339	training loss:0.26309093832969666	 training accuracy:1.0
Epoch:3340	training loss:0.2630431354045868	 training accuracy:1.0
Epoch:3341	training loss:0.26299551129341125	 training accuracy:1.0
Epoch:3342	training loss:0.26294735074043274	 training accuracy:1.0
Epoch:3343	training loss:0.262899249792099	 training accuracy:1.0
Epoch:3344	training loss:0.26285189390182495	 training accuracy:1.0
Epoch:3345	training loss:0.26280444860458374	 training accuracy:1.0
Epoch:3346	training loss:0.2627566158771515	 training accuracy:1.0
Epoch:3347	training loss:0.2627085745334625	 training accuracy:1.0
Epoch:3348	training loss:0.2626604735851288	 training accuracy:1.0
Epoch:3349	training loss:0.2626127004623413	 training accuracy:1.0
Epoch:3350	training loss:0.262565016746521	 training accuracy:1.0
Epoch:3351	training loss:0.26251718401908875	 training accuracy:1.0
Epoch:3352	training loss:0.2624691128730774	 training accuracy:1.0
Epoch:3353	training loss:0.2624216675758362	 training accuracy:1.0
Epoch:3354	training loss:0.2623739242553711	 training accuracy:1.0
Epoch:3355	training loss:0.26232588291168213	 training accuracy:1.0
Epoch:3356	training loss:0.26227834820747375	 training accuracy:1.0
Epoch:3357	training loss:0.26223090291023254	 training accuracy:1.0
Epoch:3358	training loss:0.2621832489967346	 training accuracy:1.0
Epoch:3359	training loss:0.26213517785072327	 training accuracy:1.0
Epoch:3360	training loss:0.26208701729774475	 training accuracy:1.0
Epoch:3361	training loss:0.26203984022140503	 training accuracy:1.0
Epoch:3362	training loss:0.2619929313659668	 training accuracy:1.0
Epoch:3363	training loss:0.2619454860687256	 training accuracy:1.0
Epoch:3364	training loss:0.2618979513645172	 training accuracy:1.0
Epoch:3365	training loss:0.26185017824172974	 training accuracy:1.0
Epoch:3366	training loss:0.26180267333984375	 training accuracy:1.0
Epoch:3367	training loss:0.2617553472518921	 training accuracy:1.0
Epoch:3368	training loss:0.2617078125476837	 training accuracy:1.0
Epoch:3369	training loss:0.2616605758666992	 training accuracy:1.0
Epoch:3370	training loss:0.2616129517555237	 training accuracy:1.0
Epoch:3371	training loss:0.26156532764434814	 training accuracy:1.0
Epoch:3372	training loss:0.2615179419517517	 training accuracy:1.0
Epoch:3373	training loss:0.2614699602127075	 training accuracy:1.0
Epoch:3374	training loss:0.2614222466945648	 training accuracy:1.0
Epoch:3375	training loss:0.2613750398159027	 training accuracy:1.0
Epoch:3376	training loss:0.2613276243209839	 training accuracy:1.0
Epoch:3377	training loss:0.2612801194190979	 training accuracy:1.0
Epoch:3378	training loss:0.26123255491256714	 training accuracy:1.0
Epoch:3379	training loss:0.2611851096153259	 training accuracy:1.0
Epoch:3380	training loss:0.26113787293434143	 training accuracy:1.0
Epoch:3381	training loss:0.2610906958580017	 training accuracy:1.0
Epoch:3382	training loss:0.26104336977005005	 training accuracy:1.0
Epoch:3383	training loss:0.2609958052635193	 training accuracy:1.0
Epoch:3384	training loss:0.26094818115234375	 training accuracy:1.0
Epoch:3385	training loss:0.26090097427368164	 training accuracy:1.0
Epoch:3386	training loss:0.2608537971973419	 training accuracy:1.0
Epoch:3387	training loss:0.2608066201210022	 training accuracy:1.0
Epoch:3388	training loss:0.2607591450214386	 training accuracy:1.0
Epoch:3389	training loss:0.2607118785381317	 training accuracy:1.0
Epoch:3390	training loss:0.26066458225250244	 training accuracy:1.0
Epoch:3391	training loss:0.26061713695526123	 training accuracy:1.0
Epoch:3392	training loss:0.2605697810649872	 training accuracy:1.0
Epoch:3393	training loss:0.26052308082580566	 training accuracy:1.0
Epoch:3394	training loss:0.2604760527610779	 training accuracy:1.0
Epoch:3395	training loss:0.2604285776615143	 training accuracy:1.0
Epoch:3396	training loss:0.26038113236427307	 training accuracy:1.0
Epoch:3397	training loss:0.2603338956832886	 training accuracy:1.0
Epoch:3398	training loss:0.2602870464324951	 training accuracy:1.0
Epoch:3399	training loss:0.26023995876312256	 training accuracy:1.0
Epoch:3400	training loss:0.26019251346588135	 training accuracy:1.0
Epoch:3401	training loss:0.2601456642150879	 training accuracy:1.0
Epoch:3402	training loss:0.26009851694107056	 training accuracy:1.0
Epoch:3403	training loss:0.2600511312484741	 training accuracy:1.0
Epoch:3404	training loss:0.2600042223930359	 training accuracy:1.0
Epoch:3405	training loss:0.25995704531669617	 training accuracy:1.0
Epoch:3406	training loss:0.2599097490310669	 training accuracy:1.0
Epoch:3407	training loss:0.25986263155937195	 training accuracy:1.0
Epoch:3408	training loss:0.2598152160644531	 training accuracy:1.0
Epoch:3409	training loss:0.25976812839508057	 training accuracy:1.0
Epoch:3410	training loss:0.25972145795822144	 training accuracy:1.0
Epoch:3411	training loss:0.259674608707428	 training accuracy:1.0
Epoch:3412	training loss:0.25962769985198975	 training accuracy:1.0
Epoch:3413	training loss:0.2595805525779724	 training accuracy:1.0
Epoch:3414	training loss:0.25953325629234314	 training accuracy:1.0
Epoch:3415	training loss:0.25948604941368103	 training accuracy:1.0
Epoch:3416	training loss:0.2594393193721771	 training accuracy:1.0
Epoch:3417	training loss:0.25939273834228516	 training accuracy:1.0
Epoch:3418	training loss:0.25934579968452454	 training accuracy:1.0
Epoch:3419	training loss:0.2592983543872833	 training accuracy:1.0
Epoch:3420	training loss:0.25925102829933167	 training accuracy:1.0
Epoch:3421	training loss:0.2592044770717621	 training accuracy:1.0
Epoch:3422	training loss:0.25915804505348206	 training accuracy:1.0
Epoch:3423	training loss:0.2591113746166229	 training accuracy:1.0
Epoch:3424	training loss:0.2590644657611847	 training accuracy:1.0
Epoch:3425	training loss:0.25901782512664795	 training accuracy:1.0
Epoch:3426	training loss:0.2589707672595978	 training accuracy:1.0
Epoch:3427	training loss:0.25892361998558044	 training accuracy:1.0
Epoch:3428	training loss:0.258876770734787	 training accuracy:1.0
Epoch:3429	training loss:0.25883015990257263	 training accuracy:1.0
Epoch:3430	training loss:0.25878337025642395	 training accuracy:1.0
Epoch:3431	training loss:0.2587364614009857	 training accuracy:1.0
Epoch:3432	training loss:0.25868961215019226	 training accuracy:1.0
Epoch:3433	training loss:0.25864264369010925	 training accuracy:1.0
Epoch:3434	training loss:0.2585963010787964	 training accuracy:1.0
Epoch:3435	training loss:0.2585498094558716	 training accuracy:1.0
Epoch:3436	training loss:0.2585030496120453	 training accuracy:1.0
Epoch:3437	training loss:0.25845611095428467	 training accuracy:1.0
Epoch:3438	training loss:0.25840920209884644	 training accuracy:1.0
Epoch:3439	training loss:0.25836238265037537	 training accuracy:1.0
Epoch:3440	training loss:0.25831547379493713	 training accuracy:1.0
Epoch:3441	training loss:0.2582691013813019	 training accuracy:1.0
Epoch:3442	training loss:0.2582224905490875	 training accuracy:1.0
Epoch:3443	training loss:0.25817587971687317	 training accuracy:1.0
Epoch:3444	training loss:0.2581290006637573	 training accuracy:1.0
Epoch:3445	training loss:0.25808218121528625	 training accuracy:1.0
Epoch:3446	training loss:0.25803548097610474	 training accuracy:1.0
Epoch:3447	training loss:0.2579891085624695	 training accuracy:1.0
Epoch:3448	training loss:0.2579423189163208	 training accuracy:1.0
Epoch:3449	training loss:0.2578958570957184	 training accuracy:1.0
Epoch:3450	training loss:0.25784939527511597	 training accuracy:1.0
Epoch:3451	training loss:0.2578029930591583	 training accuracy:1.0
Epoch:3452	training loss:0.25775691866874695	 training accuracy:1.0
Epoch:3453	training loss:0.25771042704582214	 training accuracy:1.0
Epoch:3454	training loss:0.25766387581825256	 training accuracy:1.0
Epoch:3455	training loss:0.2576169967651367	 training accuracy:1.0
Epoch:3456	training loss:0.2575705051422119	 training accuracy:1.0
Epoch:3457	training loss:0.2575240731239319	 training accuracy:1.0
Epoch:3458	training loss:0.2574774920940399	 training accuracy:1.0
Epoch:3459	training loss:0.2574310302734375	 training accuracy:1.0
Epoch:3460	training loss:0.2573844790458679	 training accuracy:1.0
Epoch:3461	training loss:0.2573382556438446	 training accuracy:1.0
Epoch:3462	training loss:0.25729164481163025	 training accuracy:1.0
Epoch:3463	training loss:0.2572450041770935	 training accuracy:1.0
Epoch:3464	training loss:0.2571985721588135	 training accuracy:1.0
Epoch:3465	training loss:0.25715261697769165	 training accuracy:1.0
Epoch:3466	training loss:0.2571064233779907	 training accuracy:1.0
Epoch:3467	training loss:0.25705963373184204	 training accuracy:1.0
Epoch:3468	training loss:0.25701284408569336	 training accuracy:1.0
Epoch:3469	training loss:0.25696662068367004	 training accuracy:1.0
Epoch:3470	training loss:0.25692084431648254	 training accuracy:1.0
Epoch:3471	training loss:0.2568746507167816	 training accuracy:1.0
Epoch:3472	training loss:0.2568279802799225	 training accuracy:1.0
Epoch:3473	training loss:0.2567816972732544	 training accuracy:1.0
Epoch:3474	training loss:0.2567354142665863	 training accuracy:1.0
Epoch:3475	training loss:0.2566889226436615	 training accuracy:1.0
Epoch:3476	training loss:0.2566426396369934	 training accuracy:1.0
Epoch:3477	training loss:0.2565963566303253	 training accuracy:1.0
Epoch:3478	training loss:0.2565501928329468	 training accuracy:1.0
Epoch:3479	training loss:0.25650379061698914	 training accuracy:1.0
Epoch:3480	training loss:0.25645720958709717	 training accuracy:1.0
Epoch:3481	training loss:0.2564111649990082	 training accuracy:1.0
Epoch:3482	training loss:0.25636518001556396	 training accuracy:1.0
Epoch:3483	training loss:0.25631922483444214	 training accuracy:1.0
Epoch:3484	training loss:0.2562733590602875	 training accuracy:1.0
Epoch:3485	training loss:0.2562272250652313	 training accuracy:1.0
Epoch:3486	training loss:0.25618064403533936	 training accuracy:1.0
Epoch:3487	training loss:0.25613439083099365	 training accuracy:1.0
Epoch:3488	training loss:0.2560884952545166	 training accuracy:1.0
Epoch:3489	training loss:0.2560428977012634	 training accuracy:1.0
Epoch:3490	training loss:0.25599682331085205	 training accuracy:1.0
Epoch:3491	training loss:0.2559504508972168	 training accuracy:1.0
Epoch:3492	training loss:0.25590425729751587	 training accuracy:1.0
Epoch:3493	training loss:0.2558581829071045	 training accuracy:1.0
Epoch:3494	training loss:0.2558121383190155	 training accuracy:1.0
Epoch:3495	training loss:0.2557659149169922	 training accuracy:1.0
Epoch:3496	training loss:0.2557196319103241	 training accuracy:1.0
Epoch:3497	training loss:0.2556738257408142	 training accuracy:1.0
Epoch:3498	training loss:0.25562784075737	 training accuracy:1.0
Epoch:3499	training loss:0.2555815577507019	 training accuracy:1.0
Epoch:3500	training loss:0.25553518533706665	 training accuracy:1.0
--- 507.9118318557739 seconds ---
